[
  {
    "objectID": "articles/external-materials.html",
    "href": "articles/external-materials.html",
    "title": "Materials and external sources for learning R",
    "section": "",
    "text": "R4DS: R for data science by Hadley Wickham and Garrett Grolemund (source code)\n\n\n\nRStudio cheat sheets (here) on:\n\nData import with readr, readxl, and googlesheets4 cheatsheet\nData transformation with dplyr cheatsheet\nData tidying with tidyr cheatsheet\n\nRStudio Webinars + sourcode:\n\nData wrangling with R and RStudio by Garrett Grolemund\nTidyverse visualization manipulation basics by Garrett Grolemund\nWhat’s new with readxl? with Jenny Bryan\n\nTutorials from INBO Tutorials:\n\nR for beginners from Research Institute for Nature and Forest (INBO) in Belgium"
  },
  {
    "objectID": "slides/30-multiple-regression/ovb.html#omitted-variable",
    "href": "slides/30-multiple-regression/ovb.html#omitted-variable",
    "title": "Omitted Variable Bias",
    "section": "Omitted Variable",
    "text": "Omitted Variable\nLong Model\n\\[Y_i = \\alpha ^ l + \\beta ^ l P_i + \\gamma A_i + e^l_i\\]\nwhere:\n\n\n\\(Y_i\\) is the outcome variable;\n\\(P_i\\) is the key variable of treatment effect;\n\\(\\alpha ^ l\\) , \\(\\beta ^ l\\) are true regression coefficients;\n\\(\\gamma\\) is the effect of omitted variable in long;\n\\(A_i\\) is the omitted variable;"
  },
  {
    "objectID": "slides/30-multiple-regression/ovb.html#omitted-variable-1",
    "href": "slides/30-multiple-regression/ovb.html#omitted-variable-1",
    "title": "Omitted Variable Bias",
    "section": "Omitted Variable",
    "text": "Omitted Variable\nLong Model\n\\[Y_i = \\alpha ^ l + \\beta ^ l P_i + \\gamma A_i + e^l_i\\]\nwhere:\n\n\\(Y_i\\) is the outcome variable;\n\\(P_i\\) is the key variable of treatment effect;\n\\(\\alpha ^ l\\) , \\(\\beta ^ l\\) are true regression coefficients;\n\\(\\gamma\\) is the effect of omitted variable in long;\n\\(A_i\\) is the omitted variable;\n\nShort model\n\\[Y_i = \\alpha ^ s + \\beta^s P_i + e^s_i\\]\nIs the model that omit one or more variables compare to the long one."
  },
  {
    "objectID": "slides/30-multiple-regression/ovb.html#ovb-logic",
    "href": "slides/30-multiple-regression/ovb.html#ovb-logic",
    "title": "Omitted Variable Bias",
    "section": "OVB logic",
    "text": "OVB logic"
  },
  {
    "objectID": "slides/30-multiple-regression/ovb.html#why-ovb-formula-is-important",
    "href": "slides/30-multiple-regression/ovb.html#why-ovb-formula-is-important",
    "title": "Omitted Variable Bias",
    "section": "Why OVB formula is important?",
    "text": "Why OVB formula is important?\n\n\nOmitted Variable - means that we cannot have it in the regression!\nWe can’t use data to check the consequences of omitting variables that we don’t observe.\nHaving knowledge of mathematics behind OVB, we can make an educated guess about consequences of variable omission: the BIAS (Angrist and Pischke 2014)\nFor example, we can write our:\n\nauxiliary regression: \\(A_i = \\pi_0 + \\pi_1 P_i + u\\) ; and\npotential regression: \\(Y_i = \\alpha ^ l + \\beta^l P_i + \\gamma A_i + e^l_i\\)\n\nbecause \\(\\text{OVB} = \\pi_1 \\times \\gamma\\)\n\nwe can speculate about signs of \\(\\pi_1\\) and \\(\\gamma\\)\nwe can justify how omitted variable biases our regression: upwards (increasing the effect of interest) or downwards (decreeing it)."
  },
  {
    "objectID": "slides/30-multiple-regression/ovb.html#how-to-resolve-the-ovb",
    "href": "slides/30-multiple-regression/ovb.html#how-to-resolve-the-ovb",
    "title": "Omitted Variable Bias",
    "section": "How to resolve the OVB?",
    "text": "How to resolve the OVB?\n\n\nNo solution!\n\nFind proxies\nDevelop an elaborate research design\n\nAcknowledge presence of the OVB\nDiscuss the extent of bias"
  },
  {
    "objectID": "slides/30-multiple-regression/ovb.html#mlr-fertility-rates-and-development",
    "href": "slides/30-multiple-regression/ovb.html#mlr-fertility-rates-and-development",
    "title": "Omitted Variable Bias",
    "section": "MLR: fertility rates and development",
    "text": "MLR: fertility rates and development\nWe explore UN11 data from (Weisberg 2005)\n\nIt has 199 observations and 6 variables\nVariables are:\n\nfertility - number of children per woman;\nlifeExpF - Female life expectancy, years;\nppgdp - Per capita gross domestic product in US dollars;\npctUrban - Percent of Urban population;\ngroup - variable with 3 values “oecd”, “africa” and “others”;\nafrica, other and oecd - dummy variables taking values of 1 if a country is in respectively Africa, other countries or OECD."
  },
  {
    "objectID": "slides/30-multiple-regression/ovb.html#research-question",
    "href": "slides/30-multiple-regression/ovb.html#research-question",
    "title": "Omitted Variable Bias",
    "section": "Research question",
    "text": "Research question\nHow does the life expectancy affect fertility?"
  },
  {
    "objectID": "slides/30-multiple-regression/ovb.html#data",
    "href": "slides/30-multiple-regression/ovb.html#data",
    "title": "Omitted Variable Bias",
    "section": "Data",
    "text": "Data\n\n\nCode\nlibrary(alr4)           #install.packages(\"alr4\")\nlibrary(tidyverse)      #install.packages(\"tidyverse\")\nun_dta <- \n  alr4::UN11 %>%\n  as_tibble() %>%\n  select(-region) %>%\n  mutate(\n    Africa = as.integer(group  == \"africa\"),\n    Other = as.integer(group  == \"other\"),\n    OECD = as.integer(group  == \"oecd\")\n  )\nglimpse(un_dta)\n\n\nRows: 199\nColumns: 8\n$ group     <fct> other, other, africa, africa, other, other, other, other, oe…\n$ fertility <dbl> 5.968, 1.525, 2.142, 5.135, 2.000, 2.172, 1.735, 1.671, 1.94…\n$ ppgdp     <dbl> 499.0, 3677.2, 4473.0, 4321.9, 13750.1, 9162.1, 3030.7, 2285…\n$ lifeExpF  <dbl> 49.49, 80.40, 75.00, 53.17, 81.10, 79.89, 77.33, 77.75, 84.2…\n$ pctUrban  <dbl> 23, 53, 67, 59, 100, 93, 64, 47, 89, 68, 52, 84, 89, 29, 45,…\n$ Africa    <int> 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, …\n$ Other     <int> 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, …\n$ OECD      <int> 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, …"
  },
  {
    "objectID": "slides/30-multiple-regression/ovb.html#regression",
    "href": "slides/30-multiple-regression/ovb.html#regression",
    "title": "Omitted Variable Bias",
    "section": "Regression",
    "text": "Regression\nShort regression - important control variable is omitted\n\n\nCode\nfit_s <- lm(fertility ~ lifeExpF + pctUrban + group , un_dta)\nparameters(fit_s)\n\n\nParameter      | Coefficient |       SE |         95% CI | t(194) |      p\n--------------------------------------------------------------------------\n(Intercept)    |        9.79 |     0.73 | [ 8.34, 11.24] |  13.35 | < .001\nlifeExpF       |       -0.09 | 9.62e-03 | [-0.11, -0.07] |  -9.63 | < .001\npctUrban       |   -5.11e-03 | 2.89e-03 | [-0.01,  0.00] |  -1.77 | 0.078 \ngroup [other]  |       -0.15 |     0.16 | [-0.48,  0.17] |  -0.94 | 0.350 \ngroup [africa] |        0.20 |     0.26 | [-0.31,  0.71] |   0.78 | 0.438"
  },
  {
    "objectID": "slides/30-multiple-regression/ovb.html#calculating-omitted-variable-bias",
    "href": "slides/30-multiple-regression/ovb.html#calculating-omitted-variable-bias",
    "title": "Omitted Variable Bias",
    "section": "Calculating Omitted Variable Bias",
    "text": "Calculating Omitted Variable Bias\nProcess:\n\nEstimate long and auxiliary regressions\nExtract relevant coefficients and calculating the bias"
  },
  {
    "objectID": "slides/30-multiple-regression/ovb.html#interpreting-the-results-with-ovb",
    "href": "slides/30-multiple-regression/ovb.html#interpreting-the-results-with-ovb",
    "title": "Omitted Variable Bias",
    "section": "Interpreting the results with OVB",
    "text": "Interpreting the results with OVB\n\nscreen_many_regs(fit_s, fit_l)\n\n\n=========================================================\n             Model 1                Model 2              \n---------------------------------------------------------\n(Intercept)    9.7910 (0.7332) ***   10.5082 (0.7359) ***\nlifeExpF      -0.0926 (0.0096) ***   -0.0765 (0.0103) ***\npctUrban      -0.0051 (0.0029)        0.0019 (0.0034)    \ngroupother    -0.1544 (0.1649)       -0.3678 (0.1697) *  \ngroupafrica    0.2008 (0.2585)       -0.0236 (0.2576)    \nlog(ppgdp)                           -0.2496 (0.0672) ***\n---------------------------------------------------------\nR^2            0.6899                 0.7106             \nAdj. R^2       0.6835                 0.7031             \nNum. obs.    199                    199                  \nNum. df      194                    193                  \nF statistic  107.8967 ***            94.7652 ***         \n=========================================================\n*** p < 0.001; ** p < 0.01; * p < 0.05\nModel 1: fertility ~ lifeExpF + pctUrban + group\nModel 2: fertility ~ lifeExpF + pctUrban + group + log(ppgdp)"
  },
  {
    "objectID": "slides/30-multiple-regression/collinearity.html#collinearity-or-muticollinearity",
    "href": "slides/30-multiple-regression/collinearity.html#collinearity-or-muticollinearity",
    "title": "Collinearity",
    "section": "Collinearity or Muticollinearity",
    "text": "Collinearity or Muticollinearity\n\nNo collinearity means\n\nnone of the regressors can be written as an exact linear combinations of some other regressors in the model.\n\nFor example:\n\nin \\(Y = \\beta_1 X_1 + \\beta_2 X_2 + \\beta_3 X_3\\) ,\nwhere \\(X_3 = X_2 + X_1\\) ,\nall \\(X\\) are collinear."
  },
  {
    "objectID": "slides/30-multiple-regression/collinearity.html#consequence-of-collinearity",
    "href": "slides/30-multiple-regression/collinearity.html#consequence-of-collinearity",
    "title": "Collinearity",
    "section": "Consequence of collinearity:",
    "text": "Consequence of collinearity:\n\nbiased estimates of the collinear variables\nover-significant results;"
  },
  {
    "objectID": "slides/30-multiple-regression/collinearity.html#detection-of-collinearity",
    "href": "slides/30-multiple-regression/collinearity.html#detection-of-collinearity",
    "title": "Collinearity",
    "section": "Detection of collinearity:",
    "text": "Detection of collinearity:\n\nScatter plot; Correlation matrix;\nModel specification;\nStep-wise regression approach;\nVariance Inflation Factor;"
  },
  {
    "objectID": "slides/30-multiple-regression/collinearity.html#solution-to-collinearity",
    "href": "slides/30-multiple-regression/collinearity.html#solution-to-collinearity",
    "title": "Collinearity",
    "section": "Solution to collinearity:",
    "text": "Solution to collinearity:\n\nRe specify the model;\nChoose different regressors;\nSee also:\n\nOverview: “Assumption AMLR.3 No Perfect Collinearity” in (Wooldridge 2020) ;\nExamples of causes in Chapter 9.5 (Wooldridge 2020) ;\nChapter 9.4-9.5 in (Weisberg 2005);"
  },
  {
    "objectID": "slides/30-multiple-regression/collinearity.html#example-0.1",
    "href": "slides/30-multiple-regression/collinearity.html#example-0.1",
    "title": "Collinearity",
    "section": "Example 0.1",
    "text": "Example 0.1\n\\[\\hat{output} = \\hat\\beta_1 land + \\hat\\beta_2 seeds + \\hat\\beta_3 fertilizers + \\hat\\beta_4 others + \\hat\\beta_5 total\\]\n\nwhere \\(total = seeds + fertilizers + others\\)\n\n\n\n\n\n\nImportant\n\n\nIs there a multicollinearity problem here?\n\n\n\n\n\n\n\n\n\nDanger\n\n\nYES! Definitely!\n\n\n\n\n\n\n\n\n\nTip\n\n\nCoefficient \\(\\hat\\beta_5\\) is aliased and wont be estimated"
  },
  {
    "objectID": "slides/30-multiple-regression/collinearity.html#example-0.2",
    "href": "slides/30-multiple-regression/collinearity.html#example-0.2",
    "title": "Collinearity",
    "section": "Example 0.2",
    "text": "Example 0.2\n\\[\\hat{output} = \\hat\\beta_1 land + \\hat\\beta_2 seeds + \\hat\\beta_3 fertilizers + \\hat\\beta_4 others\\]\n\nwhere \\(seeds\\) and \\(fertilizers\\) highly correlate between each other,\nVIF of \\(seeds\\) and \\(fertilizers\\) is 12.2\nour key variable is \\(land\\).\n\n\n\n\n\n\nImportant\n\n\nIs there a multicollinearity problem here?\n\n\n\n\n\n\n\n\n\nDanger\n\n\nNot really!\n\n\n\nBecause \\(fertilizers\\) is a control variable and we may have OVB if we remove it!\nIf we really want to reduce VIF…:\n\nDis-aggregate fertilizers into mineral and organic, for example.\nAggregate fertilizers and seeds"
  },
  {
    "objectID": "slides/30-multiple-regression/collinearity.html#example-0.3",
    "href": "slides/30-multiple-regression/collinearity.html#example-0.3",
    "title": "Collinearity",
    "section": "Example 0.3",
    "text": "Example 0.3\nSame model but in log:\n\\[log(\\hat{output}) = \\hat\\beta_1 log(land) + \\hat\\beta_2 log(seeds) + \\hat\\beta_3 log(fertilizers) + \\\\ \\hat\\beta_4 log(others) + \\hat\\beta_5 log(total) \\]\nwhere \\(total = seeds + fertilizers + others\\)\n\n\n\n\n\n\n\nImportant\n\n\nIs there a multicollinearity problem here?\n\n\n\nThink!\n\\(log(a) + log(b) = log(a * b)\\)\n\n\n\n\n\n\nDanger\n\n\nNot really"
  },
  {
    "objectID": "slides/30-multiple-regression/collinearity.html#example-0.4",
    "href": "slides/30-multiple-regression/collinearity.html#example-0.4",
    "title": "Collinearity",
    "section": "Example 0.4",
    "text": "Example 0.4\nSame model but with a quadratic term:\n\\[\\hat{output} = \\hat\\beta_1 land + \\hat\\beta_2 land^2 + \\hat\\beta_3 seeds + \\hat\\beta_4 fertilizers + \\hat\\beta_5 others\\]\n\n\n\n\n\n\n\nImportant\n\n\nIs there a multicollinearity problem here?\n\n\n\nThink!\n\n\n\n\n\n\nDanger\n\n\nNot really\n\n\n\n\\(land^2\\) is not a linear combination of \\(land\\) ;\nLinear combination is when \\(land + land\\) not when \\(land \\times land\\) ;"
  },
  {
    "objectID": "slides/30-multiple-regression/collinearity.html#collinearity-example-1",
    "href": "slides/30-multiple-regression/collinearity.html#collinearity-example-1",
    "title": "Collinearity",
    "section": "Collinearity example 1:",
    "text": "Collinearity example 1:\nCollinearity detection by checking the model specification"
  },
  {
    "objectID": "slides/30-multiple-regression/collinearity.html#near-collinearity-example-3",
    "href": "slides/30-multiple-regression/collinearity.html#near-collinearity-example-3",
    "title": "Collinearity",
    "section": "Near collinearity example 3:",
    "text": "Near collinearity example 3:\nAn example of water consumption in a region as a function of population, year and annual precipitation.\n\nNear collinearity occurs when variables are highly correlated."
  },
  {
    "objectID": "slides/30-multiple-regression/collinearity.html#collinearity-example-2",
    "href": "slides/30-multiple-regression/collinearity.html#collinearity-example-2",
    "title": "Collinearity",
    "section": "Collinearity example 2:",
    "text": "Collinearity example 2:\nCollinearity detection by checking the model specification"
  },
  {
    "objectID": "slides/30-multiple-regression/linearity.html#linearity-meaning",
    "href": "slides/30-multiple-regression/linearity.html#linearity-meaning",
    "title": "Linearity",
    "section": "Linearity: meaning",
    "text": "Linearity: meaning\n\n\nthe expected value of dependent variable is a straight-line function of the independent variable\nIf linearity is violated:\n\nbias of our estimates\ninappropriate representation of the dependent variable"
  },
  {
    "objectID": "slides/30-multiple-regression/linearity.html#linearity-detection",
    "href": "slides/30-multiple-regression/linearity.html#linearity-detection",
    "title": "Linearity",
    "section": "Linearity: detection",
    "text": "Linearity: detection\n\n\nHow to detect a non-linearity?\n\nno accepted statistical tests, but\nless known Tukey test\nvisual inspection\n\nTypical plots:\n\nScatter plots of dependent and independent variables;\nobserved versus predicted/fitted values;\n\nresiduals versus predicted/fitted values;"
  },
  {
    "objectID": "slides/30-multiple-regression/linearity.html#linearity-resolutions",
    "href": "slides/30-multiple-regression/linearity.html#linearity-resolutions",
    "title": "Linearity",
    "section": "Linearity: resolutions",
    "text": "Linearity: resolutions\n\n(non) linear transformation to the dependent and/or independent variables;\n\nit does change the way how we must interpret coefficients;\n\nfind a different independent variable;\npropose a different functional form;"
  },
  {
    "objectID": "slides/30-multiple-regression/linearity.html#common-linear-transformations",
    "href": "slides/30-multiple-regression/linearity.html#common-linear-transformations",
    "title": "Linearity",
    "section": "Common linear transformations",
    "text": "Common linear transformations\n\n\nPower transformation or Box-Cox transformations;\nVariables normalization to the standard normal distribution;\nTailor expansion (Cobb-Douglas, Trans-log)"
  },
  {
    "objectID": "slides/30-multiple-regression/linearity.html#example-1-anscombe-quartet",
    "href": "slides/30-multiple-regression/linearity.html#example-1-anscombe-quartet",
    "title": "Linearity",
    "section": "Example 1: Anscombe quartet",
    "text": "Example 1: Anscombe quartet\nDescriptive statistics\n\nFour data sets each of 11 observations and two variables (x and y).\nDescriptive statistics:\n\n\n\nCode\nanscombe %>%\n  mutate(id = row_number()) %>%\n  pivot_longer(c(contains(\"x\"), contains(\"y\")), names_to = \"Variables\") %>%\n  mutate(`Data set` = str_extract(Variables, \"\\\\d\"),\n         Variables = str_remove(Variables, \"\\\\d\")) %>%\n  pivot_wider(names_from = Variables, values_from = value) %>%\n  group_by(`Data set`) %>%\n  summarise(across(c(x, y), ~ mean(.), .names = \"mean_{.col}\"),\n            across(c(x, y), ~ sd(.), .names = \"sd_{.col}\"))\n\n\n# A tibble: 4 × 5\n  `Data set` mean_x mean_y  sd_x  sd_y\n  <chr>       <dbl>  <dbl> <dbl> <dbl>\n1 1               9   7.50  3.32  2.03\n2 2               9   7.50  3.32  2.03\n3 3               9   7.5   3.32  2.03\n4 4               9   7.50  3.32  2.03"
  },
  {
    "objectID": "slides/30-multiple-regression/linearity.html#example-2-wage-and-education",
    "href": "slides/30-multiple-regression/linearity.html#example-2-wage-and-education",
    "title": "Linearity",
    "section": "Example 2: Wage and Education",
    "text": "Example 2: Wage and Education"
  },
  {
    "objectID": "slides/30-multiple-regression/linearity.html#example-3-sales-and-ceo-salary",
    "href": "slides/30-multiple-regression/linearity.html#example-3-sales-and-ceo-salary",
    "title": "Linearity",
    "section": "Example 3: Sales and CEO salary",
    "text": "Example 3: Sales and CEO salary"
  },
  {
    "objectID": "slides/30-multiple-regression/linearity.html#example-4-acceptable-linearity",
    "href": "slides/30-multiple-regression/linearity.html#example-4-acceptable-linearity",
    "title": "Linearity",
    "section": "Example 4: Acceptable linearity",
    "text": "Example 4: Acceptable linearity"
  },
  {
    "objectID": "slides/30-multiple-regression/linearity.html#example-5-fuel-taxes-influence-on-fuel-consumption",
    "href": "slides/30-multiple-regression/linearity.html#example-5-fuel-taxes-influence-on-fuel-consumption",
    "title": "Linearity",
    "section": "Example 5: Fuel taxes influence on fuel consumption?",
    "text": "Example 5: Fuel taxes influence on fuel consumption?\n\nAs a federal policy maker, we would like to understand how fuel taxes were affecting the gasoline consumption across the states.\nWe use data on fuel consumption in 2001 across all states in the USA (each observation represents a state). Data from (weisberg2013a?).\nVariables present in the data are:\n\n\\(\\text{Tax}\\) : Gasoline state tax rate, cents per gallon;\n\\(\\text{Dlic}\\) : The number of licensed drivers per 1000 population over the age of 16;;\n\\(\\text{Income}\\) : in 1000 USD Per capita personal income (year 2000);\n\\(\\text{Miles}\\) : Miles of Federal-aid highway miles in the state;\n\\(\\text{Fuel}\\) : Gasoline consumption per capita (gal.);"
  },
  {
    "objectID": "slides/30-multiple-regression/linearity.html#application-exercise",
    "href": "slides/30-multiple-regression/linearity.html#application-exercise",
    "title": "Linearity",
    "section": "Application Exercise",
    "text": "Application Exercise\n\nae04-02-MLR-linearity.Rmd"
  },
  {
    "objectID": "slides/30-multiple-regression/linearity.html#takeaways",
    "href": "slides/30-multiple-regression/linearity.html#takeaways",
    "title": "Linearity",
    "section": "Takeaways",
    "text": "Takeaways\n\nLinearity assumption\nDiagnostics of the linearity\nLinear transformations"
  },
  {
    "objectID": "slides/30-multiple-regression/linearity.html#references",
    "href": "slides/30-multiple-regression/linearity.html#references",
    "title": "Linearity",
    "section": "References",
    "text": "References\n\n\n\nhttps://ebukin.github.io/mp223-2022-aem-R-public/"
  },
  {
    "objectID": "slides/30-multiple-regression/hedonic-regression.html#hedonic-model-overview",
    "href": "slides/30-multiple-regression/hedonic-regression.html#hedonic-model-overview",
    "title": "Hedonic model",
    "section": "Hedonic Model overview",
    "text": "Hedonic Model overview\nHedonic prices is an econometric approach of quantifying monetary values of differentiated characteristics of goods and services, which are subjects of economic exchange.\n\nFor example, agricultural land.\n\nIt has such characteristics as: location, slope, environmental limitation, farmers’ accessibility, climate, expected rainfall, soil salinity, nutrient content, irrigation availability and other."
  },
  {
    "objectID": "slides/30-multiple-regression/hedonic-regression.html#hedonic-theory-12",
    "href": "slides/30-multiple-regression/hedonic-regression.html#hedonic-theory-12",
    "title": "Hedonic model",
    "section": "Hedonic Theory (1/2)",
    "text": "Hedonic Theory (1/2)\nAccording to (Palmquist 1989), hedonic model of agricultural land price is based on the equilibrium between Offer and Bid functions. Author uses partial equilibrium approach to prove this.\n\n\\[\\phi(\\hat{z}, \\tilde{z}, \\pi^{S^{'}}, r, \\beta) = R = \\pi^{S^{'}} + C(\\hat{z}, \\tilde{z}, r, \\beta)\\]\n\n\n\\(R(\\cdot)\\) - realized land price (rental of sales);\n\\(\\hat{z}\\) - land characteristics exogenous to land owner;\n\\(\\tilde{z}\\) - land characteristics in control of land owner;\n\\(r\\) - inputs prices;\n\\(\\beta\\) - technologies and opportunities such as credit availability;\n\\(\\pi^{S^{'}}\\) - expected profit of agricultural producers from land;"
  },
  {
    "objectID": "slides/30-multiple-regression/hedonic-regression.html#hedonic-theory-22",
    "href": "slides/30-multiple-regression/hedonic-regression.html#hedonic-theory-22",
    "title": "Hedonic model",
    "section": "Hedonic Theory (2/2)",
    "text": "Hedonic Theory (2/2)\nEssentially, causal function of the land rental price could be written as:\n\\[R = R(\\hat{z}, \\tilde{z}, \\pi^{S^{'}}, r, \\beta)\\]\n\n\n\n\n\n\n\nImportant\n\n\nThis is a causal relationship because (Palmquist 1989) provides solid theoretical justification for it."
  },
  {
    "objectID": "slides/30-multiple-regression/hedonic-regression.html#what-are-the-differentiated-land-characteristics",
    "href": "slides/30-multiple-regression/hedonic-regression.html#what-are-the-differentiated-land-characteristics",
    "title": "Hedonic model",
    "section": "What are the differentiated land characteristics?",
    "text": "What are the differentiated land characteristics?\nAffected by land owner:\n\na.\nb.\nc.\n\nNot affected by land owner:\n\na.\nb.\nc."
  },
  {
    "objectID": "slides/30-multiple-regression/hedonic-regression.html#loading-data",
    "href": "slides/30-multiple-regression/hedonic-regression.html#loading-data",
    "title": "Hedonic model",
    "section": "Loading data",
    "text": "Loading data\n\n\nCode\ndta <- \n  alr4::MinnLand %>% \n  as_tibble()  %>%\n  # filter(year == 2007) %>% \n  select(acrePrice, acres, region, year, \n         tillable, crpPct, productivity)\nglimpse(dta)\n\n\nRows: 18,700\nColumns: 7\n$ acrePrice    <dbl> 766, 733, 850, 975, 886, 992, 623, 1382, 855, 364, 807, 4…\n$ acres        <int> 82, 30, 150, 160, 90, 120, 170, 100, 120, 160, 158, 83, 1…\n$ region       <fct> Northwest, Northwest, Northwest, Northwest, Northwest, No…\n$ year         <dbl> 2002, 2003, 2002, 2003, 2002, 2003, 2003, 2003, 2003, 200…\n$ tillable     <dbl> 94, 63, 47, 86, NA, 83, 42, 35, 46, 10, 29, 36, 14, 71, 9…\n$ crpPct       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ productivity <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…"
  },
  {
    "objectID": "slides/30-multiple-regression/hedonic-regression.html#summary-statistics-12",
    "href": "slides/30-multiple-regression/hedonic-regression.html#summary-statistics-12",
    "title": "Hedonic model",
    "section": "Summary statistics (1/2)",
    "text": "Summary statistics (1/2)\n\n\nCode\ndta %>%\n  mutate(id = row_number()) %>% \n  pivot_longer(\n    cols = c(acrePrice, acres, year, tillable, crpPct, productivity),\n    names_to = \"var\",\n    values_to = \"val\"\n  ) %>% \n  group_by(var) %>% \n  summarise(across(\n    c(val),\n    list(\n      mean = ~ mean(.x, na.rm = TRUE),\n      sd = ~ sd(.x, na.rm = TRUE),\n      meadian = ~ median(.x, na.rm = TRUE),\n      n_miss = ~ sum(is.na(.x), na.rm = TRUE),\n      min = ~ min(.x, na.rm = TRUE),\n      max = ~ max(.x, na.rm = TRUE)\n    )\n  ), \n  n = n())\n\n\n# A tibble: 6 × 8\n  var          val_mean  val_sd val_meadian val_n_miss val_min val_max     n\n  <chr>           <dbl>   <dbl>       <dbl>      <int>   <dbl>   <dbl> <int>\n1 acrePrice     2787.   1914.          2442          0     108   15000 18700\n2 acres          113.    128.            80          0       1    6970 18700\n3 crpPct           4.16   17.2            0          0       0     100 18700\n4 productivity    66.6    13.5           68       9717       1      99 18700\n5 tillable        80.7    22.8           92       1212       0     100 18700\n6 year          2006.      2.51        2006          0    2002    2011 18700"
  },
  {
    "objectID": "slides/30-multiple-regression/hedonic-regression.html#summary-statistics-22",
    "href": "slides/30-multiple-regression/hedonic-regression.html#summary-statistics-22",
    "title": "Hedonic model",
    "section": "Summary statistics (2/2)",
    "text": "Summary statistics (2/2)\n\n\nCode\ndta %>% datasummary_skim(output = \"data.frame\")\n\n\n               Unique (#) Missing (%)   Mean     SD    Min Median     Max\n1    acrePrice       5696           0 2787.3 1914.0  108.0 2442.0 15000.0\n2        acres        596           0  112.7  128.5    1.0   80.0  6970.0\n3         year         10           0 2006.4    2.5 2002.0 2006.0  2011.0\n4     tillable        102           6   80.7   22.8    0.0   92.0   100.0\n5       crpPct        101           0    4.2   17.2    0.0    0.0   100.0\n6 productivity         96          52   66.6   13.5    1.0   68.0    99.0"
  },
  {
    "objectID": "slides/30-multiple-regression/hedonic-regression.html#visual-inspection-scatter-plots",
    "href": "slides/30-multiple-regression/hedonic-regression.html#visual-inspection-scatter-plots",
    "title": "Hedonic model",
    "section": "Visual inspection: scatter plots",
    "text": "Visual inspection: scatter plots\n\n\nCode\ndta %>%\n  select(acrePrice, acres, tillable, \n         crpPct, productivity) %>%\n  ggpairs(aes(alpha = 0.5)) +\n  theme_bw()"
  },
  {
    "objectID": "slides/30-multiple-regression/hedonic-regression.html#regression.-summary",
    "href": "slides/30-multiple-regression/hedonic-regression.html#regression.-summary",
    "title": "Hedonic model",
    "section": "Regression. Summary",
    "text": "Regression. Summary\n\n\nCode\nfit1 <- lm(\n  acrePrice ~ crpPct + acres + region + \n    year + tillable + productivity, \n  data = dta\n)\nsummary(fit1)\n\n\n\nCall:\nlm(formula = acrePrice ~ crpPct + acres + region + year + tillable + \n    productivity, data = dta)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3663.2  -572.0  -132.8   356.3 11029.3 \n\nCoefficients:\n                      Estimate Std. Error t value Pr(>|t|)    \n(Intercept)         -6.476e+05  9.554e+03 -67.781   <2e-16 ***\ncrpPct              -8.288e+00  8.693e-01  -9.534   <2e-16 ***\nacres               -1.166e+00  1.337e-01  -8.720   <2e-16 ***\nregionWest Central   9.474e+02  4.703e+01  20.145   <2e-16 ***\nregionCentral        1.798e+03  5.234e+01  34.357   <2e-16 ***\nregionSouth West     1.257e+03  4.727e+01  26.595   <2e-16 ***\nregionSouth Central  1.669e+03  5.070e+01  32.923   <2e-16 ***\nregionSouth East     1.939e+03  5.875e+01  33.002   <2e-16 ***\nyear                 3.230e+02  4.764e+00  67.792   <2e-16 ***\ntillable            -2.502e+00  7.881e-01  -3.175   0.0015 ** \nproductivity         2.445e+01  1.078e+00  22.686   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1079 on 8776 degrees of freedom\n  (9913 observations deleted due to missingness)\nMultiple R-squared:  0.5179,    Adjusted R-squared:  0.5174 \nF-statistic: 942.8 on 10 and 8776 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "slides/30-multiple-regression/hedonic-regression.html#regression.-interpretation-of-the-coefficients",
    "href": "slides/30-multiple-regression/hedonic-regression.html#regression.-interpretation-of-the-coefficients",
    "title": "Hedonic model",
    "section": "Regression. Interpretation of the coefficients",
    "text": "Regression. Interpretation of the coefficients\n\nparameters(fit1)\n\nParameter              | Coefficient |      SE |                   95% CI | t(8776) |      p\n--------------------------------------------------------------------------------------------\n(Intercept)            |   -6.48e+05 | 9553.71 | [ -6.66e+05,  -6.29e+05] |  -67.78 | < .001\ncrpPct                 |       -8.29 |    0.87 | [     -9.99,      -6.58] |   -9.53 | < .001\nacres                  |       -1.17 |    0.13 | [     -1.43,      -0.90] |   -8.72 | < .001\nregion [West Central]  |      947.38 |   47.03 | [    855.19,    1039.56] |   20.15 | < .001\nregion [Central]       |     1798.21 |   52.34 | [   1695.61,    1900.81] |   34.36 | < .001\nregion [South West]    |     1257.17 |   47.27 | [   1164.51,    1349.83] |   26.60 | < .001\nregion [South Central] |     1669.12 |   50.70 | [   1569.74,    1768.50] |   32.92 | < .001\nregion [South East]    |     1938.87 |   58.75 | [   1823.71,    2054.04] |   33.00 | < .001\nyear                   |      322.97 |    4.76 | [    313.63,     332.30] |   67.79 | < .001\ntillable               |       -2.50 |    0.79 | [     -4.05,      -0.96] |   -3.18 | 0.002 \nproductivity           |       24.45 |    1.08 | [     22.33,      26.56] |   22.69 | < .001"
  },
  {
    "objectID": "slides/30-multiple-regression/hedonic-regression.html#checking-linearity-13",
    "href": "slides/30-multiple-regression/hedonic-regression.html#checking-linearity-13",
    "title": "Hedonic model",
    "section": "Checking Linearity 1/3",
    "text": "Checking Linearity 1/3\n\ncheck_model(fit1, check = \"linearity\", panel = FALSE)\n\n$NCV"
  },
  {
    "objectID": "slides/30-multiple-regression/hedonic-regression.html#checking-linearity-23",
    "href": "slides/30-multiple-regression/hedonic-regression.html#checking-linearity-23",
    "title": "Hedonic model",
    "section": "Checking Linearity 2/3",
    "text": "Checking Linearity 2/3\n\nresidualPlots(fit1, plot = FALSE)\n\n             Test stat Pr(>|Test stat|)    \ncrpPct          3.8991        9.727e-05 ***\nacres           7.0230        2.334e-12 ***\nregion                                     \nyear            2.0206          0.04335 *  \ntillable        4.9822        6.407e-07 ***\nproductivity   11.1526        < 2.2e-16 ***\nTukey test     11.0991        < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "slides/30-multiple-regression/hedonic-regression.html#checking-linearity-33",
    "href": "slides/30-multiple-regression/hedonic-regression.html#checking-linearity-33",
    "title": "Hedonic model",
    "section": "Checking Linearity 3/3",
    "text": "Checking Linearity 3/3\n\n\nCode\nresidualPlots(fit1, test = FALSE, layout = c(2, 2), ask = FALSE)"
  },
  {
    "objectID": "slides/30-multiple-regression/hedonic-regression.html#takeaway",
    "href": "slides/30-multiple-regression/hedonic-regression.html#takeaway",
    "title": "Hedonic model",
    "section": "Takeaway",
    "text": "Takeaway\n\nMultiple linear regression\nHedonic model\nSlope and Intercept (interpretation)\nResiduals vs Fitted"
  },
  {
    "objectID": "slides/30-multiple-regression/hedonic-regression.html#references-1",
    "href": "slides/30-multiple-regression/hedonic-regression.html#references-1",
    "title": "Hedonic model",
    "section": "References",
    "text": "References\n\n\n\nhttps://ebukin.github.io/mp223-2022-aem-R-public/\n\n\n\nPalmquist, Raymond B. 1989. “Land as a Differentiated Factor of Production: A Hedonic Model and Its Implications for Welfare Measurement.” Land Economics 65 (1): 23. https://doi.org/10.2307/3146260.\n\n\nTaff, Steven J, and Sanford Weisberg. 2007. “Compensated Short-Term Conservation Restrictions May Reduce Sale Prices.” Appraisal Journal 75 (1)."
  },
  {
    "objectID": "slides/30-multiple-regression/multiple-regression.html#research-question",
    "href": "slides/30-multiple-regression/multiple-regression.html#research-question",
    "title": "Multiple Lnear Regression",
    "section": "Research question",
    "text": "Research question\nHow GDP per capita \\(ppgdp\\) and degree of Urbanization \\(pctUrban\\) affects \\(fertility\\)?\n\nWe explore UN11 data from (Weisberg 2005). 199 observations. - Variables are:\n-   `fertility` - number of children per woman;\n-   `lifeExpF` - Female life expectancy, years;\n-   `ppgdp` - Per capita gross domestic product in US dollars;\n-   `pctUrban` - Percent of Urban population;\n-   `group` - variable with 3 values \"oecd\", \"africa\" and \"others\";"
  },
  {
    "objectID": "slides/30-multiple-regression/multiple-regression.html#data-loading",
    "href": "slides/30-multiple-regression/multiple-regression.html#data-loading",
    "title": "Multiple Lnear Regression",
    "section": "Data loading",
    "text": "Data loading\n\n\nCode\nlibrary(alr4)           #install.packages(\"alr4\")\nlibrary(tidyverse)      #install.packages(\"tidyverse\")\nun_dta <- \n  alr4::UN11 %>%\n  as_tibble() %>%\n  select(-region)\nglimpse(un_dta)\n\n\nRows: 199\nColumns: 5\n$ group     <fct> other, other, africa, africa, other, other, other, other, oe…\n$ fertility <dbl> 5.968, 1.525, 2.142, 5.135, 2.000, 2.172, 1.735, 1.671, 1.94…\n$ ppgdp     <dbl> 499.0, 3677.2, 4473.0, 4321.9, 13750.1, 9162.1, 3030.7, 2285…\n$ lifeExpF  <dbl> 49.49, 80.40, 75.00, 53.17, 81.10, 79.89, 77.33, 77.75, 84.2…\n$ pctUrban  <dbl> 23, 53, 67, 59, 100, 93, 64, 47, 89, 68, 52, 84, 89, 29, 45,…"
  },
  {
    "objectID": "slides/30-multiple-regression/multiple-regression.html#regression",
    "href": "slides/30-multiple-regression/multiple-regression.html#regression",
    "title": "Multiple Lnear Regression",
    "section": "Regression",
    "text": "Regression\n\n\nCode\nfit1 <- lm(fertility ~ ppgdp + pctUrban , un_dta)\nfit1\n\n\n\nCall:\nlm(formula = fertility ~ ppgdp + pctUrban, data = un_dta)\n\nCoefficients:\n(Intercept)        ppgdp     pctUrban  \n  4.374e+00   -1.305e-05   -2.491e-02"
  },
  {
    "objectID": "slides/30-multiple-regression/multiple-regression.html#reg.-summary-base-r",
    "href": "slides/30-multiple-regression/multiple-regression.html#reg.-summary-base-r",
    "title": "Multiple Lnear Regression",
    "section": "Reg. summary base R",
    "text": "Reg. summary base R\n\nsummary(fit1)\n\n\nCall:\nlm(formula = fertility ~ ppgdp + pctUrban, data = un_dta)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.19513 -0.81326 -0.09851  0.61527  2.97892 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  4.374e+00  2.244e-01  19.489  < 2e-16 ***\nppgdp       -1.304e-05  5.366e-06  -2.431    0.016 *  \npctUrban    -2.491e-02  4.217e-03  -5.907 1.51e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.114 on 196 degrees of freedom\nMultiple R-squared:  0.3155,    Adjusted R-squared:  0.3085 \nF-statistic: 45.16 on 2 and 196 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "slides/30-multiple-regression/multiple-regression.html#reg.-summary-coef.-parametersparameters",
    "href": "slides/30-multiple-regression/multiple-regression.html#reg.-summary-coef.-parametersparameters",
    "title": "Multiple Lnear Regression",
    "section": "Reg. summary; Coef. parameters::parameters()",
    "text": "Reg. summary; Coef. parameters::parameters()\nSee: easystats/parameters\n\nlibrary(parameters)\nparameters(fit1)\n\nParameter   | Coefficient |       SE |         95% CI | t(196) |      p\n-----------------------------------------------------------------------\n(Intercept) |        4.37 |     0.22 | [ 3.93,  4.82] |  19.49 | < .001\nppgdp       |   -1.30e-05 | 5.37e-06 | [ 0.00,  0.00] |  -2.43 | 0.016 \npctUrban    |       -0.02 | 4.22e-03 | [-0.03, -0.02] |  -5.91 | < .001"
  },
  {
    "objectID": "slides/30-multiple-regression/multiple-regression.html#reg.-summary-gof-performanceperformance",
    "href": "slides/30-multiple-regression/multiple-regression.html#reg.-summary-gof-performanceperformance",
    "title": "Multiple Lnear Regression",
    "section": "Reg. summary: GOF performance::performance()",
    "text": "Reg. summary: GOF performance::performance()\nSee: easystats/performance\n\nlibrary(performance)\nperformance(fit1)\n\n# Indices of model performance\n\nAIC     |     BIC |    R2 | R2 (adj.) |  RMSE | Sigma\n-----------------------------------------------------\n612.669 | 625.842 | 0.315 |     0.308 | 1.106 | 1.114"
  },
  {
    "objectID": "slides/30-multiple-regression/multiple-regression.html#reg.-summary-broom",
    "href": "slides/30-multiple-regression/multiple-regression.html#reg.-summary-broom",
    "title": "Multiple Lnear Regression",
    "section": "Reg. summary: broom",
    "text": "Reg. summary: broom\nSee: tidymodels/broom\n\nlibrary(broom)\ntidy(fit1)\n\n# A tibble: 3 × 5\n  term          estimate  std.error statistic  p.value\n  <chr>            <dbl>      <dbl>     <dbl>    <dbl>\n1 (Intercept)  4.37      0.224          19.5  9.49e-48\n2 ppgdp       -0.0000130 0.00000537     -2.43 1.60e- 2\n3 pctUrban    -0.0249    0.00422        -5.91 1.51e- 8\n\nglance(fit1)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC\n      <dbl>         <dbl> <dbl>     <dbl>    <dbl> <dbl>  <dbl> <dbl> <dbl>\n1     0.315         0.308  1.11      45.2 7.38e-17     2  -302.  613.  626.\n# … with 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>"
  },
  {
    "objectID": "slides/30-multiple-regression/multiple-regression.html#fitted-values",
    "href": "slides/30-multiple-regression/multiple-regression.html#fitted-values",
    "title": "Multiple Lnear Regression",
    "section": "Fitted values",
    "text": "Fitted values\n\nfitted(fit1)\n\n        1         2         3         4         5         6         7         8 \n3.7947689 3.0059609 2.6468172 2.8480812 1.7037141 1.9379459 2.7403669 2.9053011 \n        9        10        11        12        13        14        15        16 \n1.4119940 2.0911577 3.0052991 1.9886579 1.9199000 3.6430633 3.0641052 2.4314920 \n       17        18        19        20        21        22        23        24 \n1.3862537 2.9952823 3.3182902 0.6747918 3.4756333 2.6793659 3.0951648 2.7331546 \n       25        26        27        28        29        30        31        32 \n2.0671501 2.0550740 2.4975767 3.6948524 4.0979139 3.8656137 2.8887204 1.7516254 \n       33        34        35        36        37        38        39        40 \n2.7874076 1.1388925 3.3968120 3.6672314 2.0020368 3.1216901 2.4246981 3.6671114 \n       41        42        43        44        45        46        47        48 \n2.7700478 2.3216559 2.6544945 3.0886981 2.7490962 2.4314607 2.2355078 2.2850335 \n       49        50        51        52        53        54        55        56 \n3.4748106 1.4786284 2.4642316 2.6135811 2.5626587 3.6425976 2.6271288 3.2435170 \n       57        58        59        60        61        62        63        64 \n2.7103038 3.1579408 3.8205923 2.4460360 3.9465136 3.0325880 1.6762323 1.7159693 \n       65        66        67        68        69        70        71        72 \n2.7819453 2.0691912 2.8969061 3.0189655 2.0108490 3.0614501 2.4839826 1.8212757 \n       73        74        75        76        77        78        79        80 \n3.2808694 3.0910653 3.4718507 3.6198606 3.6127258 3.0210259 3.0524099 1.4679432 \n       81        82        83        84        85        86        87        88 \n2.5121838 1.5201712 3.6085506 3.2147493 2.5373335 2.7184888 2.2267800 1.7000065 \n       89        90        91        92        93        94        95        96 \n2.2134163 3.0149341 2.1423929 2.3482393 2.7848806 3.7908188 3.2589819 1.3402665 \n       97        98        99       100       101       102       103       104 \n3.4910499 3.5135847 2.5411568 2.0858293 3.6639271 3.1756366 2.2834597 2.5619918 \n      105       106       107       108       109       110       111       112 \n0.8857851 1.2309605 3.5964818 3.8713509 2.4464745 3.2917600 3.4447045 1.7519703 \n      113       114       115       116       117       118       119       120 \n2.5405692 3.3132026 3.2302727 2.3124210 3.7663411 3.1572796 2.7755058 2.7697167 \n      121       122       123       124       125       126       127       128 \n2.8670865 3.3973768 3.5158206 3.3358407 1.8023346 3.8939496 1.7923763 1.6946431 \n      129       130       131       132       133       134       135       136 \n2.4935395 1.8095518 2.9146065 3.9460818 3.0875801 2.8729742 1.2778538 2.2844786 \n      137       138       139       140       141       142       143       144 \n3.4643407 2.1404996 2.5070510 2.4065499 4.0317609 2.7935766 2.3854688 3.1256589 \n      145       146       147       148       149       150       151       152 \n2.6946634 2.5749830 1.5628115 1.0382976 2.0319552 2.8312421 2.4206636 3.8939809 \n      153       154       155       156       157       158       159       160 \n3.5896173 3.8323997 2.7880734 2.1249136 3.2895746 2.9123630 2.8298218 3.3981047 \n      161       162       163       164       165       166       167       168 \n1.3119324 2.7956994 2.8521083 3.8853555 3.4261067 2.7350866 2.0327080 3.9944969 \n      169       170       171       172       173       174       175       176 \n3.0481549 3.3290636 2.5388828 3.8079068 1.6187754 1.6322415 2.9409538 3.7158988 \n      177       178       179       180       181       182       183       184 \n3.6949007 2.8466123 3.4670765 3.2712912 3.7301469 3.8271317 2.6251786 2.4987419 \n      185       186       187       188       189       190       191       192 \n3.0688209 3.0621762 4.0437545 2.6157528 1.7647646 1.9074322 1.6993888 1.9015464 \n      193       194       195       196       197       198       199 \n3.4588083 3.6878846 1.8564110 3.5865571 3.5583256 3.4612803 3.3952165"
  },
  {
    "objectID": "slides/30-multiple-regression/multiple-regression.html#residuals",
    "href": "slides/30-multiple-regression/multiple-regression.html#residuals",
    "title": "Multiple Lnear Regression",
    "section": "Residuals",
    "text": "Residuals\n\nresid(fit1)\n\n          1           2           3           4           5           6 \n 2.17323111 -1.48096095 -0.50481721  2.28691883  0.29628594  0.23405405 \n          7           8           9          10          11          12 \n-1.00536689 -1.23430108  0.53700600 -0.74515772 -0.85729906 -0.11165790 \n         13          14          15          16          17          18 \n 0.51009998 -1.48606333 -1.48910516 -0.95249201  0.44874633 -0.31628228 \n         19          20          21          22          23          24 \n 1.75970984  1.08520825 -1.21763328  0.54963411 -1.96116482 -0.11615458 \n         25          26          27          28          29          30 \n-0.26715012 -0.07107397 -0.95157666  2.05514757 -0.04691388 -1.44361367 \n         31          32          33          34          35          36 \n 1.39827962 -0.06062539 -0.50840760  0.46110747  1.02618805  2.06976863 \n         37          38          39          40          41          42 \n-0.17003681 -1.56269009 -0.13169815  1.07488865  1.67195223  0.20915040 \n         43          44          45          46          47          48 \n-0.84249451  1.13530190 -1.24809620 -0.98046070 -0.77750782 -0.78403353 \n         49          50          51          52          53          54 \n 2.01018936  0.40637164  1.12476835  0.38641894 -0.07265866  2.27540238 \n         55          56          57          58          59          60 \n-0.23412884 -0.60751700 -0.53930380  1.82205918  0.42240766 -0.74403600 \n         61          62          63          64          65          66 \n-0.09851358 -0.43058797  0.19876769  0.27103069 -0.74894529  1.12580884 \n         67          68          69          70          71          72 \n 1.79209386 -1.49096555 -0.55384897  0.92654987 -0.94398258  0.39572432 \n         73          74          75          76          77          78 \n-1.10986945  0.74893473  1.56014928  1.25713938 -1.42272578  0.13797414 \n         79          80          81          82          83          84 \n-0.05640991 -0.33094322 -1.08218377  0.57782878 -1.07055057 -1.15974928 \n         85          86          87          88          89          90 \n-0.95033352  1.81651124 -0.12978005  1.20899348 -0.73741634 -0.75293412 \n         91          92          93          94          95          96 \n-0.72439291  0.54076072 -0.30388056  0.83218115  0.24101810  0.91073351 \n         97          98          99         100         101         102 \n-0.87004991 -0.97058471 -1.03515681 -0.32182931 -0.61292706  1.86236345 \n        103         104         105         106         107         108 \n 0.12654028 -1.06699184  0.79721493 -0.06796051  0.89651819  2.09664912 \n        109         110         111         112         113         114 \n 0.12552547 -1.62375995  2.67229550 -0.46797035  1.84389706  1.04779741 \n        115         116         117         118         119         120 \n-1.64027267 -0.08542101 -0.45934113 -1.70727957 -0.32950581 -1.13971671 \n        121         122         123         124         125         126 \n-0.68408649  1.31562320 -1.57682063 -0.28084074  1.49766544 -1.30694960 \n        127         128         129         130         131         132 \n 0.10762365  0.09935694 -0.40253945  0.32544818 -0.41460645  2.97891821 \n        133         134         135         136         137         138 \n 2.34341986 -0.88497422  0.67014618 -0.13847861 -0.26334069 -0.14049955 \n        139         140         141         142         143         144 \n 1.76294902  0.00245011 -0.23276089  0.06442340  0.02453119 -0.07565890 \n        145         146         147         148         149         150 \n-1.27966338 -1.26298297  0.19418853  1.16570241 -0.64295518 -1.40324213 \n        151         152         153         154         155         156 \n-0.89166361  1.38801909 -1.68261729 -0.06939970  0.69992660  0.51408637 \n        157         158         159         160         161         162 \n 1.31542538 -1.35036300 -0.48982181  1.32989528  0.05506763 -1.42369940 \n        163         164         165         166         167         168 \n-1.37510833  0.15564447  2.85689331 -0.35208655 -0.52870796 -1.75949694 \n        169         170         171         172         173         174 \n-1.05315491  0.89593645 -0.27288277 -0.63390684  0.30622457 -0.09624147 \n        175         176         177         178         179         180 \n-0.16895381 -0.55389879  1.80409931 -1.44961230 -1.93907653  0.59270880 \n        181         182         183         184         185         186 \n 0.05285313 -2.19513168 -0.71617861 -0.47674187 -0.75282087  0.63782377 \n        187         188         189         190         191         192 \n 1.85724550 -1.13275277 -0.05776457 -0.04043224  0.37761115  0.14145363 \n        193         194         195         196         197         198 \n-1.19480829  0.06211543  0.53458896 -1.83655714  1.37967443  2.83871967 \n        199 \n-0.28621654"
  },
  {
    "objectID": "slides/30-multiple-regression/multiple-regression.html#residuals-vs-fitted",
    "href": "slides/30-multiple-regression/multiple-regression.html#residuals-vs-fitted",
    "title": "Multiple Lnear Regression",
    "section": "Residuals vs Fitted",
    "text": "Residuals vs Fitted\nSee: easystats/performance + check_model help\n\n\nCode\ncheck_model(fit1, check = \"linearity\", panel = FALSE)\n\n\n$NCV"
  },
  {
    "objectID": "slides/30-multiple-regression/multiple-regression.html#predicted-values",
    "href": "slides/30-multiple-regression/multiple-regression.html#predicted-values",
    "title": "Multiple Lnear Regression",
    "section": "Predicted values",
    "text": "Predicted values\n\n\nSee: strengejacke.github.io/ggeffects\n\n\nCode\nlibrary(ggeffects)\nggpredict(fit1, terms = \"ppgdp\")\n\n\n# Predicted values of fertility\n\n ppgdp | Predicted |       95% CI\n---------------------------------\n     0 |      2.93 | [2.72, 3.14]\n 15000 |      2.74 | [2.58, 2.89]\n 25000 |      2.60 | [2.41, 2.80]\n 40000 |      2.41 | [2.09, 2.73]\n 55000 |      2.21 | [1.75, 2.68]\n 70000 |      2.02 | [1.40, 2.64]\n 85000 |      1.82 | [1.05, 2.60]\n110000 |      1.50 | [0.46, 2.53]\n\nAdjusted for:\n* pctUrban = 57.93\n\n\n\n\n\nCode\nfit2 <- lm(fertility ~ ppgdp + pctUrban + group, un_dta)\nggpredict(fit2, terms = c(\"ppgdp\", \"group\")) %>% plot()"
  },
  {
    "objectID": "slides/30-multiple-regression/multiple-regression.html#sampling-from-the-population",
    "href": "slides/30-multiple-regression/multiple-regression.html#sampling-from-the-population",
    "title": "Multiple Lnear Regression",
    "section": "Sampling from the population",
    "text": "Sampling from the population"
  },
  {
    "objectID": "slides/30-multiple-regression/multiple-regression.html#unbiased-and-efficient",
    "href": "slides/30-multiple-regression/multiple-regression.html#unbiased-and-efficient",
    "title": "Multiple Lnear Regression",
    "section": "Unbiased and efficient",
    "text": "Unbiased and efficient\n\n1 sample2 samples10 samples500 samples"
  },
  {
    "objectID": "slides/30-multiple-regression/multiple-regression.html#unbiased-but-inefficient",
    "href": "slides/30-multiple-regression/multiple-regression.html#unbiased-but-inefficient",
    "title": "Multiple Lnear Regression",
    "section": "Unbiased but inefficient",
    "text": "Unbiased but inefficient"
  },
  {
    "objectID": "slides/30-multiple-regression/multiple-regression.html#biased-but-efficient",
    "href": "slides/30-multiple-regression/multiple-regression.html#biased-but-efficient",
    "title": "Multiple Lnear Regression",
    "section": "Biased but efficient",
    "text": "Biased but efficient"
  },
  {
    "objectID": "slides/30-multiple-regression/multiple-regression.html#biased-and-inefficient",
    "href": "slides/30-multiple-regression/multiple-regression.html#biased-and-inefficient",
    "title": "Multiple Lnear Regression",
    "section": "Biased and inefficient",
    "text": "Biased and inefficient"
  },
  {
    "objectID": "slides/30-multiple-regression/multiple-regression.html#all-four-cases",
    "href": "slides/30-multiple-regression/multiple-regression.html#all-four-cases",
    "title": "Multiple Lnear Regression",
    "section": "All four cases",
    "text": "All four cases"
  },
  {
    "objectID": "slides/30-multiple-regression/multiple-regression.html#assumptions-what-why-blue",
    "href": "slides/30-multiple-regression/multiple-regression.html#assumptions-what-why-blue",
    "title": "Multiple Lnear Regression",
    "section": "Assumptions? What? Why? BLUE?",
    "text": "Assumptions? What? Why? BLUE?\n\n\nOLS is unbiased (Gauss-Markov Theorem), when assumptions 1 to 4 are satisfied:\n\nLinearity\nRandom Sampling\nNo Collinearity\nNo Endogeneity\n\nOLS is BLUE (Gauss-Markov Theorem). AKA (Best Linear Unbiased Estimator or unbiased and efficient), when assumptions 1 to 4 + 5 are satisfied\n\nHomoscedasticity (No Autocorrelation)\n\nOLS is a Classical linear model (CLM), when assumptions 1 to 5 + 6 are satisfied\n\nError Terms Normality"
  },
  {
    "objectID": "slides/30-multiple-regression/multiple-regression.html#overview",
    "href": "slides/30-multiple-regression/multiple-regression.html#overview",
    "title": "Multiple Lnear Regression",
    "section": "Overview",
    "text": "Overview\n\n\\[y = \\hat {\\beta}_{0} + \\hat {\\beta}_{1}x_1 + \\hat {\\beta}_{2}x_2 + \\hat {\\beta}_{3}x_3 + \\cdots + \\hat {\\beta}_{k}x_k + \\hat u\\]\n\n\\(\\hat u\\) - Error term, or disturbance containing factors other than \\(x_1, x_2, \\cdots, x_k\\) that affect \\(y\\)\n\\(\\hat {\\beta}_{0}\\) - intercept (constant term);\n\\(\\hat {\\beta}_{1}\\), \\(\\hat {\\beta}_{2}\\), \\(\\hat {\\beta}_{k}\\) - coefficients / parameters associated with \\(x_1\\), \\(x_2\\), … \\(x_k\\);\n\\(k\\) - entire set of independent variables;"
  },
  {
    "objectID": "slides/30-multiple-regression/multiple-regression.html#motivation",
    "href": "slides/30-multiple-regression/multiple-regression.html#motivation",
    "title": "Multiple Lnear Regression",
    "section": "Motivation",
    "text": "Motivation\n\n\nTo incorporate more explanatory factors into a model;\nExplicitly hold fixed (some) other factors;\nAllow for more flexible functional forms;"
  },
  {
    "objectID": "slides/30-multiple-regression/multiple-regression.html#interpretation",
    "href": "slides/30-multiple-regression/multiple-regression.html#interpretation",
    "title": "Multiple Lnear Regression",
    "section": "Interpretation",
    "text": "Interpretation\n\nThe multiple linear regression shows the effect of each variable, holding other explanatory variables fixed;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\nWe assume that all unobserved factors do not change if the explanatory variables are changed."
  },
  {
    "objectID": "slides/30-multiple-regression/multiple-regression.html#examples-of-the-multiple-regression",
    "href": "slides/30-multiple-regression/multiple-regression.html#examples-of-the-multiple-regression",
    "title": "Multiple Lnear Regression",
    "section": "Examples of the multiple regression",
    "text": "Examples of the multiple regression"
  },
  {
    "objectID": "slides/30-multiple-regression/heteroscedasticity.html#assumption-5.-error-terms-homoscedasticity",
    "href": "slides/30-multiple-regression/heteroscedasticity.html#assumption-5.-error-terms-homoscedasticity",
    "title": "Heteroscedasticity",
    "section": "Assumption 5. Error Terms Homoscedasticity",
    "text": "Assumption 5. Error Terms Homoscedasticity\n\\[Var(u|x_{i1}, x_{i2}, \\cdots , x_{ik}) = \\sigma^2\\]"
  },
  {
    "objectID": "slides/30-multiple-regression/heteroscedasticity.html#data",
    "href": "slides/30-multiple-regression/heteroscedasticity.html#data",
    "title": "Heteroscedasticity",
    "section": "Data",
    "text": "Data\n\n\nCode\nwoolwage2 <-\n  wooldridge::wage2 %>%\n  as_tibble %>%\n  select(wage, educ, tenure, abil = KWW)\nglimpse(woolwage2)\n\n\nRows: 935\nColumns: 4\n$ wage   <int> 769, 808, 825, 650, 562, 1400, 600, 1081, 1154, 1000, 930, 921,…\n$ educ   <int> 12, 18, 14, 12, 11, 16, 10, 18, 15, 12, 18, 14, 15, 16, 16, 10,…\n$ tenure <int> 2, 16, 9, 7, 5, 2, 0, 14, 1, 16, 13, 11, 3, 2, 9, 2, 9, 10, 7, …\n$ abil   <int> 35, 41, 46, 32, 27, 43, 24, 50, 37, 44, 44, 45, 40, 24, 47, 37,…\n\n\nCode\nreport(woolwage2) %>% as_tibble()\n\n\n# A tibble: 4 × 11\n  Variable n_Obs   Mean     SD Median    MAD   Min   Max Skewness Kurtosis\n  <chr>    <int>  <dbl>  <dbl>  <int>  <dbl> <int> <int>    <dbl>    <dbl>\n1 wage       935 958.   404.      905 369.     115  3078    1.20     2.72 \n2 educ       935  13.5    2.20     12   1.48     9    18    0.549   -0.735\n3 tenure     935   7.23   5.08      7   5.93     0    22    0.433   -0.799\n4 abil       935  35.7    7.64     37   7.41    12    56   -0.293   -0.317\n# … with 1 more variable: percentage_Missing <dbl>"
  },
  {
    "objectID": "slides/30-multiple-regression/heteroscedasticity.html#the-model",
    "href": "slides/30-multiple-regression/heteroscedasticity.html#the-model",
    "title": "Heteroscedasticity",
    "section": "The model",
    "text": "The model\n\n\nCode\nfit_1 <- lm(wage ~ educ + abil, data = woolwage2)\nscreen_many_regs(fit_1, single.row = F)\n\n\n\n=========================\n             Model 1     \n-------------------------\n(Intercept)  -71.0911    \n             (81.5735)   \neduc          43.4601 ***\n              (6.0189)   \nabil          12.4130 ***\n              (1.7308)   \n-------------------------\nR^2            0.1537    \nAdj. R^2       0.1519    \nNum. obs.    935         \nNum. df      932         \nF statistic   84.6348 ***\n=========================\n*** p < 0.001; ** p < 0.01; * p < 0.05"
  },
  {
    "objectID": "slides/30-multiple-regression/heteroscedasticity.html#visual-diagnostics",
    "href": "slides/30-multiple-regression/heteroscedasticity.html#visual-diagnostics",
    "title": "Heteroscedasticity",
    "section": "Visual diagnostics:",
    "text": "Visual diagnostics:\n\nlibrary(performance)\ncheck_model(fit_1, check = \"linearity\") %>% plot()"
  },
  {
    "objectID": "slides/30-multiple-regression/heteroscedasticity.html#statistical-tests",
    "href": "slides/30-multiple-regression/heteroscedasticity.html#statistical-tests",
    "title": "Heteroscedasticity",
    "section": "Statistical tests",
    "text": "Statistical tests\n\nlibrary(performance)\ncheck_heteroscedasticity(fit_1)\n\nWarning: Heteroscedasticity (non-constant error variance) detected (p < .001).\n\n\n\n\\(H_0\\) error terms are homoscedastic.\n\\(H_1\\) we have heteroscedastic error terms.\nWe reject \\(H_0\\) if p-value < 0.05 (at 5% significance level)."
  },
  {
    "objectID": "slides/30-multiple-regression/heteroscedasticity.html#conclusions-on-heteroskedasticity-in-the-wage-equation",
    "href": "slides/30-multiple-regression/heteroscedasticity.html#conclusions-on-heteroskedasticity-in-the-wage-equation",
    "title": "Heteroscedasticity",
    "section": "Conclusions on Heteroskedasticity in the wage equation",
    "text": "Conclusions on Heteroskedasticity in the wage equation\n\nWe have:\n\nHeteroskedasticity;\nInappropriate model specification;\nPossible linearity assumption violation;\n\nSolutions:\n\nModel re-specification;\nCorrecting standard errors;"
  },
  {
    "objectID": "slides/30-multiple-regression/heteroscedasticity.html#model-adjustment",
    "href": "slides/30-multiple-regression/heteroscedasticity.html#model-adjustment",
    "title": "Heteroscedasticity",
    "section": "Model adjustment:",
    "text": "Model adjustment:\n\n\nCode\nfit_1 <- lm(wage ~ educ + abil, data = woolwage2)\nfit_2 <- lm(log(wage) ~ educ + abil , data = woolwage2)\nfit_3 <- lm(log(wage) ~ educ + abil + tenure , data = woolwage2)\nscreen_many_regs(fit_1, fit_2, fit_3, single.row = T)\n\n\n\n=================================================================================\n             Model 1                 Model 2                Model 3              \n---------------------------------------------------------------------------------\n(Intercept)  -71.0911 (81.5735)        5.7620 (0.0858) ***    5.6751 (0.0859) ***\neduc          43.4601  (6.0189) ***    0.0436 (0.0063) ***    0.0471 (0.0063) ***\nabil          12.4130  (1.7308) ***    0.0120 (0.0018) ***    0.0103 (0.0018) ***\ntenure                                                        0.0140 (0.0025) ***\n---------------------------------------------------------------------------------\nR^2            0.1537                  0.1378                 0.1652             \nAdj. R^2       0.1519                  0.1359                 0.1625             \nNum. obs.    935                     935                    935                  \nNum. df      932                     932                    931                  \nF statistic   84.6348 ***             74.4578 ***            61.4301 ***         \n=================================================================================\n*** p < 0.001; ** p < 0.01; * p < 0.05\nModel 1 wage ~ educ + abil\nModel 2 log(wage) ~ educ + abil\nModel 3 log(wage) ~ educ + abil + tenure"
  },
  {
    "objectID": "slides/30-multiple-regression/heteroscedasticity.html#conclusions",
    "href": "slides/30-multiple-regression/heteroscedasticity.html#conclusions",
    "title": "Heteroscedasticity",
    "section": "Conclusions:",
    "text": "Conclusions:\n\nparameters(fit_3)\n\nParameter   | Coefficient |       SE |       95% CI | t(931) |      p\n---------------------------------------------------------------------\n(Intercept) |        5.68 |     0.09 | [5.51, 5.84] |  66.09 | < .001\neduc        |        0.05 | 6.26e-03 | [0.03, 0.06] |   7.52 | < .001\nabil        |        0.01 | 1.82e-03 | [0.01, 0.01] |   5.68 | < .001\ntenure      |        0.01 | 2.52e-03 | [0.01, 0.02] |   5.54 | < .001\n\n\nModel fit_3 describes the data in the best way because:\n\nReduces omitted variable bias;\nResolves non-linearity;\nBut it still suffers from the heteroskedasticity!!"
  },
  {
    "objectID": "slides/30-multiple-regression/heteroscedasticity.html#robust-standard-errors",
    "href": "slides/30-multiple-regression/heteroscedasticity.html#robust-standard-errors",
    "title": "Heteroscedasticity",
    "section": "Robust standard errors",
    "text": "Robust standard errors\nRobust estimators for variance covariance matrix:\n\nsandwich::vcovHC - heteroskedasticity consistent\nsandwich::vcovCL - clustered SE\nclubSandwich::vcovCR - clustered heteroskedasticity consistent SE\nsandwich::vcovHAC - heteroskedasticity and autocorrelation consistent\nEstimation methods:\n\nHC3 - optimal one as per Long & Ervin (2000)\nHC1 - default in Stata"
  },
  {
    "objectID": "slides/30-multiple-regression/heteroscedasticity.html#interpretation",
    "href": "slides/30-multiple-regression/heteroscedasticity.html#interpretation",
    "title": "Heteroscedasticity",
    "section": "Interpretation",
    "text": "Interpretation\n\nfit_3\n\n\nCall:\nlm(formula = log(wage) ~ educ + abil + tenure, data = woolwage2)\n\nCoefficients:\n(Intercept)         educ         abil       tenure  \n    5.67507      0.04708      0.01032      0.01396  \n\nmodel_parameters(fit_3, vcov = \"HC3\")\n\nParameter   | Coefficient |       SE |       95% CI | t(931) |      p\n---------------------------------------------------------------------\n(Intercept) |        5.68 |     0.08 | [5.51, 5.84] |  66.92 | < .001\neduc        |        0.05 | 6.72e-03 | [0.03, 0.06] |   7.00 | < .001\nabil        |        0.01 | 1.98e-03 | [0.01, 0.01] |   5.22 | < .001\ntenure      |        0.01 | 2.65e-03 | [0.01, 0.02] |   5.28 | < .001\n\nmodel_performance(fit_3)\n\n# Indices of model performance\n\nAIC       |       BIC |    R2 | R2 (adj.) |  RMSE | Sigma\n---------------------------------------------------------\n13553.141 | 26254.081 | 0.165 |     0.163 | 0.385 | 0.385"
  },
  {
    "objectID": "slides/50-data-wrangling/workflow-tidy-data-wrangling.html#r-setup",
    "href": "slides/50-data-wrangling/workflow-tidy-data-wrangling.html#r-setup",
    "title": "Data Workflow + Tidy data + Wrangling",
    "section": "R setup",
    "text": "R setup\n\nlibrary(tidyverse)       # for data wrangling\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 16))\n\n# set default figure parameters for knitr\nknitr::opts_chunk$set(\n  fig.width = 8,\n  fig.asp = 0.618,\n  fig.retina = 3,\n  dpi = 300,\n  out.width = \"80%\"\n)"
  },
  {
    "objectID": "slides/50-data-wrangling/workflow-tidy-data-wrangling.html#data-analysis-workflow",
    "href": "slides/50-data-wrangling/workflow-tidy-data-wrangling.html#data-analysis-workflow",
    "title": "Data Workflow + Tidy data + Wrangling",
    "section": "Data analysis workflow",
    "text": "Data analysis workflow\n\nImage source: R4DS"
  },
  {
    "objectID": "slides/50-data-wrangling/workflow-tidy-data-wrangling.html#tidy-data-14",
    "href": "slides/50-data-wrangling/workflow-tidy-data-wrangling.html#tidy-data-14",
    "title": "Data Workflow + Tidy data + Wrangling",
    "section": "Tidy data (1/4)",
    "text": "Tidy data (1/4)\n\n\nImage source: R4DS"
  },
  {
    "objectID": "slides/50-data-wrangling/workflow-tidy-data-wrangling.html#tidy-data-24-wide-format",
    "href": "slides/50-data-wrangling/workflow-tidy-data-wrangling.html#tidy-data-24-wide-format",
    "title": "Data Workflow + Tidy data + Wrangling",
    "section": "Tidy data (2/4) wide format",
    "text": "Tidy data (2/4) wide format\n\n\nSee: Data transformation with dplyr cheatsheet"
  },
  {
    "objectID": "slides/50-data-wrangling/workflow-tidy-data-wrangling.html#tidy-data-34-long-format",
    "href": "slides/50-data-wrangling/workflow-tidy-data-wrangling.html#tidy-data-34-long-format",
    "title": "Data Workflow + Tidy data + Wrangling",
    "section": "Tidy data (3/4) long format",
    "text": "Tidy data (3/4) long format\n\n\nSee: Data transformation with dplyr cheatsheet"
  },
  {
    "objectID": "slides/50-data-wrangling/workflow-tidy-data-wrangling.html#tidy-data-44-transformation",
    "href": "slides/50-data-wrangling/workflow-tidy-data-wrangling.html#tidy-data-44-transformation",
    "title": "Data Workflow + Tidy data + Wrangling",
    "section": "Tidy data (4/4) transformation",
    "text": "Tidy data (4/4) transformation\n\n\nSee: Data transformation with dplyr cheatsheet"
  },
  {
    "objectID": "slides/50-data-wrangling/workflow-tidy-data-wrangling.html#wrangling",
    "href": "slides/50-data-wrangling/workflow-tidy-data-wrangling.html#wrangling",
    "title": "Data Workflow + Tidy data + Wrangling",
    "section": "Wrangling",
    "text": "Wrangling\n\n\nImage source: R4DS"
  },
  {
    "objectID": "slides/50-data-wrangling/workflow-tidy-data-wrangling.html#tidy-data-and-wrangling-see-also",
    "href": "slides/50-data-wrangling/workflow-tidy-data-wrangling.html#tidy-data-and-wrangling-see-also",
    "title": "Data Workflow + Tidy data + Wrangling",
    "section": "Tidy data and Wrangling: See also",
    "text": "Tidy data and Wrangling: See also\n R4DS: R for data science by Hadley Wickham and Garrett Grolemund (book’s source code) (Wickham and Grolemund 2017)\n\nRecommended. Practice:\n\n Primers: Programming basics\n7.1.2 Wrangling and tidying data in Data Science in a Box\n\nRecommended. Read:\n\n R4DS Ch 9. Wrangle\n R4DS Ch. 12. Tidy data\nCHEATSHEET: Data tidying with tidyr cheatsheet\n\nOptional. Watch:\n\n Tidy data video + slides\n Grammar of data wrangling video + slides\n webinar: Data wrangling with R and RStudio"
  },
  {
    "objectID": "slides/50-data-wrangling/workflow-tidy-data-wrangling.html#takeaways",
    "href": "slides/50-data-wrangling/workflow-tidy-data-wrangling.html#takeaways",
    "title": "Data Workflow + Tidy data + Wrangling",
    "section": "Takeaways",
    "text": "Takeaways\n\nTidy data: Wide + long formats\nData analysis workflow\nLearning materials"
  },
  {
    "objectID": "slides/50-data-wrangling/workflow-tidy-data-wrangling.html#references",
    "href": "slides/50-data-wrangling/workflow-tidy-data-wrangling.html#references",
    "title": "Data Workflow + Tidy data + Wrangling",
    "section": "References",
    "text": "References\n\n\n\nhttps://ebukin.github.io/mp223-2022-aem-R-public/\n\n\n\nWickham, Hadley, and Garrett Grolemund. 2017. R for Data Science. O’Reilly Media. http://r4ds.had.co.nz/."
  },
  {
    "objectID": "slides/50-data-wrangling/import-data.html#general-notes",
    "href": "slides/50-data-wrangling/import-data.html#general-notes",
    "title": "Import data",
    "section": "General notes",
    "text": "General notes\nData import must be done in a reproducible way!\n\n\nRaw data must be stored together with the project.\nData import and cleaning should be done with scripts.\n\n\n\nIt is tricky to load data, because, we need to interact with the file system.\n\nYou may use interactive Users Interface to load data once,\nBut you should use R code to reload same data again.\n\n\n\n\n\n\n\n\n\nImportant\n\n\nAlways save data import R code in your scripts!"
  },
  {
    "objectID": "slides/50-data-wrangling/import-data.html#data-import-more-materials",
    "href": "slides/50-data-wrangling/import-data.html#data-import-more-materials",
    "title": "Import data",
    "section": "Data import: more materials",
    "text": "Data import: more materials\n\nRecommended. Watch:\n\nData types video + slides\n\nRecommended. Read:\n\n R4DS Ch. 11 Data import\n\nOptional. Read:\n\nCHEATSHEET: Data import with the tidyverse\ntidyverse/readxl + tidyverse/readr + janitor\n\nOptional. Watch:\n\nImporting and recoding data\nData classes video + slides\nImporting data video + slides\n webinar: What’s new with readxl?"
  },
  {
    "objectID": "slides/50-data-wrangling/import-data.html#readr-package-23-key-functions",
    "href": "slides/50-data-wrangling/import-data.html#readr-package-23-key-functions",
    "title": "Import data",
    "section": "readr package (2/3) key functions",
    "text": "readr package (2/3) key functions\n\n\n\nread_csv() - for a coma separate data in the text file\nread_dta() - for Stata data files.\n\n\nThe file, which we want to read is in\n\n\n[1] \"/home/runner/work/_temp/renv/cache/v5/R-4.2/x86_64-pc-linux-gnu/readr/2.1.2/9c59de1357dc209868b5feb5c9f0fe2f/readr/extdata/chickens.csv\"\n\n\nInstead of specifying the path to this file, we use readr_example(\"chickens.csv\").\n\n\nRows: 5\nColumns: 4\n$ chicken   <chr> \"Foghorn Leghorn\", \"Chicken Little\", \"Ginger\", \"Camilla the …\n$ sex       <chr> \"rooster\", \"hen\", \"hen\", \"hen\", \"rooster\"\n$ eggs_laid <dbl> 0, 3, 12, 7, 0\n$ motto     <chr> \"That's a joke, ah say, that's a joke, son.\", \"The sky is fa…"
  },
  {
    "objectID": "slides/50-data-wrangling/import-data.html#readr-package-33-user-interface",
    "href": "slides/50-data-wrangling/import-data.html#readr-package-33-user-interface",
    "title": "Import data",
    "section": "readr package (3/3) user interface",
    "text": "readr package (3/3) user interface\n\nStep 1Step 2Step 3Step 4Step 5"
  },
  {
    "objectID": "slides/50-data-wrangling/import-data.html#readxl-package-23-basic-usage",
    "href": "slides/50-data-wrangling/import-data.html#readxl-package-23-basic-usage",
    "title": "Import data",
    "section": "readxl package (2/3) Basic usage",
    "text": "readxl package (2/3) Basic usage\n\nStep 1 Path to the fileStep 2 SheetsStep 3 Data in R\n\n\n\nFirst, locate the file.\n\n\n\n[1] \"/home/runner/work/_temp/renv/cache/v5/R-4.2/x86_64-pc-linux-gnu/readxl/1.4.0/170c35f745563bb307e963bde0197e4f/readxl/extdata/datasets.xls\"\n\n\n\nThen, open it manually to see if it is alright.\n\n\n\n\nThen, check what sheets re present there:\n\n\n\n[1] \"iris\"     \"mtcars\"   \"chickwts\" \"quakes\"  \n\n\n\n\n\n\nRows: 71\nColumns: 2\n$ weight <dbl> 179, 160, 136, 227, 217, 168, 108, 124, 143, 140, 309, 229, 181…\n$ feed   <chr> \"horsebean\", \"horsebean\", \"horsebean\", \"horsebean\", \"horsebean\"…"
  },
  {
    "objectID": "slides/50-data-wrangling/import-data.html#readxl-package-33-user-interface",
    "href": "slides/50-data-wrangling/import-data.html#readxl-package-33-user-interface",
    "title": "Import data",
    "section": "readxl package (3/3) user interface",
    "text": "readxl package (3/3) user interface\n\nStep 1Step 2Step 3Step 4Step 5"
  },
  {
    "objectID": "slides/50-data-wrangling/import-data.html#janitor-package-22-key-functions",
    "href": "slides/50-data-wrangling/import-data.html#janitor-package-22-key-functions",
    "title": "Import data",
    "section": "janitor package (2/2) key functions",
    "text": "janitor package (2/2) key functions\n\njanitor::clean_names() - Cleans names of an object (usually a data.frame).\njanitor::row_to_names(row_number = 1) - Elevate a row to be the column names of a data.frame.\njanitor::convert_to_date() + excel_numeric_to_date() - Convert many date and datetime formats as may be received from Microsoft Excel\njanitor::remove_empty() - Remove empty rows and/or columns from a data.frame or matrix."
  },
  {
    "objectID": "slides/50-data-wrangling/dplyr.html#r-setup",
    "href": "slides/50-data-wrangling/dplyr.html#r-setup",
    "title": "Data Workflow + Tidy data + Wrangling",
    "section": "R setup",
    "text": "R setup\n\nlibrary(tidyverse)       # for data wrangling\n\n# set default theme and larger font size for ggplot2\nggplot2::theme_set(ggplot2::theme_minimal(base_size = 16))\n\n# set default figure parameters for knitr\nknitr::opts_chunk$set(\n  fig.width = 8,\n  fig.asp = 0.618,\n  fig.retina = 3,\n  dpi = 300,\n  out.width = \"80%\"\n)"
  },
  {
    "objectID": "slides/50-data-wrangling/dplyr.html#data-analysis-workflow",
    "href": "slides/50-data-wrangling/dplyr.html#data-analysis-workflow",
    "title": "Data Workflow + Tidy data + Wrangling",
    "section": "Data analysis workflow",
    "text": "Data analysis workflow\n\nImage source: R4DS"
  },
  {
    "objectID": "slides/50-data-wrangling/dplyr.html#tidy-data-15",
    "href": "slides/50-data-wrangling/dplyr.html#tidy-data-15",
    "title": "Data Workflow + Tidy data + Wrangling",
    "section": "Tidy data (1/5)",
    "text": "Tidy data (1/5)\n\n\nImage source: R4DS"
  },
  {
    "objectID": "slides/50-data-wrangling/dplyr.html#tidy-data-25-wide-format",
    "href": "slides/50-data-wrangling/dplyr.html#tidy-data-25-wide-format",
    "title": "Data Workflow + Tidy data + Wrangling",
    "section": "Tidy data (2/5) wide format",
    "text": "Tidy data (2/5) wide format\n\n\nSee: Data transformation with dplyr cheatsheet"
  },
  {
    "objectID": "slides/50-data-wrangling/dplyr.html#tidy-data-35-long-format",
    "href": "slides/50-data-wrangling/dplyr.html#tidy-data-35-long-format",
    "title": "Data Workflow + Tidy data + Wrangling",
    "section": "Tidy data (3/5) long format",
    "text": "Tidy data (3/5) long format\n\n\nSee: Data transformation with dplyr cheatsheet"
  },
  {
    "objectID": "slides/50-data-wrangling/dplyr.html#tidy-data-45-transformation",
    "href": "slides/50-data-wrangling/dplyr.html#tidy-data-45-transformation",
    "title": "Data Workflow + Tidy data + Wrangling",
    "section": "Tidy data (4/5) transformation",
    "text": "Tidy data (4/5) transformation\n\n\nSee: Data transformation with dplyr cheatsheet"
  },
  {
    "objectID": "slides/50-data-wrangling/dplyr.html#tidy-data-55.-learn-more",
    "href": "slides/50-data-wrangling/dplyr.html#tidy-data-55.-learn-more",
    "title": "Data Workflow + Tidy data + Wrangling",
    "section": "Tidy data (5/5). Learn more?",
    "text": "Tidy data (5/5). Learn more?\nRead:\n\n R4DS Ch. 12. Tidy data\n\n\nFollow slides, videos and exercises:\n\n\n\nChapter 7.1.2 Wrangling and tidying data in Data Science in a Box"
  },
  {
    "objectID": "slides/50-data-wrangling/dplyr.html#wrangling",
    "href": "slides/50-data-wrangling/dplyr.html#wrangling",
    "title": "Data Workflow + Tidy data + Wrangling",
    "section": "Wrangling",
    "text": "Wrangling\n\n\nImage source: R4DS"
  },
  {
    "objectID": "slides/50-data-wrangling/dplyr.html#wrangling-see-also",
    "href": "slides/50-data-wrangling/dplyr.html#wrangling-see-also",
    "title": "Data Workflow + Tidy data + Wrangling",
    "section": "Wrangling: See also",
    "text": "Wrangling: See also\nRead:\n\n R4DS: R for data science by Hadley Wickham and Garrett Grolemund (book’s source code) (Wickham and Grolemund 2017)\nR4DS Ch 9. Wrangle\n\n\nWatch\n\n Grammar of data wrangling video + slides\n webinar: Data wrangling with R and RStudio"
  },
  {
    "objectID": "slides/50-data-wrangling/dplyr.html#dplyr-package",
    "href": "slides/50-data-wrangling/dplyr.html#dplyr-package",
    "title": "Data Workflow + Tidy data + Wrangling",
    "section": "dplyr package",
    "text": "dplyr package\n\n\n\n\n\n\n\n\n\n\n\n\nDoes data wrangling.\n\nDocumentation tidyverse/dplyr + Source code\nCheat sheets Data transformation with dplyr\nLearn by doing R4DS Ch 5. Data transformation"
  },
  {
    "objectID": "slides/50-data-wrangling/dplyr.html#dplyr-package-getting-started",
    "href": "slides/50-data-wrangling/dplyr.html#dplyr-package-getting-started",
    "title": "Data Workflow + Tidy data + Wrangling",
    "section": "dplyr package: getting started",
    "text": "dplyr package: getting started\nArticle: Introduction to dplyr\n\nCheat sheets: Data transformation with dplyr\n\n\nWebinar: Data wrangling with R and RStudio by Garrett Grolemund\n\n\nInteractive exercises (repeated on following slides)\n\nWorking with Tibbles\nIsolating Data with dplyr\nFilter observations\nDerive Information with dplyr\nSummarizing data\n\n\n\nReadings:\n\nR4DS Chapter 5 Data transformation"
  },
  {
    "objectID": "slides/50-data-wrangling/dplyr.html#dplyrrename-rename-columns",
    "href": "slides/50-data-wrangling/dplyr.html#dplyrrename-rename-columns",
    "title": "Data Workflow + Tidy data + Wrangling",
    "section": "dplyr::rename() Rename columns",
    "text": "dplyr::rename() Rename columns\n\n\n\nRead about in R4DS Ch. 5.4 + function reference (see examples!)"
  },
  {
    "objectID": "slides/50-data-wrangling/dplyr.html#dplyrmutate-create-modify-and-delete-columns",
    "href": "slides/50-data-wrangling/dplyr.html#dplyrmutate-create-modify-and-delete-columns",
    "title": "Data Workflow + Tidy data + Wrangling",
    "section": "dplyr::mutate() Create, modify, and delete columns",
    "text": "dplyr::mutate() Create, modify, and delete columns\n\n\n\nRead about in R4DS Ch. 5.5 + function reference\n\n\n\n\nArticles: Add new columns with mutate and Column-wise operations\n\n\n\n\nInteractive exercises: Derive Information with dplyr, Summarizing data and Road Traffic Accidents"
  },
  {
    "objectID": "slides/50-data-wrangling/dplyr.html#dplyrfilter-12-subset-rows-using-column-values",
    "href": "slides/50-data-wrangling/dplyr.html#dplyrfilter-12-subset-rows-using-column-values",
    "title": "Data Workflow + Tidy data + Wrangling",
    "section": "dplyr::filter() (1/2) subset rows using column values",
    "text": "dplyr::filter() (1/2) subset rows using column values\n\n\n\nRead about in R4DS Ch. 5.2 + function reference (see examples!)\n\n\n\n\nArticle: Filter rows with filter()\n\n\n\nInteractive exercises: Isolating Data with dplyr and Filter observations."
  },
  {
    "objectID": "slides/50-data-wrangling/dplyr.html#dplyrfilter-22-relies-on-logical-operators",
    "href": "slides/50-data-wrangling/dplyr.html#dplyrfilter-22-relies-on-logical-operators",
    "title": "Data Workflow + Tidy data + Wrangling",
    "section": "dplyr::filter() (2/2) relies on logical operators",
    "text": "dplyr::filter() (2/2) relies on logical operators\n\n\nSee: ?Comparison and ?base::Logic"
  },
  {
    "objectID": "slides/50-data-wrangling/dplyr.html#dplyrselect-subset-columns-using-their-names-and-types",
    "href": "slides/50-data-wrangling/dplyr.html#dplyrselect-subset-columns-using-their-names-and-types",
    "title": "Data Workflow + Tidy data + Wrangling",
    "section": "dplyr::select() Subset columns using their names and types",
    "text": "dplyr::select() Subset columns using their names and types\n\n\n\nRead about in R4DS Ch. 5.4 + function reference (see examples!)\n\n\n\nInteractive exercises: Isolating Data with dplyr"
  },
  {
    "objectID": "slides/50-data-wrangling/dplyr.html#left-for-later",
    "href": "slides/50-data-wrangling/dplyr.html#left-for-later",
    "title": "Data Workflow + Tidy data + Wrangling",
    "section": "Left for later",
    "text": "Left for later\n\ndplyr::summarise()\ndplyr::group_by()\ndplyr::arrange()\ndplyr::pull()\ndplyr::distinct()\ndplyr::count()"
  },
  {
    "objectID": "slides/50-data-wrangling/dplyr.html#skimr-package",
    "href": "slides/50-data-wrangling/dplyr.html#skimr-package",
    "title": "Data Workflow + Tidy data + Wrangling",
    "section": "skimr package",
    "text": "skimr package\n\n\n\n\n\n\n\n\n\n\n\n\nDoes Summary statistics\n\nDocumentation ropensci/skimr + Source code\nLearn by doing Using Skimr\n\nKey functions: skimr::skim()."
  },
  {
    "objectID": "slides/50-data-wrangling/dplyr.html#correlation-1",
    "href": "slides/50-data-wrangling/dplyr.html#correlation-1",
    "title": "Data Workflow + Tidy data + Wrangling",
    "section": "Correlation",
    "text": "Correlation\n\n\n\n\n\n\n\n\n\n\n\n\nDoes Summary statistics\n\nDocumentation easystats/correlation + Source code\nLearn by doing Using correlation\n\nKey functions: correlation::correlation()."
  },
  {
    "objectID": "slides/50-data-wrangling/dplyr.html#references-1",
    "href": "slides/50-data-wrangling/dplyr.html#references-1",
    "title": "Data Workflow + Tidy data + Wrangling",
    "section": "References",
    "text": "References\n\n\n\nhttps://ebukin.github.io/mp223-2022-aem-R-public/\n\n\n\nWickham, Hadley, and Garrett Grolemund. 2017. R for Data Science. O’Reilly Media. http://r4ds.had.co.nz/."
  },
  {
    "objectID": "slides/20-data-description/correlation.html#definition-of-correlation",
    "href": "slides/20-data-description/correlation.html#definition-of-correlation",
    "title": "Correlation",
    "section": "Definition of Correlation",
    "text": "Definition of Correlation\n\nIn statistics, correlation or dependence is any statistical relationship, whether causal or not, between two random variables or bivariate data.\n\n\nMost common are following method of correlation:\n\nPearson’s correlation\nSpearman’s rank correlation\n\n\n\nBoth, capture linear relationship.\n\n\nTips for interpretation of the strength of correlation"
  },
  {
    "objectID": "slides/20-data-description/correlation.html#examples",
    "href": "slides/20-data-description/correlation.html#examples",
    "title": "Correlation",
    "section": "Examples",
    "text": "Examples"
  },
  {
    "objectID": "slides/20-data-description/correlation.html#computation-with-correlation",
    "href": "slides/20-data-description/correlation.html#computation-with-correlation",
    "title": "Correlation",
    "section": "Computation with correlation",
    "text": "Computation with correlation\n\n\n\n\n\n\n\n\n\n\n\n\nDoes Summary statistics\n\nDocumentation easystats/correlation + Source code\nLearn by doing Using correlation\n\nKey functions: correlation::correlation()."
  },
  {
    "objectID": "slides/20-data-description/correlation.html#correlation-in-penguins-data",
    "href": "slides/20-data-description/correlation.html#correlation-in-penguins-data",
    "title": "Correlation",
    "section": "Correlation in penguins data",
    "text": "Correlation in penguins data"
  },
  {
    "objectID": "slides/20-data-description/correlation.html#the-data",
    "href": "slides/20-data-description/correlation.html#the-data",
    "title": "Correlation",
    "section": "The data",
    "text": "The data\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           <fct> Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel…\n$ island            <fct> Torgersen, Torgersen, Torgersen, Torgersen, Torgerse…\n$ bill_length_mm    <dbl> 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, …\n$ bill_depth_mm     <dbl> 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, …\n$ flipper_length_mm <int> 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186…\n$ body_mass_g       <int> 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, …\n$ sex               <fct> male, female, female, NA, female, male, female, male…\n$ year              <int> 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007…"
  },
  {
    "objectID": "slides/20-data-description/correlation.html#scatter-plot",
    "href": "slides/20-data-description/correlation.html#scatter-plot",
    "title": "Correlation",
    "section": "Scatter plot",
    "text": "Scatter plot\n\nPlotCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(palmerpenguins)\npenguins %>% \n  ggplot(aes(x = flipper_length_mm, y = bill_length_mm)) +\n  geom_point(aes(color = species, shape = species)) +\n  labs(\n    title = \"Flipper and bill length\",\n    x = \"Flipper length (mm)\",\n    y = \"Bill length (mm)\",\n    color = \"Penguin species\",\n    shape = \"Penguin species\"\n  )"
  },
  {
    "objectID": "slides/20-data-description/correlation.html#correlation-usage-1",
    "href": "slides/20-data-description/correlation.html#correlation-usage-1",
    "title": "Correlation",
    "section": "correlation() usage 1",
    "text": "correlation() usage 1\n\npenguins %>% correlation()\n\n# Correlation Matrix (pearson-method)\n\nParameter1        |        Parameter2 |     r |         95% CI | t(340) |         p\n-----------------------------------------------------------------------------------\nbill_length_mm    |     bill_depth_mm | -0.24 | [-0.33, -0.13] |  -4.46 | < .001***\nbill_length_mm    | flipper_length_mm |  0.66 | [ 0.59,  0.71] |  16.03 | < .001***\nbill_length_mm    |       body_mass_g |  0.60 | [ 0.52,  0.66] |  13.65 | < .001***\nbill_length_mm    |              year |  0.05 | [-0.05,  0.16] |   1.01 | 0.797    \nbill_depth_mm     | flipper_length_mm | -0.58 | [-0.65, -0.51] | -13.26 | < .001***\nbill_depth_mm     |       body_mass_g | -0.47 | [-0.55, -0.39] |  -9.87 | < .001***\nbill_depth_mm     |              year | -0.06 | [-0.17,  0.05] |  -1.11 | 0.797    \nflipper_length_mm |       body_mass_g |  0.87 | [ 0.84,  0.89] |  32.72 | < .001***\nflipper_length_mm |              year |  0.17 | [ 0.06,  0.27] |   3.17 | 0.007**  \nbody_mass_g       |              year |  0.04 | [-0.06,  0.15] |   0.78 | 0.797    \n\np-value adjustment method: Holm (1979)\nObservations: 342"
  },
  {
    "objectID": "slides/20-data-description/correlation.html#correlation-usage-2-summary",
    "href": "slides/20-data-description/correlation.html#correlation-usage-2-summary",
    "title": "Correlation",
    "section": "correlation() usage 2 + summary()",
    "text": "correlation() usage 2 + summary()\n\npenguins %>% correlation() %>% summary()\n\n# Correlation Matrix (pearson-method)\n\nParameter         |   year | body_mass_g | flipper_length_mm | bill_depth_mm\n----------------------------------------------------------------------------\nbill_length_mm    |   0.05 |     0.60*** |           0.66*** |      -0.24***\nbill_depth_mm     |  -0.06 |    -0.47*** |          -0.58*** |              \nflipper_length_mm | 0.17** |     0.87*** |                   |              \nbody_mass_g       |   0.04 |             |                   |              \n\np-value adjustment method: Holm (1979)"
  },
  {
    "objectID": "slides/20-data-description/correlation.html#correlation-usage-3-as_tibble",
    "href": "slides/20-data-description/correlation.html#correlation-usage-3-as_tibble",
    "title": "Correlation",
    "section": "correlation() usage 3 + as_tibble()",
    "text": "correlation() usage 3 + as_tibble()\n\npenguins %>% correlation() %>% as_tibble()\n\n# A tibble: 10 × 11\n   Parameter1        Parameter2         r    CI  CI_low CI_high       t df_error\n   <chr>             <chr>          <dbl> <dbl>   <dbl>   <dbl>   <dbl>    <int>\n 1 bill_length_mm    bill_depth_… -0.235   0.95 -0.333  -0.132   -4.46       340\n 2 bill_length_mm    flipper_len…  0.656   0.95  0.591   0.713   16.0        340\n 3 bill_length_mm    body_mass_g   0.595   0.95  0.522   0.660   13.7        340\n 4 bill_length_mm    year          0.0545  0.95 -0.0518  0.160    1.01       340\n 5 bill_depth_mm     flipper_len… -0.584   0.95 -0.650  -0.509  -13.3        340\n 6 bill_depth_mm     body_mass_g  -0.472   0.95 -0.550  -0.385   -9.87       340\n 7 bill_depth_mm     year         -0.0604  0.95 -0.165   0.0460  -1.11       340\n 8 flipper_length_mm body_mass_g   0.871   0.95  0.843   0.895   32.7        340\n 9 flipper_length_mm year          0.170   0.95  0.0648  0.271    3.17       340\n10 body_mass_g       year          0.0422  0.95 -0.0641  0.148    0.779      340\n# … with 3 more variables: p <dbl>, Method <chr>, n_Obs <int>"
  },
  {
    "objectID": "slides/20-data-description/correlation.html#what-commodity-causes-surges-13",
    "href": "slides/20-data-description/correlation.html#what-commodity-causes-surges-13",
    "title": "Correlation",
    "section": "What commodity causes surges? (1/3)",
    "text": "What commodity causes surges? (1/3)"
  },
  {
    "objectID": "slides/20-data-description/correlation.html#what-commodity-causes-surges-23",
    "href": "slides/20-data-description/correlation.html#what-commodity-causes-surges-23",
    "title": "Correlation",
    "section": "What commodity causes surges? (2/3)",
    "text": "What commodity causes surges? (2/3)"
  },
  {
    "objectID": "slides/20-data-description/correlation.html#what-commodity-causes-surges-33",
    "href": "slides/20-data-description/correlation.html#what-commodity-causes-surges-33",
    "title": "Correlation",
    "section": "What commodity causes surges? (3/3)",
    "text": "What commodity causes surges? (3/3)\n\nCan we conclude, based on the plot, that surging prices of urea cause the wheat prices to surge?\nWhat could be the theoretical explanation for this cause and effect relationship?\nWhat could be the theoretical mechanism of urea prices effect on wheat?\nHow can we test empirically, if there is any (co)relationship?"
  },
  {
    "objectID": "slides/20-data-description/correlation.html#prices-correlation-12",
    "href": "slides/20-data-description/correlation.html#prices-correlation-12",
    "title": "Correlation",
    "section": "Prices correlation (1/2)",
    "text": "Prices correlation (1/2)\n\n\n# Correlation Matrix (pearson-method)\n\nParameter   | index_wheat | index_urea | index_oil\n--------------------------------------------------\nindex_maize |     0.89*** |    0.77*** |   0.81***\nindex_oil   |     0.79*** |    0.80*** |          \nindex_urea  |     0.76*** |            |          \n\np-value adjustment method: Holm (1979)\n\n\n\n\nIf we assume that theoretical causation from Urea to Wheat prices is possible!\nDoes high and significant correlation suggest about causal relationship?"
  },
  {
    "objectID": "slides/20-data-description/correlation.html#first-difference-and-correlation-12",
    "href": "slides/20-data-description/correlation.html#first-difference-and-correlation-12",
    "title": "Correlation",
    "section": "First Difference and correlation (1/2)",
    "text": "First Difference and correlation (1/2)\n\n\n\n# Correlation Matrix (pearson-method)\n\nParameter      | index_fd_wheat | index_fd_urea | index_fd_oil\n--------------------------------------------------------------\nindex_fd_maize |        0.41*** |          0.02 |      0.25***\nindex_fd_oil   |           0.07 |       0.24*** |             \nindex_fd_urea  |          -0.05 |               |             \n\np-value adjustment method: Holm (1979)"
  },
  {
    "objectID": "slides/20-data-description/correlation.html#first-difference-and-correlation-22",
    "href": "slides/20-data-description/correlation.html#first-difference-and-correlation-22",
    "title": "Correlation",
    "section": "First Difference and correlation (2/2)",
    "text": "First Difference and correlation (2/2)\nFirst Difference removed linear trends from the data.\n\nThere might be some different chains of reaction here. For example:\n\nOil price may affect Urea prices as it is an important production factor\nOil price may affect maize price as it is a baleful competitor\nMaize price affect wheat as they are the substitute."
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#summary-of-a-single-variables",
    "href": "slides/20-data-description/exploring-numeric-data.html#summary-of-a-single-variables",
    "title": "Exploring numerical data",
    "section": "Summary of a single variables",
    "text": "Summary of a single variables\n\nun_dta %>% pull(fertility) %>% mean()\n\n[1] 2.761383\n\n\n\n\nmean(un_dta$fertility)\n\n[1] 2.761383\n\n\n\n\n\nun_dta %>% pull(fertility) %>% sd()\n\n[1] 1.339589\n\n\n\n\n\nsd(un_dta$fertility)\n\n[1] 1.339589"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#using-dplyrsummarise-13",
    "href": "slides/20-data-description/exploring-numeric-data.html#using-dplyrsummarise-13",
    "title": "Exploring numerical data",
    "section": "Using dplyr::summarise() (1/3)",
    "text": "Using dplyr::summarise() (1/3)"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#using-dplyrsummarise-23",
    "href": "slides/20-data-description/exploring-numeric-data.html#using-dplyrsummarise-23",
    "title": "Exploring numerical data",
    "section": "Using dplyr::summarise() (2/3)",
    "text": "Using dplyr::summarise() (2/3)\n\nun_dta %>%\n  summarise(\n    mean_fert = mean(fertility)\n  ) \n\n# A tibble: 1 × 1\n  mean_fert\n      <dbl>\n1      2.76"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#using-dplyrsummarise-23-1",
    "href": "slides/20-data-description/exploring-numeric-data.html#using-dplyrsummarise-23-1",
    "title": "Exploring numerical data",
    "section": "Using dplyr::summarise() (2/3)",
    "text": "Using dplyr::summarise() (2/3)\n\nun_dta %>%\n  summarise(\n    mean_fert = mean(fertility),\n    sd_ppgdp = sd(ppgdp)\n  ) \n\n# A tibble: 1 × 2\n  mean_fert sd_ppgdp\n      <dbl>    <dbl>\n1      2.76   18412."
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#using-dplyrsummarise-23-2",
    "href": "slides/20-data-description/exploring-numeric-data.html#using-dplyrsummarise-23-2",
    "title": "Exploring numerical data",
    "section": "Using dplyr::summarise() (2/3)",
    "text": "Using dplyr::summarise() (2/3)\n\nun_dta %>%\n  summarise(\n    mean_fert = mean(fertility),\n    sd_ppgdp = sd(ppgdp),\n    med_lifeExpF = median(lifeExpF)\n  ) \n\n# A tibble: 1 × 3\n  mean_fert sd_ppgdp med_lifeExpF\n      <dbl>    <dbl>        <dbl>\n1      2.76   18412.         75.9"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#using-dplyrsummarise-33",
    "href": "slides/20-data-description/exploring-numeric-data.html#using-dplyrsummarise-33",
    "title": "Exploring numerical data",
    "section": "Using dplyr::summarise() (3/3)",
    "text": "Using dplyr::summarise() (3/3)\n\nun_dta %>%\n  summarise(across(\n    c(fertility),\n    list(\n      means = mean\n    )\n  )) %>% \n  t()\n\n                    [,1]\nfertility_means 2.761383"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#using-dplyrsummarise-33-1",
    "href": "slides/20-data-description/exploring-numeric-data.html#using-dplyrsummarise-33-1",
    "title": "Exploring numerical data",
    "section": "Using dplyr::summarise() (3/3)",
    "text": "Using dplyr::summarise() (3/3)\n\nun_dta %>%\n  summarise(across(\n    c(fertility, ppgdp),\n    list(\n      means = mean\n    )\n  )) %>% \n  t()\n\n                        [,1]\nfertility_means     2.761383\nppgdp_means     13011.951759"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#using-dplyrsummarise-33-2",
    "href": "slides/20-data-description/exploring-numeric-data.html#using-dplyrsummarise-33-2",
    "title": "Exploring numerical data",
    "section": "Using dplyr::summarise() (3/3)",
    "text": "Using dplyr::summarise() (3/3)\n\nun_dta %>%\n  summarise(across(\n    c(fertility, ppgdp),\n    list(\n      means = mean,\n      medians = ~ median(., na.rm = TRUE)\n    )\n  )) %>% \n  t()\n\n                          [,1]\nfertility_means       2.761383\nfertility_medians     2.262000\nppgdp_means       13011.951759\nppgdp_medians      4684.500000"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#using-dplyrsummarise-33-3",
    "href": "slides/20-data-description/exploring-numeric-data.html#using-dplyrsummarise-33-3",
    "title": "Exploring numerical data",
    "section": "Using dplyr::summarise() (3/3)",
    "text": "Using dplyr::summarise() (3/3)\n\nun_dta %>%\n  summarise(across(\n    c(fertility, ppgdp),\n    list(\n      means = mean,\n      medians = ~ median(., na.rm = TRUE),\n      sd = ~ sd(., na.rm = TRUE),\n      n_nonmis = ~ sum(!is.na(.))\n    )\n  )) %>% \n  t()\n\n                           [,1]\nfertility_means        2.761383\nfertility_medians      2.262000\nfertility_sd           1.339589\nfertility_n_nonmis   199.000000\nppgdp_means        13011.951759\nppgdp_medians       4684.500000\nppgdp_sd           18412.443368\nppgdp_n_nonmis       199.000000"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#using-dplyrgroup_by-dplyrsummarise-13",
    "href": "slides/20-data-description/exploring-numeric-data.html#using-dplyrgroup_by-dplyrsummarise-13",
    "title": "Exploring numerical data",
    "section": "Using dplyr::group_by() + dplyr::summarise() (1/3)",
    "text": "Using dplyr::group_by() + dplyr::summarise() (1/3)"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#using-dplyrgroup_by-dplyrsummarise-23",
    "href": "slides/20-data-description/exploring-numeric-data.html#using-dplyrgroup_by-dplyrsummarise-23",
    "title": "Exploring numerical data",
    "section": "Using dplyr::group_by() + dplyr::summarise() (2/3)",
    "text": "Using dplyr::group_by() + dplyr::summarise() (2/3)\n\nun_dta %>% \n  # group_by(region) %>% \n  summarise(mean_fert = mean(fertility),\n            sd_ppgdp = sd(ppgdp),\n            med_lifeExpF = median(lifeExpF))\n\n# A tibble: 1 × 3\n  mean_fert sd_ppgdp med_lifeExpF\n      <dbl>    <dbl>        <dbl>\n1      2.76   18412.         75.9"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#using-dplyrgroup_by-dplyrsummarise-23-1",
    "href": "slides/20-data-description/exploring-numeric-data.html#using-dplyrgroup_by-dplyrsummarise-23-1",
    "title": "Exploring numerical data",
    "section": "Using dplyr::group_by() + dplyr::summarise() (2/3)",
    "text": "Using dplyr::group_by() + dplyr::summarise() (2/3)\n\nun_dta %>% \n  group_by(region) %>% \n  summarise(mean_fert = mean(fertility),\n            sd_ppgdp = sd(ppgdp),\n            med_lifeExpF = median(lifeExpF))\n\n# A tibble: 8 × 4\n  region        mean_fert sd_ppgdp med_lifeExpF\n  <fct>             <dbl>    <dbl>        <dbl>\n1 Africa             4.24    3614.         58.6\n2 Asia               2.43   16742.         75.2\n3 Caribbean          2.01   23063.         78.2\n4 Europe             1.59   23820.         81.4\n5 Latin Amer         2.43    3775.         77.6\n6 North America      1.88     131.         82.4\n7 NorthAtlantic      2.22      NA          71.6\n8 Oceania            3.10   15956.         72.3"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#using-dplyrgroup_by-dplyrsummarise-33",
    "href": "slides/20-data-description/exploring-numeric-data.html#using-dplyrgroup_by-dplyrsummarise-33",
    "title": "Exploring numerical data",
    "section": "Using dplyr::group_by() + dplyr::summarise() (3/3)",
    "text": "Using dplyr::group_by() + dplyr::summarise() (3/3)\n\nun_dta %>%\n  group_by(group) %>%\n  summarise(across(\n    c(fertility, ppgdp),\n    list(\n      means = mean,\n      medians = ~ median(., na.rm = TRUE),\n      sd = ~ sd(., na.rm = TRUE),\n      n_nonmis = ~ sum(!is.na(.))\n    )\n  ))\n\n# A tibble: 3 × 9\n  group  fertility_means fertility_medians fertility_sd fertility_n_nonmis\n  <fct>            <dbl>             <dbl>        <dbl>              <int>\n1 oecd              1.77              1.79        0.340                 31\n2 other             2.35              2.17        0.927                115\n3 africa            4.24              4.42        1.30                  53\n# … with 4 more variables: ppgdp_means <dbl>, ppgdp_medians <dbl>,\n#   ppgdp_sd <dbl>, ppgdp_n_nonmis <int>"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#skimr-package",
    "href": "slides/20-data-description/exploring-numeric-data.html#skimr-package",
    "title": "Exploring numerical data",
    "section": "skimr package",
    "text": "skimr package\n\n\n\n\n\n\n\n\n\n\n\n\nPackage for Summary statistics\n\nDocumentation ropensci/skimr + Source code\nLearn by doing Using Skimr\nKey functions: skimr::skim()"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#skim-of-the-un-data",
    "href": "slides/20-data-description/exploring-numeric-data.html#skim-of-the-un-data",
    "title": "Exploring numerical data",
    "section": "skim() of the UN data",
    "text": "skim() of the UN data\n\nlibrary(skimr)\nun_dta %>% skim()\n\n\n\n── Data Summary ────────────────────────\n                           Values    \nName                       Piped data\nNumber of rows             199       \nNumber of columns          6         \n_______________________              \nColumn type frequency:               \n  factor                   2         \n  numeric                  4         \n________________________             \nGroup variables            None      \n\n── Variable type: factor ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate ordered n_unique top_counts                        \n1 region                0             1 FALSE          8 Afr: 53, Asi: 50, Eur: 39, Lat: 20\n2 group                 0             1 FALSE          3 oth: 115, afr: 53, oec: 31        \n\n── Variable type: numeric ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n  skim_variable n_missing complete_rate     mean       sd     p0     p25     p50      p75      p100 hist \n1 fertility             0             1     2.76     1.34   1.13    1.75    2.26     3.54      6.92 ▇▃▂▂▁\n2 ppgdp                 0             1 13012.   18412.   115.   1283.   4684.   15520.   105095.   ▇▁▁▁▁\n3 lifeExpF              0             1    72.3     10.1   48.1    65.7    75.9     79.6      87.1  ▂▂▂▇▅\n4 pctUrban              0             1    57.9     23.4   11      39      59       75       100    ▅▆▇▇▆"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#skim-of-the-un-data-by-group",
    "href": "slides/20-data-description/exploring-numeric-data.html#skim-of-the-un-data-by-group",
    "title": "Exploring numerical data",
    "section": "skim() of the UN data by group",
    "text": "skim() of the UN data by group\n\nun_dta %>% group_by(group) %>% skim()\n\n\n\n── Data Summary ────────────────────────\n                           Values    \nName                       Piped data\nNumber of rows             199       \nNumber of columns          6         \n_______________________              \nColumn type frequency:               \n  factor                   1         \n  numeric                  4         \n________________________             \nGroup variables            group     \n\n── Variable type: factor ─────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n  skim_variable group  n_missing complete_rate ordered n_unique top_counts                        \n1 region        oecd           0             1 FALSE          5 Eur: 22, Asi: 3, Lat: 2, Nor: 2   \n2 region        other          0             1 FALSE          6 Asi: 47, Lat: 18, Car: 17, Eur: 17\n3 region        africa         0             1 FALSE          1 Afr: 53, Asi: 0, Car: 0, Eur: 0   \n\n── Variable type: numeric ────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n   skim_variable group  n_missing complete_rate     mean        sd      p0      p25      p50      p75      p100 hist \n 1 fertility     oecd           0             1     1.77     0.340    1.31     1.48     1.79     1.95      2.91 ▇▇▃▁▁\n 2 fertility     other          0             1     2.35     0.927    1.13     1.65     2.17     2.61      5.97 ▇▆▂▁▁\n 3 fertility     africa         0             1     4.24     1.30     1.59     3.17     4.42     5.08      6.92 ▅▃▇▅▂\n 4 ppgdp         oecd           0             1 37761.   22092.    9101.   20138.   39546.   46453.   105095.   ▆▇▂▁▁\n 5 ppgdp         other          0             1 11181.   15271.     499     2527.    5195.   12857.    92625.   ▇▁▁▁▁\n 6 ppgdp         africa         0             1  2509.    3614.     115.     509      981.    2865     16852.   ▇▁▁▁▁\n 7 lifeExpF      oecd           0             1    82.4      2.09    76.6     81.3     82.8     83.5      87.1  ▁▂▇▇▁\n 8 lifeExpF      other          0             1    75.3      5.68    49.5     72.5     76.4     78.3      86.4  ▁▁▂▇▂\n 9 lifeExpF      africa         0             1    59.8      8.69    48.1     53.1     58.6     63.8      78    ▇▆▅▁▃\n10 pctUrban      oecd           0             1    75.8     11.7     49       68       78       85        97    ▁▅▃▇▂\n11 pctUrban      other          0             1    60.2     24.0     13       44.5     60       76       100    ▅▃▇▇▆\n12 pctUrban      africa         0             1    42.6     17.6     11       28       40       59        86    ▃▇▅▅▁"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#report-package",
    "href": "slides/20-data-description/exploring-numeric-data.html#report-package",
    "title": "Exploring numerical data",
    "section": "report package",
    "text": "report package\n\n\n\n\n\n\n\n\n\n\n\n\nPackage for Summary statistics!\n\nDocumentation easystats/skimr\nLearn by doing Using Skimr\nKey functions: skimr::skim()\n\n\n\n\n\n\n\nImportant\n\n\nThis is an experimental package! It does not support some types of the variables and may break or produce an error."
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#report-the-un-data",
    "href": "slides/20-data-description/exploring-numeric-data.html#report-the-un-data",
    "title": "Exploring numerical data",
    "section": "report the UN data",
    "text": "report the UN data\n\n# library(report)\n# un_dta %>% report() %>% as_tibble()"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#report-the-un-data-by-group",
    "href": "slides/20-data-description/exploring-numeric-data.html#report-the-un-data-by-group",
    "title": "Exploring numerical data",
    "section": "report the UN data by group",
    "text": "report the UN data by group\n\n# un_dta %>% group_by(group) %>% report() %>% as_tibble()"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#boxplot-basics",
    "href": "slides/20-data-description/exploring-numeric-data.html#boxplot-basics",
    "title": "Exploring numerical data",
    "section": "Boxplot: basics",
    "text": "Boxplot: basics\n\n\n\n\n\n\n\n\nImportant\n\n\nCheck out https://www.r-graph-gallery.com/boxplot.html;\nBoxplot explanation: https://www.data-to-viz.com/caveat/boxplot.html\n\n\n\n\nImage source: https://www.leansigmacorporation.com/box-plot-with-minitab/"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#boxplot-14",
    "href": "slides/20-data-description/exploring-numeric-data.html#boxplot-14",
    "title": "Exploring numerical data",
    "section": "Boxplot (1/4)",
    "text": "Boxplot (1/4)\n\nun_dta %>% \n  ggplot()"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#boxplot-24",
    "href": "slides/20-data-description/exploring-numeric-data.html#boxplot-24",
    "title": "Exploring numerical data",
    "section": "Boxplot (2/4)",
    "text": "Boxplot (2/4)\n\nun_dta %>% \n  ggplot() + \n  aes(y = fertility)"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#boxplot-34",
    "href": "slides/20-data-description/exploring-numeric-data.html#boxplot-34",
    "title": "Exploring numerical data",
    "section": "Boxplot (3/4)",
    "text": "Boxplot (3/4)\n\nun_dta %>% \n  ggplot() + \n  aes(y = fertility) + \n  geom_boxplot()"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#boxplot-44",
    "href": "slides/20-data-description/exploring-numeric-data.html#boxplot-44",
    "title": "Exploring numerical data",
    "section": "Boxplot (4/4)",
    "text": "Boxplot (4/4)\n\nun_dta %>% \n  ggplot() + \n  aes(y = fertility) + \n  geom_boxplot() + \n  labs(title = \"Boxplot of fertility\",\n       subtitle = \"Based on UN country level data for 2010-2015\",\n       y = \"Fertility, children per woman\",\n       x = \"\")"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#boxplot-44-1",
    "href": "slides/20-data-description/exploring-numeric-data.html#boxplot-44-1",
    "title": "Exploring numerical data",
    "section": "Boxplot (4/4)",
    "text": "Boxplot (4/4)\n\nun_dta %>% \n  ggplot() + \n  aes(y = fertility) + \n  geom_boxplot()"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#boxplot-by-groups-13",
    "href": "slides/20-data-description/exploring-numeric-data.html#boxplot-by-groups-13",
    "title": "Exploring numerical data",
    "section": "Boxplot by groups (1/3)",
    "text": "Boxplot by groups (1/3)\n\nun_dta %>% \n  ggplot() + \n  aes(y = fertility, x = region) + \n  geom_boxplot()"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#boxplot-by-groups-23",
    "href": "slides/20-data-description/exploring-numeric-data.html#boxplot-by-groups-23",
    "title": "Exploring numerical data",
    "section": "Boxplot by groups (2/3)",
    "text": "Boxplot by groups (2/3)\n\nun_dta %>% \n  ggplot() + \n  aes(y = fertility, x = region, colour = region) + \n  geom_boxplot()"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#boxplot-by-groups-33",
    "href": "slides/20-data-description/exploring-numeric-data.html#boxplot-by-groups-33",
    "title": "Exploring numerical data",
    "section": "Boxplot by groups (3/3)",
    "text": "Boxplot by groups (3/3)\n\nun_dta %>% \n  ggplot() + \n  aes(y = region, x = fertility, colour = region) + \n  geom_boxplot() + \n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#causal-question-on-boxplot",
    "href": "slides/20-data-description/exploring-numeric-data.html#causal-question-on-boxplot",
    "title": "Exploring numerical data",
    "section": "Causal question on boxplot!",
    "text": "Causal question on boxplot!\nDoes a country group has a causal effect on fertility?\n\n\nCode\nun_dta %>% \n  ggplot() + \n  aes(y = group, x = fertility, colour = group) + \n  geom_boxplot() + \n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#histogram-basics",
    "href": "slides/20-data-description/exploring-numeric-data.html#histogram-basics",
    "title": "Exploring numerical data",
    "section": "Histogram: basics",
    "text": "Histogram: basics\n\n\n\n\n\n\n\n\nImportant\n\n\nCheck the gallery https://r-graph-gallery.com/histogram.html;\nLearn about histograms here: THE BOXPLOT AND ITS PITFALLS"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#histogramus-simplicius",
    "href": "slides/20-data-description/exploring-numeric-data.html#histogramus-simplicius",
    "title": "Exploring numerical data",
    "section": "Histogramus simplicius",
    "text": "Histogramus simplicius\n\nun_dta \n\n# A tibble: 199 × 6\n   region     group  fertility  ppgdp lifeExpF pctUrban\n   <fct>      <fct>      <dbl>  <dbl>    <dbl>    <dbl>\n 1 Asia       other       5.97   499      49.5       23\n 2 Europe     other       1.52  3677.     80.4       53\n 3 Africa     africa      2.14  4473      75         67\n 4 Africa     africa      5.14  4322.     53.2       59\n 5 Caribbean  other       2    13750.     81.1      100\n 6 Latin Amer other       2.17  9162.     79.9       93\n 7 Asia       other       1.74  3031.     77.3       64\n 8 Caribbean  other       1.67 22852.     77.8       47\n 9 Oceania    oecd        1.95 57119.     84.3       89\n10 Europe     oecd        1.35 45159.     83.6       68\n# … with 189 more rows"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#histogramus-simplicius-1",
    "href": "slides/20-data-description/exploring-numeric-data.html#histogramus-simplicius-1",
    "title": "Exploring numerical data",
    "section": "Histogramus simplicius",
    "text": "Histogramus simplicius\n\nun_dta %>% \n  ggplot()"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#histogramus-simplicius-2",
    "href": "slides/20-data-description/exploring-numeric-data.html#histogramus-simplicius-2",
    "title": "Exploring numerical data",
    "section": "Histogramus simplicius",
    "text": "Histogramus simplicius\n\nun_dta %>% \n  ggplot() + \n  aes(x = ppgdp)"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#histogramus-simplicius-3",
    "href": "slides/20-data-description/exploring-numeric-data.html#histogramus-simplicius-3",
    "title": "Exploring numerical data",
    "section": "Histogramus simplicius",
    "text": "Histogramus simplicius\n\nun_dta %>% \n  ggplot() + \n  aes(x = ppgdp) + \n  geom_histogram() +\n  labs(x = \"GDP per capita, 2010 USD\", y = \"Frequency\")"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#histogram-bins-1",
    "href": "slides/20-data-description/exploring-numeric-data.html#histogram-bins-1",
    "title": "Exploring numerical data",
    "section": "Histogram: bins",
    "text": "Histogram: bins\n\nun_dta %>% \n  ggplot() + \n  aes(x = ppgdp) + \n  geom_histogram(bins = 50) +\n  labs(x = \"GDP per capita, 2010 USD\", y = \"Frequency\")"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#histogram-bins-2",
    "href": "slides/20-data-description/exploring-numeric-data.html#histogram-bins-2",
    "title": "Exploring numerical data",
    "section": "Histogram: bins",
    "text": "Histogram: bins\n\nun_dta %>% \n  ggplot() + \n  aes(x = ppgdp) + \n  geom_histogram(bins = 10) +\n  labs(x = \"GDP per capita, 2010 USD\", y = \"Frequency\")"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#histogram-bins-3",
    "href": "slides/20-data-description/exploring-numeric-data.html#histogram-bins-3",
    "title": "Exploring numerical data",
    "section": "Histogram: bins",
    "text": "Histogram: bins\n\nun_dta %>% \n  ggplot() + \n  aes(x = ppgdp) + \n  geom_histogram(bins = 3) +\n  labs(x = \"GDP per capita, 2010 USD\", y = \"Frequency\")"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#histogram-by-group-1",
    "href": "slides/20-data-description/exploring-numeric-data.html#histogram-by-group-1",
    "title": "Exploring numerical data",
    "section": "Histogram by group",
    "text": "Histogram by group\n\nun_dta %>% \n  ggplot() + \n  aes(x = ppgdp, fill = group) + \n  geom_histogram(bins = 10, colour = \"black\") +\n  labs(x = \"GDP per capita, 2010 USD\", y = \"Frequency\")"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#histogram-by-group-2",
    "href": "slides/20-data-description/exploring-numeric-data.html#histogram-by-group-2",
    "title": "Exploring numerical data",
    "section": "Histogram by group",
    "text": "Histogram by group\n\nun_dta %>% \n  ggplot() + \n  aes(x = ppgdp, fill = group) + \n  geom_histogram(bins = 10, colour = \"black\", position = \"dodge\") +\n  labs(x = \"GDP per capita, 2010 USD\", y = \"Frequency\")"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#histogram-by-group-3",
    "href": "slides/20-data-description/exploring-numeric-data.html#histogram-by-group-3",
    "title": "Exploring numerical data",
    "section": "Histogram by group",
    "text": "Histogram by group\n\nun_dta %>% \n  ggplot() + \n  aes(x = ppgdp, fill = group) + \n  geom_histogram(bins = 10, colour = \"black\") +\n  facet_grid(group ~ ., scales = \"free_y\") +\n  labs(x = \"GDP per capita, 2010 USD\", y = \"Frequency\")"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#histogram-x-transformation-1",
    "href": "slides/20-data-description/exploring-numeric-data.html#histogram-x-transformation-1",
    "title": "Exploring numerical data",
    "section": "Histogram: x transformation (1)",
    "text": "Histogram: x transformation (1)\n\nun_dta %>% \n  ggplot() + \n  aes(x = ppgdp, fill = group) + \n  geom_histogram(bins = 5, colour = \"black\") +\n  labs(x = \"GDP per capita, 2010 USD\", y = \"Frequency\")"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#histogram-x-transformation-1-1",
    "href": "slides/20-data-description/exploring-numeric-data.html#histogram-x-transformation-1-1",
    "title": "Exploring numerical data",
    "section": "Histogram: x transformation (1)",
    "text": "Histogram: x transformation (1)\n\nun_dta %>% \n  ggplot() + \n  aes(x = ppgdp, fill = group) + \n  geom_histogram(bins = 5, colour = \"black\") +\n  scale_x_log10() +\n  labs(x = \"GDP per capita, 2010 USD\", y = \"Frequency\")"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#histogram-x-transformation-1-2",
    "href": "slides/20-data-description/exploring-numeric-data.html#histogram-x-transformation-1-2",
    "title": "Exploring numerical data",
    "section": "Histogram: x transformation (1)",
    "text": "Histogram: x transformation (1)\n\nun_dta %>%\n  mutate(log_ppgdp = log10(ppgdp)) %>% \n  ggplot() + \n  aes(x = log_ppgdp, fill = group) + \n  geom_histogram(bins = 5, colour = \"black\") +\n  labs(x = \"Log of GDP per capita (log base 10), 2010 USD\", y = \"Frequency\")"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#histogram-x-transformation-1-3",
    "href": "slides/20-data-description/exploring-numeric-data.html#histogram-x-transformation-1-3",
    "title": "Exploring numerical data",
    "section": "Histogram: x transformation (1)",
    "text": "Histogram: x transformation (1)\n\n\n\n\n\n\nWarning\n\n\nWhat is special about bins width, when we apply a transformation to x?\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\nBins width start to vary, when we transform the data.\nThis is opposed to the fixed bins width when data is not transformed."
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#histogram-x-transformation-1-4",
    "href": "slides/20-data-description/exploring-numeric-data.html#histogram-x-transformation-1-4",
    "title": "Exploring numerical data",
    "section": "Histogram: x transformation (1)",
    "text": "Histogram: x transformation (1)\nMin, max and width of bins:\n\n\nNo transformation\n\n\n       xmin      xmax     diff\n1  -5832.26   5832.26 11664.51\n2   5832.26  17496.77 11664.51\n3  17496.77  29161.28 11664.51\n4  29161.28  40825.79 11664.51\n5  40825.79  52490.30 11664.51\n6  52490.30  64154.81 11664.51\n7  64154.81  75819.32 11664.51\n8  75819.32  87483.83 11664.51\n9  87483.83  99148.34 11664.51\n10 99148.34 110812.86 11664.51\n\n\n\nlog10() transformation\n\n\n       xmin      xmax     diff\n1     64.55    137.71    73.16\n2    137.71    293.79   156.08\n3    293.79    626.77   332.98\n4    626.77   1337.14   710.37\n5   1337.14   2852.65  1515.51\n6   2852.65   6085.83  3233.18\n7   6085.83  12983.49  6897.66\n8  12983.49  27698.91 14715.42\n9  27698.91  59092.73 31393.82\n10 59092.73 126068.14 66975.41"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#density-plot-basics",
    "href": "slides/20-data-description/exploring-numeric-data.html#density-plot-basics",
    "title": "Exploring numerical data",
    "section": "Density plot: basics",
    "text": "Density plot: basics\n\n\n\n\n\n\nImportant\n\n\nCheck the gallery https://r-graph-gallery.com/density-plot;\nLearn about density plots here: https://www.data-to-viz.com/graph/density.html"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#density-plot-example",
    "href": "slides/20-data-description/exploring-numeric-data.html#density-plot-example",
    "title": "Exploring numerical data",
    "section": "Density plot: example",
    "text": "Density plot: example\n\nun_dta %>% \n  ggplot() + \n  aes(x = ppgdp, fill = group) + \n  geom_density(alpha = 0.5) +\n  scale_x_log10() +\n  labs(x = \"GDP per capita, 2010 USD\", y = \"Density\")"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#density-plot-adjust",
    "href": "slides/20-data-description/exploring-numeric-data.html#density-plot-adjust",
    "title": "Exploring numerical data",
    "section": "Density plot: adjust",
    "text": "Density plot: adjust\n\nun_dta %>% \n  ggplot() + \n  aes(x = ppgdp, fill = group) + \n  geom_density(alpha = 0.5, adjust = 0.1) +\n  scale_x_log10() +\n  labs(x = \"GDP per capita, 2010 USD\", y = \"Density\")"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#density-plot-adjust-1",
    "href": "slides/20-data-description/exploring-numeric-data.html#density-plot-adjust-1",
    "title": "Exploring numerical data",
    "section": "Density plot: adjust",
    "text": "Density plot: adjust\n\nun_dta %>% \n  ggplot() + \n  aes(x = ppgdp, fill = group) + \n  geom_density(alpha = 0.5, adjust = 1) +\n  scale_x_log10() +\n  labs(x = \"GDP per capita, 2010 USD\", y = \"Density\")"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#density-plot-adjust-2",
    "href": "slides/20-data-description/exploring-numeric-data.html#density-plot-adjust-2",
    "title": "Exploring numerical data",
    "section": "Density plot: adjust",
    "text": "Density plot: adjust\n\nun_dta %>% \n  ggplot() + \n  aes(x = ppgdp, fill = group) + \n  geom_density(alpha = 0.5, adjust = 10) +\n  scale_x_log10() +\n  labs(x = \"GDP per capita, 2010 USD\", y = \"Density\")"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#scatter-plot-basics",
    "href": "slides/20-data-description/exploring-numeric-data.html#scatter-plot-basics",
    "title": "Exploring numerical data",
    "section": "Scatter plot: basics",
    "text": "Scatter plot: basics\n\n\n\n\n\n\nImportant\n\n\nCheck the gallery https://r-graph-gallery.com/scatterplot.html;\nLearn more about scatter plots here: https://www.data-to-viz.com/graph/scatter.html"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#simple-scatter-plot",
    "href": "slides/20-data-description/exploring-numeric-data.html#simple-scatter-plot",
    "title": "Exploring numerical data",
    "section": "Simple scatter plot",
    "text": "Simple scatter plot\n\nun_dta\n\n# A tibble: 199 × 6\n   region     group  fertility  ppgdp lifeExpF pctUrban\n   <fct>      <fct>      <dbl>  <dbl>    <dbl>    <dbl>\n 1 Asia       other       5.97   499      49.5       23\n 2 Europe     other       1.52  3677.     80.4       53\n 3 Africa     africa      2.14  4473      75         67\n 4 Africa     africa      5.14  4322.     53.2       59\n 5 Caribbean  other       2    13750.     81.1      100\n 6 Latin Amer other       2.17  9162.     79.9       93\n 7 Asia       other       1.74  3031.     77.3       64\n 8 Caribbean  other       1.67 22852.     77.8       47\n 9 Oceania    oecd        1.95 57119.     84.3       89\n10 Europe     oecd        1.35 45159.     83.6       68\n# … with 189 more rows"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#simple-scatter-plot-1",
    "href": "slides/20-data-description/exploring-numeric-data.html#simple-scatter-plot-1",
    "title": "Exploring numerical data",
    "section": "Simple scatter plot",
    "text": "Simple scatter plot\n\nun_dta %>%\n  ggplot()"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#simple-scatter-plot-2",
    "href": "slides/20-data-description/exploring-numeric-data.html#simple-scatter-plot-2",
    "title": "Exploring numerical data",
    "section": "Simple scatter plot",
    "text": "Simple scatter plot\n\nun_dta %>%\n  ggplot() +\n  aes(x = lifeExpF, y = fertility)"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#simple-scatter-plot-3",
    "href": "slides/20-data-description/exploring-numeric-data.html#simple-scatter-plot-3",
    "title": "Exploring numerical data",
    "section": "Simple scatter plot",
    "text": "Simple scatter plot\n\nun_dta %>%\n  ggplot() +\n  aes(x = lifeExpF, y = fertility) +\n  geom_point()"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#simple-scatter-plot-4",
    "href": "slides/20-data-description/exploring-numeric-data.html#simple-scatter-plot-4",
    "title": "Exploring numerical data",
    "section": "Simple scatter plot",
    "text": "Simple scatter plot\n\nun_dta %>%\n  ggplot() +\n  aes(x = lifeExpF, y = fertility) +\n  geom_point() +\n  labs(x = \"Life expectancy of wemen at birth\", y = \"Fertility, children per woman\")"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#scatter-plot-make-it-rich-with-colour",
    "href": "slides/20-data-description/exploring-numeric-data.html#scatter-plot-make-it-rich-with-colour",
    "title": "Exploring numerical data",
    "section": "Scatter plot: make it rich with colour",
    "text": "Scatter plot: make it rich with colour\n\nun_dta %>%\n  ggplot() +\n  aes(x = lifeExpF, y = fertility, color = group) +\n  geom_point() +\n  labs(x = \"Life expectancy of wemen at birth\", y = \"Fertility, children per woman\", color = \"\")"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#scatter-plot-make-it-rich-with-size",
    "href": "slides/20-data-description/exploring-numeric-data.html#scatter-plot-make-it-rich-with-size",
    "title": "Exploring numerical data",
    "section": "Scatter plot: make it rich with size",
    "text": "Scatter plot: make it rich with size\n\nun_dta %>%\n  ggplot() +\n  aes(x = lifeExpF, y = fertility, color = group, size = ppgdp) +\n  geom_point() +\n  labs(x = \"Life expectancy of wemen at birth\", y = \"Fertility, children per woman\", color = \"\", size = \"GDP/cap.\")"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#takeaway-1",
    "href": "slides/20-data-description/exploring-numeric-data.html#takeaway-1",
    "title": "Exploring numerical data",
    "section": "Takeaway",
    "text": "Takeaway\nSummary statistics:\n\nExtracting one variable with pull() and $;\ndplyr::summarise() + dplyr::group_by();\nskimr + report;\n\n\nBoxplot: geom_boxplot(), simple and by groups;\n\n\nHistogram: geom_histogram(), bins, scale_x_log10()\n\nbins is important as it changes a perspective;\ndata transformation changes bins width;\n\n\n\nScatter plot:\n\nCreate plots with rich visual details;\nBe clear and explicit with labels;"
  },
  {
    "objectID": "slides/20-data-description/exploring-numeric-data.html#references-1",
    "href": "slides/20-data-description/exploring-numeric-data.html#references-1",
    "title": "Exploring numerical data",
    "section": "References",
    "text": "References\n\n\n\nhttps://ebukin.github.io/mp223-2022-aem-R-public/\n\n\n\nWeisberg, Sanford. 2005. Applied Linear Regression. John Wiley & Sons, Inc. https://doi.org/10.1002/0471704091."
  },
  {
    "objectID": "slides/00-introduction/00-introduction.html#mp223---applied-econometrics-methods-for-the-social-sciences",
    "href": "slides/00-introduction/00-introduction.html#mp223---applied-econometrics-methods-for-the-social-sciences",
    "title": "Introduction. Organisation. Setup.",
    "section": "MP223 - Applied Econometrics Methods for the Social Sciences",
    "text": "MP223 - Applied Econometrics Methods for the Social Sciences\nAuthor: Eduard Bukin (StudIP profile)\nEmail: eduardbukin@agrar.uni-giessen.de,\nTelephone: +49 641 99-37055\nOffice: Zeughaus (Senckenbergstr. 3). Room: 132.\nOffice hours: Part time (better to make an appointment)"
  },
  {
    "objectID": "slides/00-introduction/00-introduction.html#introduction",
    "href": "slides/00-introduction/00-introduction.html#introduction",
    "title": "Introduction. Organisation. Setup.",
    "section": "Introduction",
    "text": "Introduction\nWelcome to the MP223 - Applied Econometrics Methods for the Social Sciences!"
  },
  {
    "objectID": "slides/00-introduction/00-introduction.html#lecturers-christoph-funk",
    "href": "slides/00-introduction/00-introduction.html#lecturers-christoph-funk",
    "title": "Introduction. Organisation. Setup.",
    "section": "Lecturers: Christoph Funk",
    "text": "Lecturers: Christoph Funk\nChristoph.Funk@wirtschaft.uni-giessen.de. Website.\nPost Doc.\n\nCenter for international Development and Environmental Research (ZEU) Justus Liebig Universität\n\n2020 - PhD in economics from Justus Liebig University Giessen\nResearch interests: - SDG monitoring - Climate change vulnerability - Adaptation strategies - Energy economics - Econometric modelling"
  },
  {
    "objectID": "slides/00-introduction/00-introduction.html#lecturers-vladimir-otrachshenko",
    "href": "slides/00-introduction/00-introduction.html#lecturers-vladimir-otrachshenko",
    "title": "Introduction. Organisation. Setup.",
    "section": "Lecturers: Vladimir Otrachshenko",
    "text": "Lecturers: Vladimir Otrachshenko\nVladimir.Otrachshenko@zeu.uni-giessen.de. Website.\nSenior Researcher.\n\nCenter for international Development and Environmental Research (ZEU) Justus Liebig Universität\n\n2013 - PhD in Economics from Nova School of Business and Economics, Lisbon, Portugal\nResearch interests:\n\nEnvironmental and Resource Economics\nClimate Change\nHealth and Population Economics"
  },
  {
    "objectID": "slides/00-introduction/00-introduction.html#lecturers-eduard-bukin",
    "href": "slides/00-introduction/00-introduction.html#lecturers-eduard-bukin",
    "title": "Introduction. Organisation. Setup.",
    "section": "Lecturers: Eduard Bukin",
    "text": "Lecturers: Eduard Bukin\neduardbukin@agrar.uni-giessen.de, (StudIP profile)\nData science enthusiast, econometrics practitioner. PhD Student.\n\nInstitute of Agricultural Policy and Market Research\n\n2015 – MSc in Rural Development:\n\nGhent University, Belgium\n\nResearch interests:\n\nRestructuring and productivity change in agriculture\nLand and labor factor markets in agriculture"
  },
  {
    "objectID": "slides/00-introduction/00-introduction.html#your-turn",
    "href": "slides/00-introduction/00-introduction.html#your-turn",
    "title": "Introduction. Organisation. Setup.",
    "section": "Your turn!",
    "text": "Your turn!\nPlease introduce yourself\n\nWhat is your name?\nWhere do you come from?\n\n\nWhat do you study?\nWhat is your background?\n\n\nWhat are your expectations?"
  },
  {
    "objectID": "slides/00-introduction/00-introduction.html#course-structure-and-overview-14",
    "href": "slides/00-introduction/00-introduction.html#course-structure-and-overview-14",
    "title": "Introduction. Organisation. Setup.",
    "section": "Course structure and overview (1/4)",
    "text": "Course structure and overview (1/4)\nMP223 - Applied Econometrics Methods for the Social Sciences is taught in presence.\n\n\nEvery Wednesday 14:00 - 18:00, Room: Senckenbergstr. 03, 216 (Ze-PC2)\nWear a mask all the time.\nGet a new mask from a lecturer for every lecture.\nOptional, make a COVID-19 speed tests if you do no feel well (ask the test from a lecturer).\nPlease, do not show up if you are sick."
  },
  {
    "objectID": "slides/00-introduction/00-introduction.html#course-structure-and-overview-24",
    "href": "slides/00-introduction/00-introduction.html#course-structure-and-overview-24",
    "title": "Introduction. Organisation. Setup.",
    "section": "Course structure and overview (2/4)",
    "text": "Course structure and overview (2/4)\n\nOnline resources:\n\nIlias is used for materials dissemination;\nStudIP is only used for announcements.\n\n\n\nRough course structure is in the Course Plan on Ilias.\n\n\nAlmost every week will have a checklist\n\nsummary of materials from the class;\nkey materials to cover on your own;"
  },
  {
    "objectID": "slides/00-introduction/00-introduction.html#course-structure-and-overview-34",
    "href": "slides/00-introduction/00-introduction.html#course-structure-and-overview-34",
    "title": "Introduction. Organisation. Setup.",
    "section": "Course structure and overview (3/4)",
    "text": "Course structure and overview (3/4)\nLectures\n\nSlides on Ilias. No pre-recording;\n“Takeaways” slides in th end of a lecture (if available);\n\n\nApplication exercises in class\n\nSometimes have pre requisites (watch a video, read a paper)\nSometimes require preparation in advance;\n\n\n\n\nSeminar discussions - definitely require preparation (reading papers) in advance;\n\n\n\nApplication exercises at home\n\nSome are mandatory, some are optional but highly recommended.\nWith /or without video guidance."
  },
  {
    "objectID": "slides/00-introduction/00-introduction.html#course-structure-and-overview-44",
    "href": "slides/00-introduction/00-introduction.html#course-structure-and-overview-44",
    "title": "Introduction. Organisation. Setup.",
    "section": "Course structure and overview (4/4)",
    "text": "Course structure and overview (4/4)\nExamination:\n\n60% written exam\n\n\n\n40% practical homework on R analysis.\n\nWill be disseminated on the week 4-6.\nDeadline: end of semester."
  },
  {
    "objectID": "slides/00-introduction/00-introduction.html#any-questions",
    "href": "slides/00-introduction/00-introduction.html#any-questions",
    "title": "Introduction. Organisation. Setup.",
    "section": "Any questions?",
    "text": "Any questions?"
  },
  {
    "objectID": "slides/00-introduction/00-introduction.html#plan-for-today",
    "href": "slides/00-introduction/00-introduction.html#plan-for-today",
    "title": "Introduction. Organisation. Setup.",
    "section": "Plan for today",
    "text": "Plan for today\nNext 45 minutes: Application Exercise 01 - Soft introduction to R\n\nin class we will do “ae01a-vaccination.Rmd” everything else is at home;\n\n\nTwo Lectures (90 min):\n\nCeteris Paribus\nSelection Bias\n\n\n\nApplication Exercise at home.\n\nSee the check list."
  },
  {
    "objectID": "slides/00-introduction/00-introduction.html#application-exercise-01---soft-introduction-to-r",
    "href": "slides/00-introduction/00-introduction.html#application-exercise-01---soft-introduction-to-r",
    "title": "Introduction. Organisation. Setup.",
    "section": "Application Exercise 01 - Soft introduction to R",
    "text": "Application Exercise 01 - Soft introduction to R\n\nTurn on your PC\n\n\n\n\n\n\nImportant\n\n\nLogin: ZH-user-pcl\nPassword: V5-senc!3ken\n\n\n\n\n\nWrite them down and remember.\nSame password an login will be used on all PCs in Zeughaus."
  },
  {
    "objectID": "slides/00-introduction/00-introduction.html#log-into-studip-and-ilias",
    "href": "slides/00-introduction/00-introduction.html#log-into-studip-and-ilias",
    "title": "Introduction. Organisation. Setup.",
    "section": "Log into studIP and Ilias",
    "text": "Log into studIP and Ilias\n\nLog into your studIP;\n\n\nFollow to “Ilias >> Kurs (ID 301421) in JLUG”;\n\n\n\n\n\n\n\n\n\n\n\nLog in to Ilias;\n\n\nDownload ae01-soft-intro-to-R.zip to downloads;"
  },
  {
    "objectID": "slides/00-introduction/00-introduction.html#setup-working-folders",
    "href": "slides/00-introduction/00-introduction.html#setup-working-folders",
    "title": "Introduction. Organisation. Setup.",
    "section": "Setup working folders",
    "text": "Setup working folders\n\nNavigate to your user folder: C > Users > Name of your user account;\n\n\n\nCreate there a course folder names {your initial}-mk223-2022.\n\nUse it for your course for all in-class work;\non my pc the course folder is called eb-mk223-2022;\nthe full path is C:\\Users\\ZH-user-pcl\\eb-mk223-2022;\n\n\n\n\n\nPaste ae01-soft-intro-to-R.zip from downloads to the course folder;\n\n\n\n\nUnzip ae01-soft-intro-to-R.zip into ae01-soft-intro-to-R;"
  },
  {
    "objectID": "slides/00-introduction/00-introduction.html#launch-the-r-studio-from-the-project-ae01-soft-intro-to-r",
    "href": "slides/00-introduction/00-introduction.html#launch-the-r-studio-from-the-project-ae01-soft-intro-to-r",
    "title": "Introduction. Organisation. Setup.",
    "section": "Launch the R Studio from the project “ae01-soft-intro-to-R”",
    "text": "Launch the R Studio from the project “ae01-soft-intro-to-R”\n\n\nNavigate to ae01-soft-intro-to-R in your course folder\n\n\n\n\nOpen ae01-soft-intro-to-R.Rproj that has R studio icon and .Rproj extension:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsta210-s22.github.io/website"
  },
  {
    "objectID": "slides/10-simple-regression/10-simple-regression.html#pearson-lee-data",
    "href": "slides/10-simple-regression/10-simple-regression.html#pearson-lee-data",
    "title": "Simple regression",
    "section": "Pearson-Lee data",
    "text": "Pearson-Lee data\n\nData used is published in (Pearson and Lee 1903).\nKarl Pearson collected data on over 1100 families in England in the period 1893 to 1898;\nHeights of mothers mheight and daughters dheight was recorded for 1375 observations.\nWe rely on the examples of SLR in (Weisberg 2005)"
  },
  {
    "objectID": "slides/10-simple-regression/10-simple-regression.html#data-loading-and-preparation",
    "href": "slides/10-simple-regression/10-simple-regression.html#data-loading-and-preparation",
    "title": "Simple regression",
    "section": "Data loading and preparation",
    "text": "Data loading and preparation\n\n\nLoading data\nConverting data frame into a tibble() object\nRenaming variables\nGlimpse of data\n\n\n\n\n\nCode\n# Note, we use `sample_n(400)` to randomly select only 400 observations\ndta <- \n  alr4::Heights %>% \n  as_tibble() %>% \n  rename(mother_height = mheight,\n         daughter_height = dheight) %>% \n  sample_n(400)\nglimpse(dta)\n\n\nRows: 400\nColumns: 2\n$ mother_height   <dbl> 58.8, 65.4, 65.5, 63.2, 60.1, 61.2, 60.8, 63.7, 63.8, …\n$ daughter_height <dbl> 62.7, 66.2, 62.8, 62.2, 65.1, 64.8, 63.4, 64.3, 62.5, …"
  },
  {
    "objectID": "slides/10-simple-regression/10-simple-regression.html#exploring-data-scatter-plot",
    "href": "slides/10-simple-regression/10-simple-regression.html#exploring-data-scatter-plot",
    "title": "Simple regression",
    "section": "Exploring data (Scatter plot)",
    "text": "Exploring data (Scatter plot)\n\nPlotImprove the code yourself\n\n\n\n\nCode\nplt <- \n  dta %>% \n  ggplot() + \n  aes(x = mother_height, y = daughter_height) + \n  geom_point(alpha = 0.5) + \n  theme_minimal()\nplt\n\n\n\n\n\n\n\n\n\n\n\n\nWhat alpha = 0.5 stands for?\nAdd labels.\nchange color of points (add color = \"red\" after alpha separating arguments with comma)\n\n\n\nCode\ndta %>% \n  ggplot() + \n  aes(x = mother_height, y = daughter_height) + \n  geom_point(alpha = 0.5) + \n  labs(x = \"___________\", \n       y = \"___________\")"
  },
  {
    "objectID": "slides/10-simple-regression/10-simple-regression.html#simple-regression-line",
    "href": "slides/10-simple-regression/10-simple-regression.html#simple-regression-line",
    "title": "Simple regression",
    "section": "Simple regression line",
    "text": "Simple regression line\n\n\n\n\\(Y \\\\ = \\color{green}{f(X)} \\\\ + \\text{Error term} \\\\ = \\color{green}{E[Y|X]} + \\epsilon\\)\n\n\n\n\nCode\nfit <- \n  lm(daughter_height ~ mother_height, data = dta)\nplt <- \n  plt + \n  labs(x = \"Mothers' height\", \n       y = \"Daughter height\") + \n  geom_smooth(method = \"lm\", \n              color = \"green\", \n              se = FALSE) + \n  theme_minimal()\nplt"
  },
  {
    "objectID": "slides/10-simple-regression/10-simple-regression.html#simple-regression",
    "href": "slides/10-simple-regression/10-simple-regression.html#simple-regression",
    "title": "Simple regression",
    "section": "Simple regression",
    "text": "Simple regression\n\\[\\Large{Y = \\beta_0 + \\beta_1 X}\\]\n\n\n\\(Y\\): dependent variable, observed values\n\\(X\\): independent variable\n\\(\\beta_1\\): True slope\n\\(\\beta_0\\): True intercept\nNote, in the population regression function, there is no error terms!"
  },
  {
    "objectID": "slides/10-simple-regression/10-simple-regression.html#estimated-simple-regression",
    "href": "slides/10-simple-regression/10-simple-regression.html#estimated-simple-regression",
    "title": "Simple regression",
    "section": "Estimated simple regression",
    "text": "Estimated simple regression\n\\[\\Large{\\hat{Y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 X}\\]\n\n\n\\(\\hat{Y}\\): fitted values, predicted values\n\\(\\hat{\\beta}_1\\): Estimated slope\n\\(\\hat{\\beta}_0\\): Estimated intercept\nNo error term!"
  },
  {
    "objectID": "slides/10-simple-regression/10-simple-regression.html#residuals",
    "href": "slides/10-simple-regression/10-simple-regression.html#residuals",
    "title": "Simple regression",
    "section": "Residuals",
    "text": "Residuals\n\n\n\\(Y \\\\ = \\color{green}{f(X)} \\\\ + \\color{blue}{\\text{Error term}} \\\\ = \\color{green}{E[Y|X]} + \\color{blue}{\\epsilon}\\)\n\n\n\nCode\nplt + \n  geom_segment(\n    aes(x = mother_height, xend = mother_height,\n        y = daughter_height, yend = predict(fit)), \n    color = \"blue\",\n    alpha = 0.4\n  )"
  },
  {
    "objectID": "slides/10-simple-regression/10-simple-regression.html#residuals-1",
    "href": "slides/10-simple-regression/10-simple-regression.html#residuals-1",
    "title": "Simple regression",
    "section": "Residuals",
    "text": "Residuals\n\n\n\\(\\text{residuals} \\\\ = \\text{observed} - \\text{predicted} \\\\ = \\epsilon = Y - \\hat{Y}\\)\n\\({Y = \\hat{\\beta}_0 + \\hat{\\beta}_1 X + \\epsilon}\\)\n\\(\\epsilon\\) is the error term or residual\nFor each specific observation \\(i\\)\nresidual \\(e_i = y_i - \\hat{y_i}\\)\nsquared residual \\(e_i^2 = (y_i - \\hat{y_i})^2\\)"
  },
  {
    "objectID": "slides/10-simple-regression/10-simple-regression.html#ordinary-least-square-ols-1",
    "href": "slides/10-simple-regression/10-simple-regression.html#ordinary-least-square-ols-1",
    "title": "Simple regression",
    "section": "Ordinary Least Square (OLS)",
    "text": "Ordinary Least Square (OLS)\n\n\n\n\n“finds” values for \\(\\hat{\\beta}_0\\) and \\(\\hat{\\beta}_1\\)\neach new value of \\(\\hat{\\beta}_0\\) and \\(\\hat{\\beta}_1\\) generates new regression line;\n\n\n\n\n\nCode\nplt + \n  geom_segment(\n    aes(x = mother_height, xend = mother_height,\n        y = daughter_height, yend = predict(fit)), \n    color = \"blue\",\n    alpha = 0.4\n  ) + \n  geom_abline(intercept = 33, slope = 0.49, color = \"black\") + \n  geom_abline(intercept = 5, slope = 0.95, color = \"black\") + \n  geom_abline(intercept = 25, slope = 0.62, color = \"black\")"
  },
  {
    "objectID": "slides/10-simple-regression/10-simple-regression.html#ordinary-least-square-ols-2",
    "href": "slides/10-simple-regression/10-simple-regression.html#ordinary-least-square-ols-2",
    "title": "Simple regression",
    "section": "Ordinary Least Square (OLS)",
    "text": "Ordinary Least Square (OLS)\nthe OLS finds such values of \\(\\hat{\\beta}_0\\) and \\(\\hat{\\beta}_1\\) that minimizes the sum of squared residuals:\n\\[\n\\Large{\nSSR =\n\\sum_{i}^{n}{e_i^2} = \\sum_{i}^{n}{(y_i - \\hat{y_i})^2} \\\\ = {[e_1^2 + e_2^2 + ... + e_n^2]}\n}\n\\]"
  },
  {
    "objectID": "slides/10-simple-regression/10-simple-regression.html#properties-of-ols",
    "href": "slides/10-simple-regression/10-simple-regression.html#properties-of-ols",
    "title": "Simple regression",
    "section": "Properties of OLS",
    "text": "Properties of OLS\n\n\nThe regression line goes through the center of all point.\nThe sum of the residuals (not squared) is zero: \\(\\sum_{i}^n e_i = 0\\)\nZero correlation between residuals and regressors \\(Cov(X,\\epsilon) = 0\\)\nPredicted value of \\(Y\\), when all regressors are at means \\(\\bar{X}\\) is the mean of \\(\\bar{Y}\\): \\(E[Y|\\bar{X}] = \\bar{Y}\\)"
  },
  {
    "objectID": "slides/10-simple-regression/10-simple-regression.html#regression-coefficients",
    "href": "slides/10-simple-regression/10-simple-regression.html#regression-coefficients",
    "title": "Simple regression",
    "section": "Regression coefficients",
    "text": "Regression coefficients\n\nfit <- lm(daughter_height ~ mother_height, data = dta)\nfit\n\n\nCall:\nlm(formula = daughter_height ~ mother_height, data = dta)\n\nCoefficients:\n  (Intercept)  mother_height  \n      29.4551         0.5498"
  },
  {
    "objectID": "slides/10-simple-regression/10-simple-regression.html#regression-summary-13",
    "href": "slides/10-simple-regression/10-simple-regression.html#regression-summary-13",
    "title": "Simple regression",
    "section": "Regression summary (1/3)",
    "text": "Regression summary (1/3)\n\nsummary(fit)\n\n\nCall:\nlm(formula = daughter_height ~ mother_height, data = dta)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.6255 -1.5767 -0.0878  1.3916  9.0083 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   29.45511    2.91727   10.10   <2e-16 ***\nmother_height  0.54979    0.04662   11.79   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.337 on 398 degrees of freedom\nMultiple R-squared:  0.2589,    Adjusted R-squared:  0.2571 \nF-statistic: 139.1 on 1 and 398 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "slides/10-simple-regression/10-simple-regression.html#regression-summary-23",
    "href": "slides/10-simple-regression/10-simple-regression.html#regression-summary-23",
    "title": "Simple regression",
    "section": "Regression summary (2/3)",
    "text": "Regression summary (2/3)\n\nusing broom package overview and source code\n\n\nlibrary(broom)\ntidy(fit)\n\n# A tibble: 2 × 5\n  term          estimate std.error statistic  p.value\n  <chr>            <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)     29.5      2.92        10.1 1.71e-21\n2 mother_height    0.550    0.0466      11.8 9.88e-28\n\n\n\n\nglance(fit)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC\n      <dbl>         <dbl> <dbl>     <dbl>    <dbl> <dbl>  <dbl> <dbl> <dbl>\n1     0.259         0.257  2.34      139. 9.88e-28     1  -906. 1818. 1830.\n# … with 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>"
  },
  {
    "objectID": "slides/10-simple-regression/10-simple-regression.html#regression-summary-33",
    "href": "slides/10-simple-regression/10-simple-regression.html#regression-summary-33",
    "title": "Simple regression",
    "section": "Regression summary (3/3)",
    "text": "Regression summary (3/3)\n\nusing parameters package overview and source code\n\n\nlibrary(parameters)\nparameters(fit)\n\nParameter     | Coefficient |   SE |         95% CI | t(398) |      p\n---------------------------------------------------------------------\n(Intercept)   |       29.46 | 2.92 | [23.72, 35.19] |  10.10 | < .001\nmother height |        0.55 | 0.05 | [ 0.46,  0.64] |  11.79 | < .001\n\n\n\n\nusing performance package overview and source code\n\n\nlibrary(performance)\nperformance(fit)\n\n# Indices of model performance\n\nAIC      |      BIC |    R2 | R2 (adj.) |  RMSE | Sigma\n-------------------------------------------------------\n1818.301 | 1830.276 | 0.259 |     0.257 | 2.331 | 2.337"
  },
  {
    "objectID": "slides/10-simple-regression/10-simple-regression.html#intercept",
    "href": "slides/10-simple-regression/10-simple-regression.html#intercept",
    "title": "Simple regression",
    "section": "Intercept",
    "text": "Intercept\n\nImportant in the context of the data.\nValue of \\(Y\\) when all \\(X\\) are zero."
  },
  {
    "objectID": "slides/10-simple-regression/10-simple-regression.html#slope",
    "href": "slides/10-simple-regression/10-simple-regression.html#slope",
    "title": "Simple regression",
    "section": "Slope",
    "text": "Slope\nMarginal effect or unit change in \\(Y\\) on average, when \\(X\\) is being change by on unit, keeping all other regressors fixed.\n\nWhen mother’s height increases by 1 inch, the height of a daughter increases by \\(\\hat{\\beta_1}\\) inches, keeping other variables constant."
  },
  {
    "objectID": "slides/10-simple-regression/10-simple-regression.html#residuals-2",
    "href": "slides/10-simple-regression/10-simple-regression.html#residuals-2",
    "title": "Simple regression",
    "section": "Residuals",
    "text": "Residuals\n\n# With `[1:20]` we foce R only to print first 20 values\nresiduals(fit)[1:20]\n\n         1          2          3          4          5          6          7 \n 0.9173961  0.7887997 -2.6661790 -2.0016682  2.6026726  1.6979065  0.5178215 \n         8          9         10         11         12         13         14 \n-0.1765618 -2.0315406 -1.5917107 -5.4523061 -5.1774125  0.8022473 -1.4757112 \n        15         16         17         18         19         20 \n-3.4674550  4.0178215 -0.6813279 -3.6462641  1.8927151 -4.2860940 \n\nresid(fit)[1:20]\n\n         1          2          3          4          5          6          7 \n 0.9173961  0.7887997 -2.6661790 -2.0016682  2.6026726  1.6979065  0.5178215 \n         8          9         10         11         12         13         14 \n-0.1765618 -2.0315406 -1.5917107 -5.4523061 -5.1774125  0.8022473 -1.4757112 \n        15         16         17         18         19         20 \n-3.4674550  4.0178215 -0.6813279 -3.6462641  1.8927151 -4.2860940"
  },
  {
    "objectID": "slides/10-simple-regression/10-simple-regression.html#fitted",
    "href": "slides/10-simple-regression/10-simple-regression.html#fitted",
    "title": "Simple regression",
    "section": "Fitted",
    "text": "Fitted\n\n# With `[1:20]` we foce R only to print first 20 values\nfitted(fit)[1:20]\n\n       1        2        3        4        5        6        7        8 \n61.78260 65.41120 65.46618 64.20167 62.49733 63.10209 62.88218 64.47656 \n       9       10       11       12       13       14       15       16 \n64.53154 64.09171 62.55231 62.27741 61.39775 66.67571 62.16746 62.88218 \n      17       18       19       20 \n65.08133 65.24626 62.60728 65.68609"
  },
  {
    "objectID": "slides/10-simple-regression/10-simple-regression.html#residuals-vs-fitted-13",
    "href": "slides/10-simple-regression/10-simple-regression.html#residuals-vs-fitted-13",
    "title": "Simple regression",
    "section": "Residuals vs fitted (1/3)",
    "text": "Residuals vs fitted (1/3)\n\ndta_1 <- \n  dta %>% \n  mutate(fitted = fitted(fit)) %>% \n  mutate(residuals = resid(fit))\n\nglimpse(dta_1)\n\nRows: 400\nColumns: 4\n$ mother_height   <dbl> 58.8, 65.4, 65.5, 63.2, 60.1, 61.2, 60.8, 63.7, 63.8, …\n$ daughter_height <dbl> 62.7, 66.2, 62.8, 62.2, 65.1, 64.8, 63.4, 64.3, 62.5, …\n$ fitted          <dbl> 61.78260, 65.41120, 65.46618, 64.20167, 62.49733, 63.1…\n$ residuals       <dbl> 0.9173961, 0.7887997, -2.6661790, -2.0016682, 2.602672…"
  },
  {
    "objectID": "slides/10-simple-regression/10-simple-regression.html#residuals-vs-fitted-23",
    "href": "slides/10-simple-regression/10-simple-regression.html#residuals-vs-fitted-23",
    "title": "Simple regression",
    "section": "Residuals vs fitted (2/3)",
    "text": "Residuals vs fitted (2/3)\n\ndta_1 %>% \n  ggplot() + \n  aes(x = fitted, y = residuals) + \n  geom_point()"
  },
  {
    "objectID": "slides/10-simple-regression/10-simple-regression.html#residuals-vs-fitted-33",
    "href": "slides/10-simple-regression/10-simple-regression.html#residuals-vs-fitted-33",
    "title": "Simple regression",
    "section": "Residuals vs fitted (3/3)",
    "text": "Residuals vs fitted (3/3)\n\nlibrary(performance)\nlibrary(see)\ncheck_model(fit, check = \"linearity\", panel = FALSE)\n\n$NCV"
  },
  {
    "objectID": "slides/10-simple-regression/10-simple-regression.html#takeaway",
    "href": "slides/10-simple-regression/10-simple-regression.html#takeaway",
    "title": "Simple regression",
    "section": "Takeaway",
    "text": "Takeaway\n\nSimple linear regression\nOLS\nSlope and Intercept (interpretation)\nFitted values\nResiduals\nResiduals vs Fitted\n\n\n\nfitting regression: fit()\nregression summary: summary(), tidy(), glance(), parameters(), performance() , check_model() , fitted() , residuals() , resid()\npackages: broom, parameters and performance"
  },
  {
    "objectID": "slides/10-simple-regression/10-simple-regression.html#references-1",
    "href": "slides/10-simple-regression/10-simple-regression.html#references-1",
    "title": "Simple regression",
    "section": "References",
    "text": "References\n\n\n\nhttps://ebukin.github.io/mp223-2022-aem-R-public/\n\n\n\nPearson, Karl, and Alice Lee. 1903. “On the Laws of Inheritance in Man: I. Inheritance of Physical Characters.” Biometrika 2 (4): 357. https://doi.org/10.2307/2331507.\n\n\nWeisberg, Sanford. 2005. Applied Linear Regression. John Wiley & Sons, Inc. https://doi.org/10.1002/0471704091."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "mp223 Applied Econometric Methods for the Social Sciences (SoSe 2022)",
    "section": "",
    "text": "This is the website where most lectures, R application exercises and supplementary materials are developed for the course MP223 Applied Econometric Methods for the Social Sciences (SoSe 2022). it is not a substitute of course Ilias or course StudIP pages, but rather a convenient way of making the slides accessible, downloadable and nice."
  },
  {
    "objectID": "weeks/week05-checklist.html",
    "href": "weeks/week05-checklist.html",
    "title": "Week 5",
    "section": "",
    "text": "In class\n\n\n\n\nSLIDES: 🖥W05-01 Omitted variable bias\nApplication Exercise: 📋ae05-01-OVB.rmd\nDownload here ae/ae05-multiple-regression-part-2.zip or on Ilias.\n\n\n\n\n\n\n\n\n\nSELF STUDY\n\n\n\n\nHomework section of the application exercise: 📋ae05-01-OVB.rmd\nApplication Exercise: 📋ae05-02-HW-slides-ovb.Rmd\n\n\n\n\nWatch:   Regression Part I: Call in the CIA\nWatch:   Regression Part II: Theory"
  },
  {
    "objectID": "weeks/week05-checklist.html#w05-02-collinearity-and-heteroscedasticity",
    "href": "weeks/week05-checklist.html#w05-02-collinearity-and-heteroscedasticity",
    "title": "Week 5",
    "section": "W05-02 Collinearity and Heteroscedasticity",
    "text": "W05-02 Collinearity and Heteroscedasticity\n\n\n\n\n\n\nIn class\n\n\n\n\nSLIDES: 🖥W05-02 Collinearity\nSLIDES: 🖥W05-03 Heteroscedasticity"
  },
  {
    "objectID": "weeks/week05-checklist.html#w05-03-hedonic-model",
    "href": "weeks/week05-checklist.html#w05-03-hedonic-model",
    "title": "Week 5",
    "section": "W05-03 Hedonic model",
    "text": "W05-03 Hedonic model\n\n\n\n\n\n\nIn class\n\n\n\n\nSLIDES: 🖥W05-04 Hedonic Prices Model\nApplication Exercise: 📋ae05-03-hedonic-complete-reg-analysis.Rmd\n\n\n\n\n\n\n\n\n\nSELF STUDY\n\n\n\n\nHomework section of the application exercise: 📋ae05-03-hedonic-complete-reg-analysis.Rmd"
  },
  {
    "objectID": "weeks/week04-checklist.html",
    "href": "weeks/week04-checklist.html",
    "title": "Week 4",
    "section": "",
    "text": "SELF STUDY\n\n\n\n\nSLIDES: 🖥W04-00 Simple regression\nApplication Exercise: 📋ae04-00-simple-regression-from-slides-HW.R\n\nPerform all the R analysis from slides in an R script.\n\n\n\n\n\nPractice:  Open Intro. Lab. Simple Regression\nRead: 📖 Introduction to Modern Statistics. Ch. 7 Linear Regression with a single predictor"
  },
  {
    "objectID": "weeks/week04-checklist.html#w04-01-multiple-regression",
    "href": "weeks/week04-checklist.html#w04-01-multiple-regression",
    "title": "Week 4",
    "section": "W04-01 Multiple Regression",
    "text": "W04-01 Multiple Regression\n\n\n\n\n\n\nIn class\n\n\n\n\nSLIDES: 🖥W04-01 Multiple Regression\nApplication Exercise: 📋ae04-01-MLR.Rmd\nDownload here ae04-multiple-regression-part-1.zip or on Ilias.\n\n\n\n\nPractice:  Open Intro. Lab. Multiple Regression\nRead:  Chapter 2. Regression in (Angrist and Pischke 2014), JLU: justfind.\nRead: 📖 Introduction to Modern Statistics. Ch. 8 Linear regression with multiple predictors"
  },
  {
    "objectID": "weeks/week04-checklist.html#w04-02-linearity",
    "href": "weeks/week04-checklist.html#w04-02-linearity",
    "title": "Week 4",
    "section": "W04-02 Linearity",
    "text": "W04-02 Linearity\n\n\n\n\n\n\nIn class\n\n\n\n\nSLIDES: 🖥W04-02 Linearity\nApplication Exercise: 📋ae04-02-MLR-linearity.Rmd"
  },
  {
    "objectID": "weeks/week04-checklist.html#w04-03-hedonic-prices-model",
    "href": "weeks/week04-checklist.html#w04-03-hedonic-prices-model",
    "title": "Week 4",
    "section": "W04-03 Hedonic prices model",
    "text": "W04-03 Hedonic prices model\n\n\n\n\n\n\nSELF STUDY\n\n\n\n\nSLIDES: 🖥W04-03 Hedonic Prices Model\nApplication Exercise: 📋ae04-03-hedonic-land-prices-HW.Rmd"
  },
  {
    "objectID": "weeks/week01-checklist.html",
    "href": "weeks/week01-checklist.html",
    "title": "Week 1",
    "section": "",
    "text": "Important\n\n\n\nThe class is in-person. We meet in the PC room 216 in Zeughaus."
  },
  {
    "objectID": "weeks/week01-checklist.html#to-do-before-the-week-3",
    "href": "weeks/week01-checklist.html#to-do-before-the-week-3",
    "title": "Week 1",
    "section": "To do before the Week 3",
    "text": "To do before the Week 3\n\nCheck 🖥 hw00-01 and watch  Installing R and R Studio (video 4:08)\nCheck 🖥 hw00-02 and watch  R and R Studio: introduction and interface (video 1:36)\nCheck 🖥 hw00-03 and watch  Setup working folders (video 3:54)\nCheck 🖥 hw00-04 and watch  Creating an RStudio project (video 4:06)\nCheck 🖥 hw00-05 and watch  Console: running R code in there (video 10:09)\nCheck 🖥 hw00-06 and watch  .R scripts: create, modify, run, save (video 4:34)\nCheck 🖥 hw00-07 and watch  .Rmd R Markdown: create, modify, save, Knit (video 4:54)\nCheck 🖥 hw00-08 Making an R scripts based on the example from the lecture “01 Ceteris Paribus”"
  },
  {
    "objectID": "weeks/week01-checklist.html#optional.-to-better-learn-r.-no-deadline.",
    "href": "weeks/week01-checklist.html#optional.-to-better-learn-r.-no-deadline.",
    "title": "Week 1",
    "section": "Optional. to better learn R. No deadline.",
    "text": "Optional. to better learn R. No deadline.\n\nCheck 🖥 hw00-09 and watch  Coding out loud: introduction to R and R Markdown (about 1 hour).\nCheck 🖥 hw00-10 doing 📋 ae01b-un-votes.Rmd about voting pattern of the countries in the UN General Assembly in 📋 ae01 under video guidance from  Mine Cetinkaya-Rundel."
  },
  {
    "objectID": "weeks/week01-checklist.html#some-other-videos-of-josh-angrist-to-watch.",
    "href": "weeks/week01-checklist.html#some-other-videos-of-josh-angrist-to-watch.",
    "title": "Week 1",
    "section": "Some other videos of Josh Angrist to watch.",
    "text": "Some other videos of Josh Angrist to watch.\n\n What’s the Difference Between Econometrics and Data Science?\n What’s the Difference Between Econometrics and Statistics?\n Isn’t Econometrics Boring?\n If I Master Econometrics, What Jobs Can I Get?\n Econometrics is the original data science"
  },
  {
    "objectID": "weeks/week03-checklist.html",
    "href": "weeks/week03-checklist.html",
    "title": "Week 3",
    "section": "",
    "text": "In class\n\n\n\n\nSLIDES: 🖥W03-00 Data Workflow + Tidy data + Wrangling\n\n\n\n\nRecommended. Practice:\n\n Primers: Programming basics\n\nRecommended. Read:\n\n R4DS Ch 9. Wrangle\n R4DS Ch. 12. Tidy data\nCHEATSHEET: Data tidying with tidyr cheatsheet\n\nOptional. Watch:\n\n Tidy data video + slides\n Grammar of data wrangling video + slides\n webinar: Data wrangling with R and RStudio"
  },
  {
    "objectID": "weeks/week03-checklist.html#w03-01-import-data",
    "href": "weeks/week03-checklist.html#w03-01-import-data",
    "title": "Week 3",
    "section": "W03-01 Import data",
    "text": "W03-01 Import data\n\n\n\n\n\n\nIn class\n\n\n\n\nApplication Exercise: 📋ae03-01-import-clean-sum-plot.Rmd\n\n\n\n\n\n\n\n\n\nSELF STUDY\n\n\n\n\nSLIDES: 🖥W03-02 Import data\n\n\n\n\nRecommended. Watch:\n\nData types video + slides\n\nRecommended. Read:\n\n R4DS Ch. 11 Data import\n\nOptional. Read:\n\nCHEATSHEET: Data import with the tidyverse\ntidyverse/readxl + tidyverse/readr + janitor\n\nOptional. Watch:\n\nImporting and recoding data\nData classes video + slides\nImporting data video + slides\n webinar: What’s new with readxl?"
  },
  {
    "objectID": "weeks/week03-checklist.html#w03-02-exploring-numerical-data",
    "href": "weeks/week03-checklist.html#w03-02-exploring-numerical-data",
    "title": "Week 3",
    "section": "W03-02 Exploring numerical data",
    "text": "W03-02 Exploring numerical data\n\n\n\n\n\n\nSELF STUDY\n\n\n\n\nSLIDES: 🖥W03-02 Exploring numerical data\nApplication Exercise: 📋 AE03-02 Exploring data on plstic waste + Solution to the ae03-02: ae03-02-plastic-waste-solutions.rmd\n\n\n\n\nRecommended. Practice:\n\n Primers: Derive Information with dplyr\n Open Intro. Interactive. Visualizing numerical data (takes time to load)\n Open Intro. Interactive. Summarizing data (takes time to load)\n Primers: Data Visualization Basics\n Primers: Histograms\n Primers: Boxplots and Counts\n Primers: Scatterplots\n\nOptional. Read:\n\n IMS: Chapter 5 Exploring numerical data\n\nOptional. Watch + Practice:\n\n Data and visualisation video + slides\n Visualising data with ggplot2 video + slides\n Visualising numerical data video + slides"
  },
  {
    "objectID": "weeks/week03-checklist.html#w03-03-correlation",
    "href": "weeks/week03-checklist.html#w03-03-correlation",
    "title": "Week 3",
    "section": "🖥 W03-03 Correlation",
    "text": "🖥 W03-03 Correlation\n\n\n\n\n\n\nIn class\n\n\n\n\nSLIDES: 🖥W03-04 correlation correlation\n\n\n\n\n\n\n\n\n\nSELF STUDY\n\n\n\n\nApplication Exercise: 📋ae03-03-correlation.Rmd\n\n\n\n\nRecommended. Practice:\n\n Primers: Exploratory data analysis\n\nRecommended. Read:\n\nInterpretation of the strength of correlation\n\nOptional. Read:\n\neasystats/correlation\nCorrelation types"
  },
  {
    "objectID": "weeks/week03-checklist.html#w03ae---application-exercise",
    "href": "weeks/week03-checklist.html#w03ae---application-exercise",
    "title": "Week 3",
    "section": "📋 W03AE - application exercise:",
    "text": "📋 W03AE - application exercise:\nDownload project from 📋 ae03-data-wrangling.zip or the same on Ilias: 📋 ae03-data-wrangling.zip on Ilias.\n\n\n\n\n\n\nIn class\n\n\n\n\nApplication Exercise: 📋ae03-01-import-clean-sum-plot.Rmd\n\n\n\n\n\n\n\n\n\nSELF STUDY\n\n\n\n\nApplication Exercise: 📋 ae03-02-correlation.Rmd\nApplication Exercise: 📋 ae03-02-plastic-waste.rmd"
  },
  {
    "objectID": "weeks/week03-checklist.html#self-study-exploring-categorical-data",
    "href": "weeks/week03-checklist.html#self-study-exploring-categorical-data",
    "title": "Week 3",
    "section": "🖥 SELF STUDY Exploring categorical data",
    "text": "🖥 SELF STUDY Exploring categorical data\n\nRecommended. Practice:\n\n Open Intro. Interactive. Visualizing categorical data (takes time to load)\n\nRecommended. Watch + Practice:\n\n webinar: Tidyverse visualization manipulation basics\n Visualising categorical data video + slides\n\nOptional. Read:\n\n IMS: Chapter 4 Exploring categorical data"
  },
  {
    "objectID": "weeks/week03-checklist.html#self-study-wrangle-with-dplyr",
    "href": "weeks/week03-checklist.html#self-study-wrangle-with-dplyr",
    "title": "Week 3",
    "section": "🖥 SELF STUDY Wrangle with dplyr",
    "text": "🖥 SELF STUDY Wrangle with dplyr\nWe use dplyr every day in any exercise. Thus, there is no point to dedicate specific time to it. Use this list of materials to guide your learning process. Most of the core functions of dplyr are covered in data other parts of the course.\nMaterials listed here may repeat the ones listed before.\n\nRecommended. Read:\n\n R4DS Chapter 5 Data transformation\nCHEATSHEET: Data transformation with dplyr\ntidyverse/dplyr\n\nRecommended. Practice:\n\n Primers: Working with Tibbles\n Primers: Isolating Data with dplyr\n Primers: Derive Information with dplyr\n Primers: Filter observations\n Open Intro. Interactive. Summarizing data (takes time to load)\nInteractive tutorial based on R4DS Ch. 5.6 Summarizing data"
  },
  {
    "objectID": "weeks/week03-checklist.html#self-study-data-visualization-with-ggplot2",
    "href": "weeks/week03-checklist.html#self-study-data-visualization-with-ggplot2",
    "title": "Week 3",
    "section": "🖥 SELF STUDY Data visualization with ggplot2",
    "text": "🖥 SELF STUDY Data visualization with ggplot2\nThere are many ways how data could be visualized in R. We do touch numerous visualization examples over the course. Therefore, dedicated mastering of the ggplot2 package is scheduled for self learning.\n\nRecommended. Read:\n\n R4DS Chapter 3 Data visualisation\nCHEATSHEET: Data visualization with ggplot2 cheatsheet\n\nRecommended. Practice:\n\n Primers: Data Visualization Basics\n Primers: Exploratory data analysis\n Primers: Bar Charts\n Primers: Histograms\n Primers: Boxplots and Counts\n Primers: Scatterplots\n Primers: Overplotting\n Primers: Customize plots\n\nOptional. Practice:\n\n Open Intro. Interactive. Visualizing categorical data (takes time to load)\n Open Intro. Interactive. Visualizing numerical data (takes time to load)\n\nOptional. Watch + Practice:\n\n webinar: Tidyverse visualization manipulation basics\n Data and visualisation video + slides\n Visualising data with ggplot2 video + slides\n Visualising numerical data video + slides\n Visualising categorical data video + slides"
  },
  {
    "objectID": "ae/ae04-multiple-regression-part-1/ae04-01-MLR.html",
    "href": "ae/ae04-multiple-regression-part-1/ae04-01-MLR.html",
    "title": "AE04-01 Multiple Linear Regression",
    "section": "",
    "text": "library(tidyverse)\nlibrary(wooldridge)\nlibrary(modelsummary)\nlibrary(GGally)\nlibrary(parameters)\nlibrary(performance)\nlibrary(see)\nlibrary(patchwork)\nlibrary(ggeffects)\n\nggplot2::theme_set(ggplot2::theme_bw())\n\nknitr::opts_chunk$set(\n  fig.width = 12,\n  fig.asp = 0.618,\n  out.width = \"100%\"\n)\n\n\n\n\nFit multiple linear regression;\nDisplay and interpret regression summary;\nCompute fitted values and residuals;\n\n\n\n\nWe use data from (Blackburn and Neumark, 1992) on wage determinants. Variables present are:\n\n\\(wage\\) - monthly earnings in USD;\n\\(educ\\) - years of education;\n\\(exper\\) - years of experiences;\n\\(black\\) - dummy variable representing individuals which are not Caucasian;\n\nSee: Blackburn, M. and Neumark, D. (1992) Unobserved Ability, Efficiency Wages, and Interindustry Wage Differentials. The Quarterly Journal of Economics , Vol. 107, No. 4. Oxford University Press (OUP). p. 1421-1436\n\nwage_dta <- \n    wooldridge::wage2 %>% \n    as_tibble() %>% \n    select(wage, educ, exper, black)\n\n\n\n\n\n# __________(_____)\n\nCompute a new variables caucasian that takes values “yes” and “no” for each person depending on the values of the variable black.\n\n# wage_dta <-\n#   _____ %>%\n#   mutate(_____ = ifelse(black, \"no\", \"yes\"),\n#          caucasian = as.factor(caucasian))\n# glimpse(_____)\n\n\n\nUse function datasummary_skim() from the package modelsummary.\n\n# library(_________)\n# _________(wage_dta)\n\n\n\n\nWe inspect data visually by building a grid of scatter plots using GGally::ggpairs()\n\n# library(_________)\n# _________(wage_dta)\n\nAdd parameter aes(colour = caucasian) to ggpairs().\nWhat is the difference compare to the previous plot?\n\n# ggpairs(_________, _________)\n\n\n\n\n\nDependent variable is wage, independent are: educ, exper and black\n\n# fit1 <- lm(____ ~ ____ + ____ + ____, data = ____)\n# fit1\n\n\n\n\n# fit1\n\n\n\n\n\n\n# summary(______)\n\nInterpret the coefficients:\n\n\nCheck help on ?parameters::parameters\n\n# library(________)\n# ________(________)\n\n\n\n\nCheck help on ?performance::performance\n\n# library(________)\n# performance(________)\n\n\n\n\n\n\n# fitted_vector <- fitted(________)\n# fitted_vector[1:20]\n\n\n\n\n\n# resid_vector <- resid(________)\n# resid_vector[1:20]\n\n\n\n\nUse function plot(). Put fitted as an x argument and residuals as y.\n\n# plot(x = _____, ___ = ________)\n\n\n\nSee: ?performance::check_model\n\n# check_model(fit1, check = \"linearity\")\n\n\n\n\n\nWe can compute predicted values based on the regression results for arbitrary values of \\(X\\). See: ?predict\nFirst, we need to make a table the \\(X\\) variables for which we want compute the predicted value.\n\nVariables names in table should match the variables in the regression.\n\nLet us predict wage for a person with 0 years of education, 0 experience, when he/she is white.\n\n# pred1 <-\n#   tibble(educ = 0,\n#          exper = 0,\n#          black = 0)\n# predict(fit1, pred1)\n\nThe same when the person is black.\n\n# pred2 <-\n#   tibble(educ = c(0, 0),\n#          exper = c(0, 0),\n#          black = c(0, 1)\n#   )\n# predict(fit1, pred2)\n\n\n\nUse mutate to mutate new variable in a data frame:\n\n# pred3 <-\n#   tibble(educ = c(0, 0, 10),\n#          exper = c(0, 0, 25),\n#          black = c(0, 1, 1)\n#   )\n# \n# pred3 %>% \n#   mutate(predicted = predict(fit1, pred3))\n\n\n\n\nWe can use function ggeffects::ggpredict(), check help.\n\n# library(ggeffects)\n# ggpredict(fit1, term = \"educ\")\n\nWe can also plot this effects using plot after ggpredict\n\n# ggpredict(fit1, term = \"educ\") %>% ________()\n\nCompute predicted values for a different independent variable and a dummy variable\n\n# ggpredict(fit1, term = c(\"________\", \"________\")) \n# ________(________, term = c(\"________\", \"________\")) %>% plot()\n\n\n\n\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(wooldridge)\n\nwage_dta <- \n    wooldridge::wage2 %>% \n    as_tibble() %>% \n    select(wage, educ, exper, black)\nglimpse(wage_dta)\n\n\nRows: 935\nColumns: 4\n$ wage  <int> 769, 808, 825, 650, 562, 1400, 600, 1081, 1154, 1000, 930, 921, …\n$ educ  <int> 12, 18, 14, 12, 11, 16, 10, 18, 15, 12, 18, 14, 15, 16, 16, 10, …\n$ exper <int> 11, 11, 11, 13, 14, 14, 13, 8, 13, 16, 8, 9, 4, 7, 9, 17, 6, 19,…\n$ black <int> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\nCode\nwage_dta <-\n  wage_dta %>%\n  mutate(caucasian = ifelse(black, \"no\", \"yes\"),\n         caucasian = as.factor(caucasian))\nglimpse(wage_dta)\n\n\nRows: 935\nColumns: 5\n$ wage      <int> 769, 808, 825, 650, 562, 1400, 600, 1081, 1154, 1000, 930, 9…\n$ educ      <int> 12, 18, 14, 12, 11, 16, 10, 18, 15, 12, 18, 14, 15, 16, 16, …\n$ exper     <int> 11, 11, 11, 13, 14, 14, 13, 8, 13, 16, 8, 9, 4, 7, 9, 17, 6,…\n$ black     <int> 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ caucasian <fct> yes, yes, yes, yes, yes, no, yes, yes, yes, yes, yes, yes, y…\n\n\nCode\nlibrary(modelsummary)\ndatasummary_skim(wage_dta)\n\n\n\n\n \n  \n      \n    Unique (#) \n    Missing (%) \n    Mean \n    SD \n    Min \n    Median \n    Max \n       \n  \n \n\n  \n    wage \n    449 \n    0 \n    957.9 \n    404.4 \n    115.0 \n    905.0 \n    3078.0 \n     \n\n\n  \n  \n    educ \n    10 \n    0 \n    13.5 \n    2.2 \n    9.0 \n    12.0 \n    18.0 \n     \n\n\n  \n  \n    exper \n    22 \n    0 \n    11.6 \n    4.4 \n    1.0 \n    11.0 \n    23.0 \n     \n\n\n  \n  \n    black \n    2 \n    0 \n    0.1 \n    0.3 \n    0.0 \n    0.0 \n    1.0 \n     \n\n\n  \n\n\n\n\n\nCode\nlibrary(GGally)\nggpairs(wage_dta)\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nCode\nggpairs(wage_dta, aes(colour = caucasian))\n\n\nWarning in cor(x, y): the standard deviation is zero\n\nWarning in cor(x, y): the standard deviation is zero\n\nWarning in cor(x, y): the standard deviation is zero\n\nWarning in cor(x, y): the standard deviation is zero\n\nWarning in cor(x, y): the standard deviation is zero\n\nWarning in cor(x, y): the standard deviation is zero\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nCode\nfit1 <- lm(wage ~ educ + exper + black, data = wage_dta)\nfit1\n\n\n\nCall:\nlm(formula = wage ~ educ + exper + black, data = wage_dta)\n\nCoefficients:\n(Intercept)         educ        exper        black  \n    -170.23        70.77        17.18      -183.98  \n\n\nCode\nsummary(fit1)\n\n\n\nCall:\nlm(formula = wage ~ educ + exper + black, data = wage_dta)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-923.57 -250.05  -35.42  195.94 2139.28 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -170.225    107.893  -1.578    0.115    \neduc          70.769      6.313  11.210  < 2e-16 ***\nexper         17.178      3.124   5.499 4.92e-08 ***\nblack       -183.984     36.948  -4.980 7.59e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 371.6 on 931 degrees of freedom\nMultiple R-squared:  0.1583,    Adjusted R-squared:  0.1556 \nF-statistic: 58.35 on 3 and 931 DF,  p-value: < 2.2e-16\n\n\nCode\nlibrary(parameters)\nparameters(fit1)\n\n\nParameter   | Coefficient |     SE |             95% CI | t(931) |      p\n-------------------------------------------------------------------------\n(Intercept) |     -170.23 | 107.89 | [-381.97,   41.52] |  -1.58 | 0.115 \neduc        |       70.77 |   6.31 | [  58.38,   83.16] |  11.21 | < .001\nexper       |       17.18 |   3.12 | [  11.05,   23.31] |   5.50 | < .001\nblack       |     -183.98 |  36.95 | [-256.49, -111.47] |  -4.98 | < .001\n\n\n\nUncertainty intervals (equal-tailed) and p values (two-tailed) computed using a\n  Wald t-distribution approximation.\n\n\nCode\nlibrary(performance)\nperformance(fit1)\n\n\n# Indices of model performance\n\nAIC       |       BIC |    R2 | R2 (adj.) |    RMSE |   Sigma\n-------------------------------------------------------------\n13725.631 | 13749.834 | 0.158 |     0.156 | 370.785 | 371.581\n\n\nCode\nfitted_vector <- fitted(fit1)\nfitted_vector[1:20]\n\n\n        1         2         3         4         5         6         7         8 \n 867.9558 1292.5693 1009.4937  902.3111  848.7198 1018.5808  760.7732 1241.0364 \n        9        10        11        12        13        14        15        16 \n1114.6179  953.8440 1241.0364  975.1384  960.0191 1082.3209 1116.6762  829.4838 \n       17        18        19        20 \n 994.3744  934.6080  889.2502  902.3111 \n\n\nCode\nresid_vector <- resid(fit1)\nresid_vector[1:20]\n\n\n         1          2          3          4          5          6          7 \n -98.95581 -484.56934 -184.49366 -252.31109 -286.71981  381.41917 -160.77325 \n         8          9         10         11         12         13         14 \n-160.03642   39.38214   46.15599 -311.03642  -54.13838  -60.01910  235.67906 \n        15         16         17         18         19         20 \n 675.32378  128.51619  365.62562  -84.60801  -59.25017 -431.31109 \n\n\nCode\nplot(x = fitted_vector, y = resid_vector)\n\n\n\n\n\nCode\ncheck_model(fit1, check = \"linearity\")\n\n\n\n\n\nCode\npred1 <-\n tibble(educ = 0,\n        exper = 0,\n        black = 0)\npredict(fit1, pred1)\n\n\n        1 \n-170.2253 \n\n\nCode\npred2 <-\n  tibble(educ = c(0, 0),\n         exper = c(0, 0),\n         black = c(0, 1)\n  )\npredict(fit1, pred2)\n\n\n        1         2 \n-170.2253 -354.2089 \n\n\nCode\npred3 <-\n  tibble(educ = c(0, 0, 10),\n         exper = c(0, 0, 25),\n         black = c(0, 1, 1)\n  )\npred3 %>% \n  mutate(predicted = predict(fit1, pred3))\n\n\n# A tibble: 3 × 4\n   educ exper black predicted\n  <dbl> <dbl> <dbl>     <dbl>\n1     0     0     0     -170.\n2     0     0     1     -354.\n3    10    25     1      783.\n\n\nCode\nlibrary(ggeffects)\n\nggpredict(fit1, term = \"educ\")\n\n\n# Predicted values of wage\n\neduc | Predicted |             95% CI\n-------------------------------------\n   9 |    655.65 | [ 591.81,  719.49]\n  10 |    726.42 | [ 673.67,  779.16]\n  11 |    797.19 | [ 754.83,  839.55]\n  12 |    867.96 | [ 834.59,  901.32]\n  14 |   1009.49 | [ 983.63, 1035.36]\n  15 |   1080.26 | [1050.16, 1110.37]\n  16 |   1151.03 | [1112.96, 1189.11]\n  18 |   1292.57 | [1233.79, 1351.35]\n\nAdjusted for:\n* exper = 11.00\n* black =  0.00\n\n\nCode\nggpredict(fit1, term = \"educ\") %>% plot()\n\n\n\n\n\nCode\nggpredict(fit1, term = c(\"exper\", \"black\"))\n\n\n# Predicted values of wage\n\n# black = 0\n\nexper | Predicted |             95% CI\n--------------------------------------\n    1 |    696.18 | [ 616.64,  775.72]\n    5 |    764.89 | [ 707.08,  822.70]\n    8 |    816.42 | [ 772.95,  859.90]\n   12 |    885.13 | [ 853.45,  916.82]\n   16 |    953.84 | [ 917.55,  990.14]\n   23 |   1074.09 | [1005.16, 1143.02]\n\n# black = 1\n\nexper | Predicted |           95% CI\n------------------------------------\n    1 |    512.20 | [414.77, 609.62]\n    5 |    580.91 | [499.60, 662.22]\n    8 |    632.44 | [560.06, 704.82]\n   12 |    701.15 | [634.39, 767.91]\n   16 |    769.86 | [700.03, 839.69]\n   23 |    890.10 | [797.94, 982.26]\n\nAdjusted for:\n* educ = 12.00\n\n\nCode\nggpredict(fit1, term = c(\"exper\", \"black\")) %>% plot()"
  },
  {
    "objectID": "ae/ae04-multiple-regression-part-1/ae04-03-hedonic-land-prices-HW.html",
    "href": "ae/ae04-multiple-regression-part-1/ae04-03-hedonic-land-prices-HW.html",
    "title": "AE04-02 Multiple Linear Regression: Hedonic Prices",
    "section": "",
    "text": "library(tidyverse)\nlibrary(alr4)\nlibrary(GGally)\nlibrary(parameters)\nlibrary(performance)\nlibrary(see)\nlibrary(car)\nlibrary(broom)\nlibrary(modelsummary)\nlibrary(texreg)\n\nknitr::opts_chunk$set(\n  fig.align = \"center\",\n  fig.width = 12,\n  fig.asp = 0.618,\n  fig.retina = 1,\n  out.width = \"100%\", \n  message = FALSE,\n  echo = TRUE\n)\n\nmy_gof <- function(fit_obj, digits = 4) {\n  sum_fit <- summary(fit_obj)\n  \n  stars <- \n    pf(sum_fit$fstatistic[1],\n       sum_fit$fstatistic[2], \n       sum_fit$fstatistic[3],\n       lower.tail=FALSE) %>% \n    symnum(corr = FALSE, na = FALSE, \n           cutpoints = c(0,  .001,.01,.05,  1),\n           symbols   =  c(\"***\",\"**\",\"*\",\" \")) %>% \n    as.character()\n  \n  list(\n    # `R^2` = sum_fit$r.squared %>% round(digits),\n    # `Adj. R^2` = sum_fit$adj.r.squared %>% round(digits),\n    # `Num. obs.` = sum_fit$residuals %>% length(),\n    `Num. df` = sum_fit$df[[2]],\n    `F statistic` = \n      str_c(sum_fit$fstatistic[1] %>% round(digits), \" \", stars)\n  )\n}\n\n# Function for screening many regressors\nscreen_many_regs <-\n  function(fit_obj_list, ..., digits = 4, single.row = TRUE) {\n    \n    if (class(fit_obj_list) == \"lm\") \n      fit_obj_list <- list(fit_obj_list)\n    \n    if (length(rlang::dots_list(...)) > 0)  \n      fit_obj_list <- fit_obj_list %>% append(rlang::dots_list(...))\n    \n    # browser()\n    fit_obj_list %>%\n      screenreg(\n        custom.note =\n          map2_chr(., seq_along(.), ~ {\n            str_c(\"Model \", .y, \" \", as.character(.x$call)[[2]])\n          }) %>%\n          c(\"*** p < 0.001; ** p < 0.01; * p < 0.05\", .) %>%\n          str_c(collapse = \"\\n\") ,\n        digits = digits,\n        single.row = single.row,\n        custom.gof.rows =\n          map(., ~my_gof(.x, digits)) %>%\n          transpose() %>%\n          map(unlist),\n        reorder.gof = c(3, 4, 5, 1, 2)\n      )\n  }"
  },
  {
    "objectID": "ae/ae04-multiple-regression-part-1/ae04-03-hedonic-land-prices-HW.html#data-loading",
    "href": "ae/ae04-multiple-regression-part-1/ae04-03-hedonic-land-prices-HW.html#data-loading",
    "title": "AE04-02 Multiple Linear Regression: Hedonic Prices",
    "section": "Data loading",
    "text": "Data loading\n\ndta <- \n  alr4::MinnLand %>% \n  as_tibble()  %>%\n  # filter(year == 2007) %>% \n  select(acrePrice, acres, region, year, \n         tillable, crpPct, productivity)\n\nGlimpse at the data:\n\n# _______(dta)"
  },
  {
    "objectID": "ae/ae04-multiple-regression-part-1/ae04-03-hedonic-land-prices-HW.html#summary-statistics",
    "href": "ae/ae04-multiple-regression-part-1/ae04-03-hedonic-land-prices-HW.html#summary-statistics",
    "title": "AE04-02 Multiple Linear Regression: Hedonic Prices",
    "section": "Summary Statistics",
    "text": "Summary Statistics\nThis is a simple short-cut to the summary statistics.\n\nlibrary(modelsummary)\n#dta %>% datasummary_skim()\n\n\nDo yourself at home!\nIn the code chunk below, adopt the R code used to prepare data summary manually. Run it step by step and comment on what it does between each component of the pipe.\n\n# dta %>%\n#   _______(id = _______()) %>% \n#   _______(\n#     cols = c(acrePrice, acres, year, tillable, crpPct, productivity),\n#     names_to = \"var\",\n#     values_to = \"val\"\n#   ) %>% \n#   _______(var) %>% \n#   _______(_______(\n#     c(val),\n#     _______(\n#       mean = ~ mean(.x, na.rm = TRUE),\n#       sd = ~ sd(.x, na.rm = TRUE),\n#       meadian = ~ median(.x, na.rm = TRUE),\n#       n_miss = ~ sum(is.na(.x), na.rm = TRUE),\n#       min = ~ min(.x, na.rm = TRUE),\n#       max = ~ max(.x, na.rm = TRUE)\n#     )\n#   ), \n#   n = n())"
  },
  {
    "objectID": "ae/ae04-multiple-regression-part-1/ae04-03-hedonic-land-prices-HW.html#visual-inspection",
    "href": "ae/ae04-multiple-regression-part-1/ae04-03-hedonic-land-prices-HW.html#visual-inspection",
    "title": "AE04-02 Multiple Linear Regression: Hedonic Prices",
    "section": "Visual inspection",
    "text": "Visual inspection\nWe reply on the visual inspection of data to build some prior expectations. We will use function ggpairs() from GGally. Insert function name where appropriate:\n\nlibrary(GGally)\n# dta %>%\n#   select(acrePrice, acres, tillable, \n#          crpPct, productivity) %>%\n#   ________()"
  },
  {
    "objectID": "ae/ae04-multiple-regression-part-1/ae04-03-hedonic-land-prices-HW.html#regression-1",
    "href": "ae/ae04-multiple-regression-part-1/ae04-03-hedonic-land-prices-HW.html#regression-1",
    "title": "AE04-02 Multiple Linear Regression: Hedonic Prices",
    "section": "Regression 1",
    "text": "Regression 1\nLet us fit the basic regression and summarize the results.\n\n# fit1 <- lm(\n#   acrePrice ~ _____ + _____ + _____ + _____ + ____ + _____,\n#   data = dta\n# )\n# summary(fit1)\n\nUse performance and parameters package to summarize the regression results.\n\nProvide object with the fitted regression;\n\n\nlibrary(parameters)\nlibrary(performance)\n# parameters(_____)\n# performance(_____)\n\n\nLinearity: visual inspection\nWe can use built-in function for plotting residuals vs fitted.\n\nProvide object with the fitted regression;\n\n\n# plot(_____, which = 1)\n\nWe can also rely on the performance package:\n\nlibrary(see)\n# check_model(_____, check = \"linearity\", panel = FALSE)\n\nWhat do you conclude about the linearity assumption based on these results?\n\n\nLinearity: statistical test\nWhat does the residualPlots() test and plots show us?\n\nlibrary(car)\n# residualPlots(_____)\n\nWhat we conclude based on this linearity test?"
  },
  {
    "objectID": "ae/ae04-multiple-regression-part-1/ae04-03-hedonic-land-prices-HW.html#regression-2",
    "href": "ae/ae04-multiple-regression-part-1/ae04-03-hedonic-land-prices-HW.html#regression-2",
    "title": "AE04-02 Multiple Linear Regression: Hedonic Prices",
    "section": "Regression 2",
    "text": "Regression 2\nLet us transform the dependent variable with a logarithm!\n\n# fit2 <- lm(\n#   log(acrePrice) ~ _______________,\n#   data = _____\n# )\n# summary(_____________)\n\n\nRegressions comparison\nLet us compare regression 1 and 2 using function screen_many_regs.\n\n# screen_many_regs(_______, fit2)\n\n\n\nLinearity assumption\nIs the linearity assumption fulfilled now?\n\n# residualPlots(___________)"
  },
  {
    "objectID": "ae/ae04-multiple-regression-part-1/ae04-04-slides-ovb-HW.html",
    "href": "ae/ae04-multiple-regression-part-1/ae04-04-slides-ovb-HW.html",
    "title": "AE04-05 OVB examples from the slides",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\n\n✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n✔ tibble  3.1.7     ✔ dplyr   1.0.9\n✔ tidyr   1.2.0     ✔ stringr 1.4.0\n✔ readr   2.1.2     ✔ forcats 0.5.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(wooldridge)\nlibrary(modelsummary)\nlibrary(GGally)\n\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n\nlibrary(parameters)\n\nRegistered S3 method overwritten by 'parameters':\n  method                         from      \n  format.parameters_distribution datawizard\n\n\n\nAttaching package: 'parameters'\n\n\nThe following object is masked from 'package:modelsummary':\n\n    supported_models\n\nlibrary(performance)\nlibrary(see)\n\nggplot2::theme_set(ggplot2::theme_bw())\n\nknitr::opts_chunk$set(\n  fig.width = 12,\n  fig.asp = 0.618,\n  out.width = \"100%\"\n)"
  },
  {
    "objectID": "ae/ae04-multiple-regression-part-1/ae04-04-slides-ovb-HW.html#goals",
    "href": "ae/ae04-multiple-regression-part-1/ae04-04-slides-ovb-HW.html#goals",
    "title": "AE04-05 OVB examples from the slides",
    "section": "Goals",
    "text": "Goals\n\nReproduce analysis from the slides on the OVB in a form of an RMarkdown document;"
  },
  {
    "objectID": "ae/ae04-multiple-regression-part-1/ae04-02-MLR-linearity.html",
    "href": "ae/ae04-multiple-regression-part-1/ae04-02-MLR-linearity.html",
    "title": "AE04-02 Multiple Linear Regression: linearity",
    "section": "",
    "text": "library(tidyverse)       # for data wrangling\nlibrary(alr4)            # for the data sets #\nlibrary(GGally)\nlibrary(parameters)\nlibrary(performance)\nlibrary(see)\nlibrary(car)\nlibrary(broom)\nlibrary(modelsummary)\nlibrary(texreg)\nlibrary(modelbased)\nlibrary(emmeans)\nlibrary(ggeffects)\n\nggplot2::theme_set(ggplot2::theme_bw())\n\nknitr::opts_chunk$set(\n  fig.width = 10,\n  fig.asp = 0.618,\n  out.width = \"100%\"\n)\n\n\n\n\nPerform a linear regression analysis;\nLearn how to test linearity assumption;\nPractice linear transformation;\nPractice coefficients interactions;\nExerciser coefficients interpretation with linear transformation and or interactions;\n\n\n\n\nWe explore UN11 data from with 199 observations.\nVariables are:\n\nfertility - number of children per woman;\nlifeExpF - Female life expectancy, years;\nppgdp - Per capita gross domestic product in US dollars;\npctUrban - Percent of Urban population;\ngroup - variable with 3 values “oecd”, “africa” and “others”;\n\n\n\n\n\nCode\nlibrary(alr4)\nlibrary(tidyverse)\nun_dta <- \n  alr4::UN11 %>%\n  as_tibble()\nglimpse(un_dta)\n\n\nRows: 199\nColumns: 6\n$ region    <fct> Asia, Europe, Africa, Africa, Caribbean, Latin Amer, Asia, C…\n$ group     <fct> other, other, africa, africa, other, other, other, other, oe…\n$ fertility <dbl> 5.968, 1.525, 2.142, 5.135, 2.000, 2.172, 1.735, 1.671, 1.94…\n$ ppgdp     <dbl> 499.0, 3677.2, 4473.0, 4321.9, 13750.1, 9162.1, 3030.7, 2285…\n$ lifeExpF  <dbl> 49.49, 80.40, 75.00, 53.17, 81.10, 79.89, 77.33, 77.75, 84.2…\n$ pctUrban  <dbl> 23, 53, 67, 59, 100, 93, 64, 47, 89, 68, 52, 84, 89, 29, 45,…\n\n\n\n\n\n\nLet us build a simple econometric model:\n\\[\\textit{fertility} = f(\\textit{ppgdp}, \\textit{pctUrban})\\]\n\n\n\nCheck help: ?lm\n\n# ft1 <- lm(_____ ~ ______, data = _____)\n\n\n\n\n\n# library(______)\n# library(______)\n# parameters(______)\n# performance(______)\n\n\n\n\n\n\nImportant to specify argument which = 1 that makes R print only the first plot!\n\n# plot(______, which = 1)\n\n\n\n\nSee help: ?check_model. First argument is the model, second argument check = \"linearity\" make sure that the function checks linearity only.\n\n# _____(_____, check = \"linearity\")\n\n\n\n\n\n# library(car)\n# residualPlots(_____, plot = FALSE)\n\n\n# _____(_____, test = FALSE)\n\n\n\n\n\nWhat variable should we first try to transform with log?\n\n\n\n# ft2 <- lm(_______ ~ log(______) + _______, ________)\n\n\n\n\n\n# _______(_______)\n\nHas anything changed? Do we have an improvement in the linearity assumption?\n\n\n\n\n# parameters(_______)\n# _______(ft2)\n\n\n\n\n?ggeffects::ggpredict\nFirs argument of a function is the model, second argument is the term that we want to predict.\nif we pass result of ggpredict to plot, we will get a plot of predicted values constructed for us.\n\nlibrary(ggeffects)\n# ggpredict(_______, terms = \"_______\")\n# _______(ft2, _______) %>% plot()\n\n\n\n\n\n\n\n\n# ft3a <- lm(_____ ~ log(_____) * _____, data = un_dta)\n\nWe can also calculate log of the variable before regression, in the data and then use a newly calculated variable:\n\n# ft3 <- lm(_____ ~ log_ppgdp * _____ ,\n#           data = \n#             un_dta %>%\n#             mutate(log_ppgdp = log(ppgdp))\n#           )\n\n\n\n\nAre there any improvement in fulfillment of the linearity assumption?\n\n# _______(_______)\n\n\n\n\n\n# parameters(_______)\n# _______(ft3)\n\n\n\n\n\n# library(modelbased)\n# library(emmeans)\n# estimate_slopes(_______, trend = \"log_ppgdp\")\n# estimate_slopes(_______, trend = \"_______\", at = \"pctUrban\") %>% plot()\n\n\n# estimate_slopes(ft3, trend = \"pctUrban\")\n# estimate_slopes(ft3, trend = \"_______\", at = \"_______\") %>% plot()\n\n\n\n\nLet us use regression fit3a\n\n# library(ggeffects)\n# ggpredict(______, terms = \"ppgdp\")\n# ggpredict(______, terms = c(\"______\", \"pctUrban [10, 50, 90]\")) %>% plot()\n\n\n\n\n\n\n## Regression\nft1 <- lm(fertility ~ ppgdp + pctUrban, data = un_dta)\n\n## Reg. Summary\nlibrary(parameters)\nlibrary(performance)\nparameters(ft1)\n\nParameter   | Coefficient |       SE |         95% CI | t(196) |      p\n-----------------------------------------------------------------------\n(Intercept) |        4.37 |     0.22 | [ 3.93,  4.82] |  19.49 | < .001\nppgdp       |   -1.30e-05 | 5.37e-06 | [ 0.00,  0.00] |  -2.43 | 0.016 \npctUrban    |       -0.02 | 4.22e-03 | [-0.03, -0.02] |  -5.91 | < .001\n\n\n\nUncertainty intervals (equal-tailed) and p values (two-tailed) computed using a\n  Wald t-distribution approximation.\n\nperformance(ft1)\n\n# Indices of model performance\n\nAIC     |     BIC |    R2 | R2 (adj.) |  RMSE | Sigma\n-----------------------------------------------------\n612.669 | 625.842 | 0.315 |     0.308 | 1.106 | 1.114\n\n## Linearity\n\n### Checking linearity with `base::plot`\nplot(ft1, which = 1)\n\n\n\n### Checking linearity with `performance::check_model`\ncheck_model(ft1, check = \"linearity\")\n\n\n\n### Checking linearity with `car::residualPlots`\nlibrary(car)\nresidualPlots(ft1)\n\n\n\n\n           Test stat Pr(>|Test stat|)    \nppgdp         3.7219        0.0002586 ***\npctUrban      2.9481        0.0035876 ** \nTukey test    4.7335        2.207e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n## Linear transformation of ______________\nft2 <- lm(fertility ~ log(ppgdp) + pctUrban, data = un_dta)\n\n## Checking linearity with `car::residualPlots`\nresidualPlots(ft2)\n\n\n\n\n           Test stat Pr(>|Test stat|)    \nlog(ppgdp)    5.4068        1.863e-07 ***\npctUrban      3.2868         0.001202 ** \nTukey test    5.4198        5.966e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n## Interpretation logged variable\nparameters(ft2)\n\nParameter   | Coefficient |       SE |         95% CI | t(196) |      p\n-----------------------------------------------------------------------\n(Intercept) |        7.99 |     0.40 | [ 7.21,  8.78] |  20.02 | < .001\nppgdp [log] |       -0.62 |     0.06 | [-0.74, -0.49] |  -9.59 | < .001\npctUrban    |   -4.39e-04 | 4.27e-03 | [-0.01,  0.01] |  -0.10 | 0.918 \n\n\n\nUncertainty intervals (equal-tailed) and p values (two-tailed) computed using a\n  Wald t-distribution approximation.\n\nperformance(ft2)\n\n# Indices of model performance\n\nAIC     |     BIC |    R2 | R2 (adj.) |  RMSE | Sigma\n-----------------------------------------------------\n542.043 | 555.216 | 0.520 |     0.515 | 0.926 | 0.933\n\n## Predicted values\nlibrary(ggeffects)\nggpredict(ft2, terms = \"ppgdp\")\n\n# Predicted values of fertility\n\n ppgdp | Predicted |       95% CI\n---------------------------------\n     0 |       Inf |             \n 15000 |      2.05 | [1.86, 2.25]\n 25000 |      1.74 | [1.49, 1.98]\n 40000 |      1.45 | [1.15, 1.75]\n 55000 |      1.25 | [0.92, 1.59]\n 70000 |      1.11 | [0.74, 1.47]\n 85000 |      0.99 | [0.60, 1.37]\n110000 |      0.83 | [0.41, 1.24]\n\nAdjusted for:\n* pctUrban = 57.93\n\nggpredict(ft2, terms = \"pctUrban \")\n\n# Predicted values of fertility\n\npctUrban | Predicted |       95% CI\n-----------------------------------\n      10 |      2.16 | [1.64, 2.68]\n      20 |      2.16 | [1.72, 2.60]\n      30 |      2.15 | [1.79, 2.52]\n      40 |      2.15 | [1.86, 2.44]\n      60 |      2.14 | [1.97, 2.31]\n      70 |      2.13 | [1.98, 2.29]\n      80 |      2.13 | [1.95, 2.31]\n     100 |      2.12 | [1.82, 2.42]\n\nAdjusted for:\n* ppgdp = 13011.95\n\nggpredict(ft2, terms = \"ppgdp\") %>% plot()\n\n\n\n## Introducing interaction term\nft3 <- lm(fertility ~ log_ppgdp + pctUrban + log_ppgdp:pctUrban ,\n          data = un_dta %>% mutate(log_ppgdp = log(ppgdp)))\n\nft3a <- lm(fertility ~ log(ppgdp) * pctUrban, data = un_dta)\n\n## Checking linearity with `car::residualPlots`\nresidualPlots(ft3)\n\n\n\n\n           Test stat Pr(>|Test stat|)   \nlog_ppgdp     2.7594         0.006345 **\npctUrban     -0.1503         0.880705   \nTukey test    1.6733         0.094275 . \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n## Interpretation logged variable + interaction term\nparameters(ft3)\n\nParameter            | Coefficient |       SE |         95% CI | t(195) |      p\n--------------------------------------------------------------------------------\n(Intercept)          |       12.00 |     0.94 | [10.15, 13.85] |  12.79 | < .001\nlog ppgdp            |       -1.11 |     0.12 | [-1.35, -0.87] |  -9.08 | < .001\npctUrban             |       -0.08 |     0.02 | [-0.11, -0.04] |  -4.56 | < .001\nlog ppgdp * pctUrban |    8.85e-03 | 1.90e-03 | [ 0.01,  0.01] |   4.67 | < .001\n\n\n\nUncertainty intervals (equal-tailed) and p values (two-tailed) computed using a\n  Wald t-distribution approximation.\n\nperformance(ft3)\n\n# Indices of model performance\n\nAIC     |     BIC |    R2 | R2 (adj.) |  RMSE | Sigma\n-----------------------------------------------------\n522.948 | 539.415 | 0.568 |     0.562 | 0.878 | 0.887\n\n## Marginal effects\nlibrary(modelbased)\nlibrary(emmeans)\nestimate_slopes(ft3, trend = \"log_ppgdp\")\n\nEstimated Marginal Effects\n\nCoefficient |   SE |         95% CI | t(195) |      p\n-----------------------------------------------------\n-0.60       | 0.06 | [-0.72, -0.48] |  -9.76 | < .001\nMarginal effects estimated for log_ppgdp\n\nestimate_slopes(ft3, trend = \"pctUrban\")\n\nEstimated Marginal Effects\n\nCoefficient |       SE |        95% CI | t(195) |     p\n-------------------------------------------------------\n-1.49e-03   | 4.06e-03 | [-0.01, 0.01] |  -0.37 | 0.715\nMarginal effects estimated for pctUrban\n\nestimate_slopes(ft3, trend = \"log_ppgdp\", at = \"pctUrban\") %>% plot()\n\n\n\nestimate_slopes(ft3, trend = \"pctUrban\", at = \"log_ppgdp\") %>% plot()\n\n\n\n## Predicted values\nggpredict(ft3a, terms = \"ppgdp\")\n\n# Predicted values of fertility\n\n ppgdp | Predicted |       95% CI\n---------------------------------\n     0 |           |             \n 15000 |      1.83 | [1.63, 2.04]\n 25000 |      1.53 | [1.28, 1.78]\n 40000 |      1.25 | [0.95, 1.54]\n 55000 |      1.06 | [0.73, 1.39]\n 70000 |      0.91 | [0.56, 1.27]\n 85000 |      0.80 | [0.42, 1.17]\n110000 |      0.64 | [0.24, 1.05]\n\nAdjusted for:\n* pctUrban = 57.93\n\nggpredict(ft3a, terms = c(\"ppgdp\", \"pctUrban [10, 50, 90]\")) %>%  plot()\n\nWarning: Removed 3 row(s) containing missing values (geom_path)."
  },
  {
    "objectID": "ae/ae03-data-wrangling-hw/ae03-04-categorical-data-vis.html",
    "href": "ae/ae03-data-wrangling-hw/ae03-04-categorical-data-vis.html",
    "title": "AE03-03 Visualisation of the categorical data",
    "section": "",
    "text": "We will us tidyverse for data wrangling and readr and readxl for data import.\n\nlibrary(tidyverse)\nlibrary(readr)       # install.packages(\"readr\")\nlibrary(readxl)      # install.packages(\"readxl\")\nlibrary(janitor)     # install.packages(\"janitor\")\nlibrary(skimr)       # install.packages(\"skimr\")"
  },
  {
    "objectID": "ae/ae03-data-wrangling-hw/ae03-04-categorical-data-vis.html#categorical-data",
    "href": "ae/ae03-data-wrangling-hw/ae03-04-categorical-data-vis.html#categorical-data",
    "title": "AE03-03 Visualisation of the categorical data",
    "section": "Categorical data",
    "text": "Categorical data\nUse Chapter 4 in intro to modern stats: https://openintro-ims.netlify.app/explore-categorical.html#chp4-exercises\nCheck examples and problems in the end.\nExploratory data analysis: 1 - Exploring categorical data\nhttps://openintrostat.github.io/ims-tutorials/02-explore/\nhttps://openintro.shinyapps.io/ims-02-explore-01/"
  },
  {
    "objectID": "ae/ae03-data-wrangling/ae03-03-correlation.html",
    "href": "ae/ae03-data-wrangling/ae03-03-correlation.html",
    "title": "AE03-03 Correlation",
    "section": "",
    "text": "library(tidyverse)\nlibrary(readr)       # install.packages(\"readr\")\nlibrary(readxl)      # install.packages(\"readxl\")\nlibrary(janitor)     # install.packages(\"janitor\")\nlibrary(skimr)       # install.packages(\"skimr\")\nlibrary(lubridate)   # install.packages(\"lubridate\")\n\nggplot2::theme_set(ggplot2::theme_minimal())\n\nknitr::opts_chunk$set(out.width = 60)"
  },
  {
    "objectID": "ae/ae03-data-wrangling/ae03-03-correlation.html#data-import-and-cleaning",
    "href": "ae/ae03-data-wrangling/ae03-03-correlation.html#data-import-and-cleaning",
    "title": "AE03-03 Correlation",
    "section": "Data import and cleaning",
    "text": "Data import and cleaning\n\nImporting and cleaning data in the wide format\nPractically the same procedure that we did in the previous exercise.\n\np_wd <- \n  read_excel(\"data/commodity-prices.xlsx\", sheet =  \"data\") %>% \n  clean_names() %>% \n  rename(wheat = soft_red_winter_wheat_no_2_f_o_b_us_gulf_usd_per_mt, \n        maize = yellow_maize_no_2_f_o_b_us_gulf_usd_per_mt, \n        date = day_month_year, \n        oil = crude_oil_brent_usd_per_barrel, \n        urea = urea_f_o_b_black_sea_usd_per_mt) %>%\n  slice(-1) %>% \n  mutate(\n    oil = as.numeric(oil),\n    wheat = as.numeric(wheat),\n    maize = as.numeric(maize),\n    urea = as.numeric(urea),\n    date = convert_to_date(date)\n  ) \n\nglimpse(p_wd)\n\nRows: 359\nColumns: 5\n$ date  <date> 1992-03-01, 1992-04-01, 1992-05-01, 1992-06-01, 1992-07-01, 199…\n$ oil   <dbl> 17.45, 18.63, 19.50, 20.83, 20.17, 19.62, 20.15, 20.08, 18.88, 1…\n$ wheat <dbl> 161.44, 153.07, 139.72, 140.36, 129.93, 118.80, 131.47, 137.42, …\n$ maize <dbl> 117.00, 108.52, 109.64, 110.90, 102.75, 96.96, 98.05, 95.11, 94.…\n$ urea  <dbl> 120.00, 120.00, 120.00, 120.00, 120.00, 120.00, 120.00, 116.88, …\n\n\n\n\nConverting data to the long format\n\np_lg <- \n  p_wd %>% \n  pivot_longer(cols = c(oil:urea), \n               names_to = \"var\", \n               values_to = \"price\") %>% \n  arrange(date, var)\nglimpse(p_lg)\n\nRows: 1,436\nColumns: 3\n$ date  <date> 1992-03-01, 1992-03-01, 1992-03-01, 1992-03-01, 1992-04-01, 199…\n$ var   <chr> \"maize\", \"oil\", \"urea\", \"wheat\", \"maize\", \"oil\", \"urea\", \"wheat\"…\n$ price <dbl> 117.00, 17.45, 120.00, 161.44, 108.52, 18.63, 120.00, 153.07, 10…"
  },
  {
    "objectID": "ae/ae03-data-wrangling/ae03-03-correlation.html#example-computing-prices-index-with-some-base",
    "href": "ae/ae03-data-wrangling/ae03-03-correlation.html#example-computing-prices-index-with-some-base",
    "title": "AE03-03 Correlation",
    "section": "Example: Computing prices index with some base",
    "text": "Example: Computing prices index with some base\nIndex of a variable with a base is a mathematical transformation of a variable, where each value of a variable is divided by the base value and then multiplied by 100.\n\\[\n{I}_{i} = \\frac{x_i}{x_{base}} \\times 100\n\\]\nThis is easy in Excel, but tricky without it!\nLet us demonstrate the logic of calculations based on a simple example of 2 commodities (wheat and urea) and few month in year 2010.\n\nStep 1. Filter a sub-sample\nAs discussed above, we want to:\n\nfilter data, where year is 2010, month less than 6, var is \"wheat\" or \"maize\"\n\nWhich identically translate into R code as:\n\nfilter(data, year(date) == 2010, month(date) < 6, var %in% c(\"wheat\", \"maize\"))`\nfilter data, where year is 2010, month less than 6, var is \"wheat\" or \"maize\"\n\n\np_lg_sb <- \n  filter(p_lg, \n         year(date) == 2010, \n         month(date) < 6, \n         var %in% c(\"wheat\", \"maize\")) %>% \n  arrange(var, date)\np_lg_sb\n\n# A tibble: 10 × 3\n   date       var   price\n   <date>     <chr> <dbl>\n 1 2010-01-01 maize  167.\n 2 2010-02-01 maize  162.\n 3 2010-03-01 maize  159.\n 4 2010-04-01 maize  157.\n 5 2010-05-01 maize  163.\n 6 2010-01-01 wheat  199.\n 7 2010-02-01 wheat  192.\n 8 2010-03-01 wheat  190.\n 9 2010-04-01 wheat  188.\n10 2010-05-01 wheat  190.\n\n\n\n\nStep 2. Create variable with the base for indexing\nHere we want to:\n\nfor each groups of commodities \"var\", mutate variable \"base\", which is equal to \"price\" when month is equal to 1 and year is equal to 2010.\n\nIn language of R this is:\n\np_lg_sb %>% \n  group_by(var) %>%           # 1. for each groups of commodities \"var\"\n  mutate(                     # 2. mutate\n    base = ifelse(            # 3. variable \"base\", which is equal to\n      month(date) == 1 &      # 5. when month is equal to 1 and\n        year(date) == 2010,   # 6. year is equal to 2010\n      price,                  # 4. \"price\"\n      NA                      # 7. missing value is in other cases\n      )\n    )\n\n# A tibble: 10 × 4\n# Groups:   var [2]\n   date       var   price  base\n   <date>     <chr> <dbl> <dbl>\n 1 2010-01-01 maize  167.  167.\n 2 2010-02-01 maize  162.   NA \n 3 2010-03-01 maize  159.   NA \n 4 2010-04-01 maize  157.   NA \n 5 2010-05-01 maize  163.   NA \n 6 2010-01-01 wheat  199.  199.\n 7 2010-02-01 wheat  192.   NA \n 8 2010-03-01 wheat  190.   NA \n 9 2010-04-01 wheat  188.   NA \n10 2010-05-01 wheat  190.   NA \n\n\n\n\nStep 3. Make sure that base is the same for all observations in each group var\n\np_lg_sb %>% \n  group_by(var) %>% \n  mutate(base = ifelse(month(date) == 1 & year(date) == 2010, price, NA)) %>% \n  tidyr::fill(base, .direction = \"updown\")\n\n# A tibble: 10 × 4\n# Groups:   var [2]\n   date       var   price  base\n   <date>     <chr> <dbl> <dbl>\n 1 2010-01-01 maize  167.  167.\n 2 2010-02-01 maize  162.  167.\n 3 2010-03-01 maize  159.  167.\n 4 2010-04-01 maize  157.  167.\n 5 2010-05-01 maize  163.  167.\n 6 2010-01-01 wheat  199.  199.\n 7 2010-02-01 wheat  192.  199.\n 8 2010-03-01 wheat  190.  199.\n 9 2010-04-01 wheat  188.  199.\n10 2010-05-01 wheat  190.  199.\n\n\n\n\nStep 4. Calculate index\n\np_lg_sb %>% \n  group_by(var) %>% \n  mutate(base = ifelse(month(date) == 1 & year(date) == 2010, price, NA)) %>% \n  tidyr::fill(base, .direction = \"updown\") %>% \n  mutate(index = price / base * 100)\n\n# A tibble: 10 × 5\n# Groups:   var [2]\n   date       var   price  base index\n   <date>     <chr> <dbl> <dbl> <dbl>\n 1 2010-01-01 maize  167.  167. 100  \n 2 2010-02-01 maize  162.  167.  96.7\n 3 2010-03-01 maize  159.  167.  95.1\n 4 2010-04-01 maize  157.  167.  93.9\n 5 2010-05-01 maize  163.  167.  97.7\n 6 2010-01-01 wheat  199.  199. 100  \n 7 2010-02-01 wheat  192.  199.  96.5\n 8 2010-03-01 wheat  190.  199.  95.6\n 9 2010-04-01 wheat  188.  199.  94.5\n10 2010-05-01 wheat  190.  199.  95.7\n\n\n\n\nOptional example: calculate index, where base is average of month 2 and 3\n\np_lg_sb %>%\n  group_by(var) %>%\n  mutate(base = ifelse(month(date) %in% c(2,3) & \n                         year(date) == 2010, \n                       price, \n                       NA)) %>% \n  mutate(base_full = mean(base, na.rm = TRUE)) %>% \n  mutate(index = price / base_full * 100)\n\n# A tibble: 10 × 6\n# Groups:   var [2]\n   date       var   price  base base_full index\n   <date>     <chr> <dbl> <dbl>     <dbl> <dbl>\n 1 2010-01-01 maize  167.   NA       160. 104. \n 2 2010-02-01 maize  162.  162.      160. 101. \n 3 2010-03-01 maize  159.  159.      160.  99.1\n 4 2010-04-01 maize  157.   NA       160.  97.9\n 5 2010-05-01 maize  163.   NA       160. 102. \n 6 2010-01-01 wheat  199.   NA       191. 104. \n 7 2010-02-01 wheat  192.  192.      191. 100. \n 8 2010-03-01 wheat  190.  190.      191.  99.5\n 9 2010-04-01 wheat  188.   NA       191.  98.4\n10 2010-05-01 wheat  190.   NA       191.  99.7\n\n\nNote, we specify mean(…, na.rm = TRUE) because when we compute mean, there are some missing observations in the variable. Mean of a vector with missing observation will return NA.\n\nmean(c(1, 2, 3, 4, NA))\n\n[1] NA\n\n\nIf we specify parameter to ignore NA in the data, we will get a result:\n\nmean(c(1, 2, 3, 4, NA), na.rm = TRUE)\n\n[1] 2.5"
  },
  {
    "objectID": "ae/ae03-data-wrangling/ae03-03-correlation.html#exercise-1.-compute-prices-index-with-base-mean-prices-in-2010",
    "href": "ae/ae03-data-wrangling/ae03-03-correlation.html#exercise-1.-compute-prices-index-with-base-mean-prices-in-2010",
    "title": "AE03-03 Correlation",
    "section": "Exercise 1. Compute prices index with base mean prices in 2010",
    "text": "Exercise 1. Compute prices index with base mean prices in 2010\nFollowing the previous examples, let us compute:\n\nStep 1. for each group of var;\nStep 2. mutate base_part, which contains price if year is 2010 and NA in else cases;\nStep 3. mutate base with the mean() value of base_part price with parameter na.rm = TRUE;\nStep 4. mutate price index against such base;\nStep 5. ungroup data\nStep 6. select variables date, var, price and index\n\n\n# p_index <- \n#   p_lg %>%\n#   ________() %>%                               # step 1.\n#   ______(                                      # step 2.\n#     base_part = \n#       ifelse(year(_____) == 2010, price, ____)\n#     ) %>% \n#   ______(                                      # step 3.\n#     base = ______(_______, na.rm = TRUE)\n#     ) %>%  \n#   mutate(index = ____ / _____ * 100) %>%       # step 4.\n#   ungroup() %>%                                # step 5.\n#   select(date, var, price, index)              # step 6.\n# \n# glimpse(p_index)"
  },
  {
    "objectID": "ae/ae03-data-wrangling/ae03-03-correlation.html#exercise-2.-plot-time-series-of-indexes-for-wheat-and-urea",
    "href": "ae/ae03-data-wrangling/ae03-03-correlation.html#exercise-2.-plot-time-series-of-indexes-for-wheat-and-urea",
    "title": "AE03-03 Correlation",
    "section": "Exercise 2. Plot time series of indexes for wheat and urea",
    "text": "Exercise 2. Plot time series of indexes for wheat and urea\nBefore plotting we need to filter var when it is %in% \"wehat\" or \"urea\";\nRemember from the previous exercises: ggplot() + aes() + geom_path()\n\nUse labs(x = \"\", y = \"\", title = \"\") to give meaningful labels to the plot.\n\n\n# p_index %>% \n#   ______(var %in% c(\"wheat\", ______)) %>% \n#   ______() + \n#   aes(x = _____, y = _______, colour = var) + \n#   geom_path() + \n#   labs()\n\nAnswer the following questions:\n\nCan we conclude, based on the plot, that surging prices of urea cause the wheat prices to surge?\nWhat could be a theoretical explanation for this?\nWhat could be the theoretical mechanism of urea prices effect on wheat?"
  },
  {
    "objectID": "ae/ae03-data-wrangling/ae03-03-correlation.html#exercise-3.-build-a-correlation-table-between-price-indices-of-different-commodities",
    "href": "ae/ae03-data-wrangling/ae03-03-correlation.html#exercise-3.-build-a-correlation-table-between-price-indices-of-different-commodities",
    "title": "AE03-03 Correlation",
    "section": "Exercise 3. Build a correlation table between price indices of different commodities",
    "text": "Exercise 3. Build a correlation table between price indices of different commodities\nFirst, we need to convert our data to wide format again:\n\n# p_index_wd <-\n#   p_index %>% \n#   pivot_wider(names_from = var, values_from = c(price, index))\n# glimpse(p_index_wd)\n\nTo make a correlation table, we use package correlation and a function with the same name. We use summary to convert correlation table with extensive results to a compact matrix\n\nWe select only those variables, where names contains() string index.\n\n\nlibrary(correlation)\n\n# p_index_wd %>% \n#   select(contains(\"index\")) %>% \n#   correlation() %>% \n#   summary()\n\n# p_index_wd %>% \n#   select(contains(\"price\")) %>% \n#   correlation() %>% \n#   summary()\n\n\nDoes this correlation coefficients suggests about causation if we assume that theory does justifies causal relationship?\n\nRun the same correlations but without summary(). What are the differences?\n\n# p_index_wd %>% \n#   ______(_______(\"index\")) %>% \n#   _________()\n\n# ______ %>% \n#   ______(______(\"price\")) %>% \n#   ______()"
  },
  {
    "objectID": "ae/ae03-data-wrangling/ae03-03-correlation.html#exercise-4.-compute-a-first-difference-of-indices-with-lag-1",
    "href": "ae/ae03-data-wrangling/ae03-03-correlation.html#exercise-4.-compute-a-first-difference-of-indices-with-lag-1",
    "title": "AE03-03 Correlation",
    "section": "Exercise 4. Compute a first difference of indices with lag 1",
    "text": "Exercise 4. Compute a first difference of indices with lag 1\nFirst difference is a change of value in the next period, compared to the previous one. To compute it, we use function lag() and perform similar mutate operations.\n\nSimple example of a first difference\nBefore, we computed index in the following way:\n\np_lg_sb %>% \n  group_by(var) %>% \n  mutate(base = ifelse(month(date) == 1 & year(date) == 2010, price, NA)) %>% \n  tidyr::fill(base, .direction = \"updown\") %>% \n  mutate(index = price / base * 100)\n\n# A tibble: 10 × 5\n# Groups:   var [2]\n   date       var   price  base index\n   <date>     <chr> <dbl> <dbl> <dbl>\n 1 2010-01-01 maize  167.  167. 100  \n 2 2010-02-01 maize  162.  167.  96.7\n 3 2010-03-01 maize  159.  167.  95.1\n 4 2010-04-01 maize  157.  167.  93.9\n 5 2010-05-01 maize  163.  167.  97.7\n 6 2010-01-01 wheat  199.  199. 100  \n 7 2010-02-01 wheat  192.  199.  96.5\n 8 2010-03-01 wheat  190.  199.  95.6\n 9 2010-04-01 wheat  188.  199.  94.5\n10 2010-05-01 wheat  190.  199.  95.7\n\n\nlet us mutate() the index_fd variable:\n\np_lg_sb %>% \n  group_by(var) %>% \n  mutate(base = ifelse(month(date) == 1 & year(date) == 2010, price, NA)) %>% \n  tidyr::fill(base, .direction = \"updown\") %>% \n  mutate(index = price / base * 100) %>% \n  mutate(index_fd = index - lag(index))\n\n# A tibble: 10 × 6\n# Groups:   var [2]\n   date       var   price  base index index_fd\n   <date>     <chr> <dbl> <dbl> <dbl>    <dbl>\n 1 2010-01-01 maize  167.  167. 100     NA    \n 2 2010-02-01 maize  162.  167.  96.7   -3.29 \n 3 2010-03-01 maize  159.  167.  95.1   -1.64 \n 4 2010-04-01 maize  157.  167.  93.9   -1.18 \n 5 2010-05-01 maize  163.  167.  97.7    3.77 \n 6 2010-01-01 wheat  199.  199. 100     NA    \n 7 2010-02-01 wheat  192.  199.  96.5   -3.51 \n 8 2010-03-01 wheat  190.  199.  95.6   -0.926\n 9 2010-04-01 wheat  188.  199.  94.5   -1.11 \n10 2010-05-01 wheat  190.  199.  95.7    1.29 \n\n\nUsing simple example, let us compute the first difference of the index for the entire data.\n\n# p_index_fd <- \n#   ______ %>% \n#   group_by(______) %>% \n#   mutate(index_fd = ______ - lag(______)) %>% \n#   ungroup() %>% \n#   select(date, var, index_fd) %>% \n#   pivot_wider(names_from = var, \n#               values_from = c(index_fd))\n#\n# p_index_fd %>% \n#   glimpse()"
  },
  {
    "objectID": "ae/ae03-data-wrangling/ae03-03-correlation.html#exercise-5.-build-a-correlation-table-between-first-differences-of-indices-for-different-commodities",
    "href": "ae/ae03-data-wrangling/ae03-03-correlation.html#exercise-5.-build-a-correlation-table-between-first-differences-of-indices-for-different-commodities",
    "title": "AE03-03 Correlation",
    "section": "Exercise 5. Build a correlation table between first differences of indices for different commodities",
    "text": "Exercise 5. Build a correlation table between first differences of indices for different commodities\nAs the same exercise before, we use correlation package and the same function.\n\n# p_index_fd %>% \n#   correlation() %>% \n#   summary()\n\n\nBased on this results, does urea prices causes surges in the wheat prices?\nWhat kind of causal relationship could be there?"
  },
  {
    "objectID": "ae/ae03-data-wrangling/ae03-03-correlation.html#exercise-6.-compute-first-differences-with-lag-2-and-3",
    "href": "ae/ae03-data-wrangling/ae03-03-correlation.html#exercise-6.-compute-first-differences-with-lag-2-and-3",
    "title": "AE03-03 Correlation",
    "section": "Exercise 6. Compute first differences with lag 2 and 3",
    "text": "Exercise 6. Compute first differences with lag 2 and 3\n\n# p_index_fd_lags <- \n#   p_index %>% \n#   group_by(var) %>% \n#   mutate(fd = index - lag(index, 1)) %>% \n#   ungroup() %>% \n#   select(date, var, contains(\"fd\")) %>% \n#   pivot_wider(names_from = var, \n#               values_from = c(contains(\"fd\"))) %>% \n#   mutate(urea_fd1 = urea,\n#          urea_fd2 = lag(urea, 2),\n#          urea_fd3 = lag(urea, 3),\n#          urea_fd4 = lag(urea, 4),\n#          urea_fd5 = lag(urea, 5)\n#   )\n# \n# correlation(p_index_fd_lags) %>% summary()"
  },
  {
    "objectID": "ae/ae03-data-wrangling/ae03-03-correlation.html#solutions",
    "href": "ae/ae03-data-wrangling/ae03-03-correlation.html#solutions",
    "title": "AE03-03 Correlation",
    "section": "Solutions",
    "text": "Solutions\n\np_wd <- \n  read_excel(\"data/commodity-prices.xlsx\", sheet =  \"data\") %>% \n  clean_names() %>% \n  rename(wheat = soft_red_winter_wheat_no_2_f_o_b_us_gulf_usd_per_mt, \n        maize = yellow_maize_no_2_f_o_b_us_gulf_usd_per_mt, \n        date = day_month_year, \n        oil = crude_oil_brent_usd_per_barrel, \n        urea = urea_f_o_b_black_sea_usd_per_mt) %>%\n  slice(-1) %>% \n  mutate(\n    oil = as.numeric(oil),\n    wheat = as.numeric(wheat),\n    maize = as.numeric(maize),\n    urea = as.numeric(urea),\n    date = convert_to_date(date)\n  ) \n\np_lg <- \n  p_wd %>% \n  pivot_longer(cols = c(oil:urea), \n               names_to = \"var\", \n               values_to = \"price\") %>% \n  arrange(var, date)\n\n\nEx. 1\n\np_index <- \n  p_lg %>%\n  group_by() %>%                               # step 1.\n  mutate(                                      # step 2.\n    base_part = \n      ifelse(year(date) == 2010, price, NA)\n    ) %>% \n  mutate(                                      # step 3.\n    base = mean(base_part, na.rm = TRUE)\n    ) %>%  \n  mutate(index = price / base * 100) %>%       # step 4.\n  ungroup() %>%                                # step 5.\n  select(date, var, price, index)              # step 6.\n\nglimpse(p_index)\n\nRows: 1,436\nColumns: 4\n$ date  <date> 1992-03-01, 1992-04-01, 1992-05-01, 1992-06-01, 1992-07-01, 199…\n$ var   <chr> \"maize\", \"maize\", \"maize\", \"maize\", \"maize\", \"maize\", \"maize\", \"…\n$ price <dbl> 117.00, 108.52, 109.64, 110.90, 102.75, 96.96, 98.05, 95.11, 94.…\n$ index <dbl> 59.72918, 55.40009, 55.97185, 56.61509, 52.45447, 49.49864, 50.0…\n\n\n\n\nEx. 2\n\np_index %>% \n  filter(var %in% c(\"wheat\", \"urea\")) %>%\n  ggplot() + \n  aes(x = date, y = index, colour = var) + \n  geom_path() + \n  labs(x = \"Date\", y = \"Price index, 2010 = 100\",\n       title = \"Price indices of key commodities\",\n       colour = NULL)\n\nWarning: Removed 1 row(s) containing missing values (geom_path).\n\n\n\n\n\n\n\nEx. 3\n\np_index_wd <-\n  p_index %>% \n  pivot_wider(names_from = var, values_from = c(price, index))\n\nlibrary(correlation)\n\np_index_wd %>% \n  select(contains(\"index\")) %>% \n  correlation() %>% \n  summary()\n\nRegistered S3 method overwritten by 'parameters':\n  method                         from      \n  format.parameters_distribution datawizard\n\n\n# Correlation Matrix (pearson-method)\n\nParameter   | index_wheat | index_urea | index_oil\n--------------------------------------------------\nindex_maize |     0.89*** |    0.77*** |   0.81***\nindex_oil   |     0.79*** |    0.80*** |          \nindex_urea  |     0.76*** |            |          \n\np-value adjustment method: Holm (1979)\n\np_index_wd %>% \n  select(contains(\"price\")) %>% \n  correlation() %>% \n  summary()\n\n# Correlation Matrix (pearson-method)\n\nParameter   | price_wheat | price_urea | price_oil\n--------------------------------------------------\nprice_maize |     0.89*** |    0.77*** |   0.81***\nprice_oil   |     0.79*** |    0.80*** |          \nprice_urea  |     0.76*** |            |          \n\np-value adjustment method: Holm (1979)\n\n\n\n\nEx. 4\n\np_index_fd <- \n  p_index %>% \n  group_by(var) %>% \n  mutate(index_fd = index - lag(index)) %>% \n  ungroup() %>% \n  select(date, var, index_fd) %>% \n  pivot_wider(names_from = var,\n              values_from = c(index_fd))"
  },
  {
    "objectID": "ae/ae03-data-wrangling/ae03-02-plastic-waste-solutions.html",
    "href": "ae/ae03-data-wrangling/ae03-02-plastic-waste-solutions.html",
    "title": "AE03-02 Exploring data on plstic waste",
    "section": "",
    "text": "This exercise is adopted from Data Science in a Box."
  },
  {
    "objectID": "ae/ae03-data-wrangling/ae03-02-plastic-waste-solutions.html#setup",
    "href": "ae/ae03-data-wrangling/ae03-02-plastic-waste-solutions.html#setup",
    "title": "AE03-02 Exploring data on plstic waste",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "ae/ae03-data-wrangling/ae03-02-plastic-waste-solutions.html#data",
    "href": "ae/ae03-data-wrangling/ae03-02-plastic-waste-solutions.html#data",
    "title": "AE03-02 Exploring data on plstic waste",
    "section": "Data",
    "text": "Data\nThe data set for this assignment can be found as a csv file in the data folder of your repository. You can read it in using the following.\n\nplastic_waste <- read_csv(\"data/plastic-waste.csv\")\n\nThe variable descriptions are as follows:\n\ncode: 3 Letter country code\nentity: Country name\ncontinent: Continent name\nyear: Year\ngdp_per_cap: GDP per capita constant 2011 international $, rate\nplastic_waste_per_cap: Amount of plastic waste per capita in kg/day\nmismanaged_plastic_waste_per_cap: Amount of mismanaged plastic waste per capita in kg/day\nmismanaged_plastic_waste: Tonnes of mismanaged plastic waste\ncoastal_pop: Number of individuals living on/near coast\ntotal_pop: Total population according to Gapminder"
  },
  {
    "objectID": "ae/ae03-data-wrangling/ae03-02-plastic-waste.html",
    "href": "ae/ae03-data-wrangling/ae03-02-plastic-waste.html",
    "title": "AE03-02 Exploring data on plstic waste",
    "section": "",
    "text": "This exercise is adopted from ata Science in a Box."
  },
  {
    "objectID": "ae/ae03-data-wrangling/ae03-02-plastic-waste.html#setup",
    "href": "ae/ae03-data-wrangling/ae03-02-plastic-waste.html#setup",
    "title": "AE03-02 Exploring data on plstic waste",
    "section": "Setup",
    "text": "Setup\n\nlibrary(tidyverse)"
  },
  {
    "objectID": "ae/ae03-data-wrangling/ae03-02-plastic-waste.html#data",
    "href": "ae/ae03-data-wrangling/ae03-02-plastic-waste.html#data",
    "title": "AE03-02 Exploring data on plstic waste",
    "section": "Data",
    "text": "Data\nThe data set for this assignment can be found as a csv file in the data folder of your repository. You can read it in using the following.\n\nplastic_waste <- read_csv(\"data/plastic-waste.csv\")\n\nThe variable descriptions are as follows:\n\ncode: 3 Letter country code\nentity: Country name\ncontinent: Continent name\nyear: Year\ngdp_per_cap: GDP per capita constant 2011 international $, rate\nplastic_waste_per_cap: Amount of plastic waste per capita in kg/day\nmismanaged_plastic_waste_per_cap: Amount of mismanaged plastic waste per capita in kg/day\nmismanaged_plastic_waste: Tonnes of mismanaged plastic waste\ncoastal_pop: Number of individuals living on/near coast\ntotal_pop: Total population according to Gapminder"
  },
  {
    "objectID": "ae/ae03-data-wrangling/ae03-01-import-clean-sum-plot.html",
    "href": "ae/ae03-data-wrangling/ae03-01-import-clean-sum-plot.html",
    "title": "AE03-01 Import, cleaning, summary plot",
    "section": "",
    "text": "We will us tidyverse for data wrangling and readr and readxl for data import.\n\nlibrary(tidyverse)\nlibrary(readr)       # install.packages(\"readr\")\nlibrary(readxl)      # install.packages(\"readxl\")\nlibrary(janitor)     # install.packages(\"janitor\")\nlibrary(skimr)       # install.packages(\"skimr\")"
  },
  {
    "objectID": "ae/ae03-data-wrangling/ae03-01-import-clean-sum-plot.html#exercise-1.-load-clean-and-plot-data-from-excel",
    "href": "ae/ae03-data-wrangling/ae03-01-import-clean-sum-plot.html#exercise-1.-load-clean-and-plot-data-from-excel",
    "title": "AE03-01 Import, cleaning, summary plot",
    "section": "Exercise 1. Load clean and plot data from Excel",
    "text": "Exercise 1. Load clean and plot data from Excel\nHere, we will explore the data from the file called commodity-prices.xlsx in the data folder.\n\nEx. 1.1 Inspect the file in excel: readxl::excel_sheets()\nOpen the file in Excel and inspect it.\n\nWhat sheets are there?\nWhere is the data?\n\nUse function excel_sheets() to check what sheets does R sees in this file. Please note that you need to provide path to the file manually. Thus:\n\nCreate an object path_prices\n\nand assign to it a value of the string with the path to the file.\nThis string may look like: ./path_to_folder/file_name.ext.\nMake sure that you specify the path exactly as it is with the file extension.\nMake sure that in the path, there are no extra spaces of characters which are not present in the file path.\n\nExecute function excel_sheets() specifying in the arguments path to the file.\n\n\nlibrary(readxl)\n# path_prices <- \"______\"\n# excel_sheets(path = _______)\n\nWhat does the excel_sheets() tells us?\n\n\nEx. 1.2 Load data from the sheet: readxl::read_excel(..., sheet = ____), utils::head()\nYou need to use function read_excel() to load data.\n\nCheck help for this function in the console!\nSave data in the environment under the object name prices_dta.\nglimpse() at the data\nus function head() with the data and explain what it does\n\n\n# prices_dta <- \n#   ________(path_prices)\n\n# prices_dta %>% \n#   ________()\n\n# prices_dta %>% \n#   head()\n\nAs you can see, the data is loaded into R, but there are problems:\n\nVariables names are long, bulky, contain spaces and it is difficult to use them.\nAll variables are in <chr>, which means character, when it should be numerical <dbl>.\nFirst row in the data contains text, which is irrelevant to the data.\nThe data is not tidy! We need to clean it.\n\n\n\nEx. 1.3 Cleaning variables names: janitor::clean_names(...) , base::names()\nCurrently variables names are very long.\n\nNote, we use names() function to check variables names.\n\n\n# prices_dta %>% names()\n\nWe can simplify these names and make them machine readable and usable using function janitor::clean_names().\n\ncheck help for this function ?clean_names\nrun it on the data and check the variables names\n\n\n# prices_dta %>% \n#   __________() %>% \n#   names()\n\nAre those variables names useful now?\n\n\nEx. 1.4 Cleaning variables names: dplyr::rename()\nWell, no, these variables names are not useful. We still need to rename() them into something shorter. For this, we use dplyr::rename() . See help here.\nThe logit is:\n\nwe supply data into rename() with pipe: data %>% rename().\nin the rename() , we specify what should be the new name on the left hand side and old name on the right hand\n\ndata %>% rename(new_name = OLD_NAME).\n\nwe do not use any quotation marks.\nRemember to repeat the data cleaning step with janitor::lean_names().\n\nHere is the example with the longest variable:\n\n# prices_dta %>% \n#   clean_names() %>% \n#   rename(wheat = soft_red_winter_wheat_no_2_f_o_b_us_gulf_usd_per_mt) %>% \n#   names()\n\nFollow this example to rename variables into date, oil, maize and urea.\n\n# prices_dta %>%\n#   clean_names() %>% \n#   rename(wheat = soft_red_winter_wheat_no_2_f_o_b_us_gulf_usd_per_mt, \n#          maize = ______________, \n#          date = ______________, \n#          ______________ = ______________, \n#          ______________ = ______________) %>%\n#   names()\n\nDid it work?\n\n\nEx. 1.5 Removing first row with irrelevant data dplyr::slice()\nUse function slice(prices_dta, -1). Check help for dplyr::slice().\n\nwith argument -1 we are telling to R to drop row with the number 1;\nNote, wen we use pipeline %>% we do not need to specify data frame name prices_dta within the brackets (…) of the slice() call!\nRemember to copy all the code from before, where you renamed the variables.\nAssign value of this long pipe to the new object named prices_dta_1. This object will stand for the intermediary step in the data cleaning process.\n\n\n# prices_dta_1 <- \n#   prices_dta %>%\n#   ### Place here the R code with renaming ###\n#   ### Place here the R code with renaming ###\n#   ### Place here the R code with renaming ###\n#   slice(___) %>% \n#   glimpse()\n\nIf everything alright with the data now? Let us use summary() to summaries the variables and extract some numerical features:\n\n# prices_dta_1 %>%\n#   summary()\n\nAre these results meaningful?\n\n\nEx. 1.6 Mutating variables types: dplyr::mutate(), base::as.numeric().\nAs we say on the previous step, all variables have the type character or <chr>. As this is text, it is not possible to make summary statistics out of it. R simply does not understand that we want to used those variables as numbers as we need to explain this to R.\nWe need to:\n\nmutate() existing variables (see definition of mutate here)\nthe help on the mutate() function is here with more case example here and a dedicated Chapter 5.5 in R4DS;\nand convert them to numeric or double type referred as <dbl>\nto convert variable type, we use as.numeric(), see: ?as.numeric or run as.numeric(c(\"-.1\",\" 2.7 \",\"B\")) in console.\n\nHere is the example that should work for one column:\n\nNote, it will only work if you made previous cleaning steps correctly.\nplease un-commencement it.\n\n\n# prices_dta_1 %>% \n#   mutate(oil = as.numeric(oil)) %>% \n#   glimpse()\n\nAs you can see now, oil variable has numeric format. Thus, when we run summary() we get description of the numerical values there:\n\n# prices_dta_1 %>% \n#   mutate(oil = as.numeric(oil)) %>% \n#   summary()\n\nNow, your turn to mutate all variable as numeric.\n\n# prices_dta_1 %>%\n#   mutate(oil = as.numeric(oil),\n#          wheat = ____________(____),\n#          _____ = ____________(urea),\n#          _____ = ____________(____),\n#          _____ = ____________(____)) %>%\n#   glimpse()\n\n\n\nEx. 1.7 Mutating date variable: dplyr::mutate(), janitor::convert_to_date().\nCheck results of the previous chunk!\n\nIt is clear that date variable is not a date, but a series of a number instead.\nThis is because Excel stores date as a number of days since January 1, 1990. Thus, 33664 is March 1, 1992.\nWe need to convert such date notations to some real dates using function janitor::convert_to_date().\nSee: ?convert_to_date.\nConvert date to the type <date> in the same way as variable type conversion at the previous step.\nAssign new object prices_dta_clean with the value of the data frame with all cleaning steps.\n\n\n# prices_dta_clean <- \n#   prices_dta_1 %>%\n#   mutate(oil = as.numeric(oil),\n#          wheat = ____________(____),\n#          _____ = ____________(urea),\n#          _____ = ____________(____),\n#          date = convert_to_date(____)) \n# prices_dta_clean %>% glimpse()\n\nWe have manage to clean the data!\nDo data summary() of the data to see what the variables are about.\n\n# \n\n\n\nEx. 1.8 Use skimr::skim() to generate summary statistics of the data\nGo to skimr website and learn how to use function skim(). Apply it to the prices_dta_clean data frame below and discuss how the results are different from summary().\n\nlibrary(skimr)       # install.packages(\"skimr\")\n# prices_dta_clean %>% \n#   _____()\n\n\n\nEx. 1.9 Plot a time-series of all four variables using ggplot2 package\nPlotting according to the grammar of graphics (gg) using package ggplot2 is a rewarding process. But, we need to follow some steps.\n\nWe need to make data clean and tidy.\n\nIdeally, data has to be in the long format, but wide data may also work\n\nSend data to ggplot() function to initiate a plot.\n\nNote, we use %>% (pipe) for this step: data %>% ggplot()\n\nStart adding (+) various aesthetics to the plot using aes() function:\n\nNote, inside the ggplot builder we use +, not a pipe! data %>% ggplot() + aes(x, y)\n\nAdd geometries using +\n\ndata %>% ggplot() + aes(x, y) + geom_line()\n\n\nLet us give it a try! Let us convert existing data to the plot basis and add an aesthetics for x axis:\n\nUse date as an aesthetics for x axis, wheat for y axis and a string \"wheat\" for color.\nDo not use quotation marks in aes for x and y.\nDo USE quotation marks in aes for colour.\n\n\n# prices_dta_clean %>% \n#   _________() + \n#   aes(____ = date, y = _____, color = \"_____\") \n\nR created a grid for a plot, but no plot. This is because, we did not add any geometries! Let us add a geom_path() to the plot.\n\n# prices_dta_clean %>% \n#   _________() + \n#   aes(____ = date, y = _____, color = \"_____\") \n#   _________() + \n#   geom_path(aes(y = _______, colour = \"Maize\")) + \n#   geom_path(aes(y = _______, colour = \"_____\"))\n\nNow, we shall add another line to the plot with the Maize prices:\n\nwe need to add a line with a new geom_path(), and\nspecify aes() inside geom_path(),\nfor example geom_path(aes(y = maize, colour = \"Maize\")).\ndo not forget +.\n\nGo ahead:\n\n# prices_dta_clean %>% \n#   _________() + \n#   aes(____ = date, y = _____, color = \"_____\") \n#   _________() + \n#   geom_path(_____(y = ______, colour = \"_____\"))\n\nAdd another line with `geom_path`, this time adding the oil prices to the plot.\n\n# prices_dta_clean %>% \n#   _________() + \n#   aes(____ = date, y = _____, color = \"_____\") \n#   _________() + \n#   geom_path(_____(y = ______, colour = \"_____\")) + \n#   geom_path(_____(y = ______, colour = \"_____\"))\n\n\n\nSolution to the exercise 2\n\nprices_dta_clean <- \n  read_excel(\"data/commodity-prices.xlsx\", sheet =  \"data\") %>% \n  clean_names() %>% \n  rename(wheat = soft_red_winter_wheat_no_2_f_o_b_us_gulf_usd_per_mt, \n        maize = yellow_maize_no_2_f_o_b_us_gulf_usd_per_mt, \n        date = day_month_year, \n        oil = crude_oil_brent_usd_per_barrel, \n        urea = urea_f_o_b_black_sea_usd_per_mt) %>%\n  slice(-1) %>% \n  mutate(\n    oil = as.numeric(oil),\n    wheat = as.numeric(wheat),\n    maize = as.numeric(maize),\n    urea = as.numeric(urea),\n    date = convert_to_date(date)\n  ) \n\nglimpse(prices_dta_clean)\n\nRows: 359\nColumns: 5\n$ date  <date> 1992-03-01, 1992-04-01, 1992-05-01, 1992-06-01, 1992-07-01, 199…\n$ oil   <dbl> 17.45, 18.63, 19.50, 20.83, 20.17, 19.62, 20.15, 20.08, 18.88, 1…\n$ wheat <dbl> 161.44, 153.07, 139.72, 140.36, 129.93, 118.80, 131.47, 137.42, …\n$ maize <dbl> 117.00, 108.52, 109.64, 110.90, 102.75, 96.96, 98.05, 95.11, 94.…\n$ urea  <dbl> 120.00, 120.00, 120.00, 120.00, 120.00, 120.00, 120.00, 116.88, …\n\nsummary(prices_dta_clean)\n\n      date                 oil             wheat           maize       \n Min.   :1992-03-01   Min.   : 10.41   Min.   : 85.3   Min.   : 75.27  \n 1st Qu.:1999-08-16   1st Qu.: 20.93   1st Qu.:137.3   1st Qu.:104.16  \n Median :2007-02-01   Median : 46.17   Median :175.4   Median :150.15  \n Mean   :2007-01-30   Mean   : 50.48   Mean   :185.3   Mean   :155.62  \n 3rd Qu.:2014-07-16   3rd Qu.: 71.81   3rd Qu.:220.3   3rd Qu.:176.88  \n Max.   :2022-01-01   Max.   :132.83   Max.   :419.6   Max.   :333.05  \n                                       NA's   :1                       \n      urea       \n Min.   : 62.75  \n 1st Qu.:103.94  \n Median :213.88  \n Mean   :221.94  \n 3rd Qu.:278.70  \n Max.   :900.50  \n                 \n\nskim(prices_dta_clean)\n\n\nData summary\n\n\nName\nprices_dta_clean\n\n\nNumber of rows\n359\n\n\nNumber of columns\n5\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nDate\n1\n\n\nnumeric\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\ndate\n0\n1\n1992-03-01\n2022-01-01\n2007-02-01\n359\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\noil\n0\n1\n50.48\n30.88\n10.41\n20.93\n46.17\n71.81\n132.83\n▇▃▃▂▁\n\n\nwheat\n1\n1\n185.35\n65.07\n85.30\n137.26\n175.45\n220.31\n419.61\n▇▇▃▂▁\n\n\nmaize\n0\n1\n155.62\n62.66\n75.27\n104.16\n150.15\n176.88\n333.05\n▇▆▂▂▁\n\n\nurea\n0\n1\n221.93\n137.63\n62.75\n103.94\n213.88\n278.70\n900.50\n▇▅▁▁▁\n\n\n\n\nprices_dta_clean %>% \n  ggplot() + \n  aes(x = date, y = wheat, colour = \"Wheat\") + \n  geom_path() + \n  geom_path(aes(y = maize, colour = \"Maize\")) + \n  geom_path(aes(y = urea, colour = \"Urea\"))\n\nWarning: Removed 1 row(s) containing missing values (geom_path).\n\n\n\n\n\nSame plot could be build build in a more simple way if we use long formatted data.\n\nprices_dta_clean_long <- \n  prices_dta_clean %>% \n  pivot_longer(cols = c(oil:urea))\n\nglimpse(prices_dta_clean_long)\n\nRows: 1,436\nColumns: 3\n$ date  <date> 1992-03-01, 1992-03-01, 1992-03-01, 1992-03-01, 1992-04-01, 199…\n$ name  <chr> \"oil\", \"wheat\", \"maize\", \"urea\", \"oil\", \"wheat\", \"maize\", \"urea\"…\n$ value <dbl> 17.45, 161.44, 117.00, 120.00, 18.63, 153.07, 108.52, 120.00, 19…\n\nprices_dta_clean_long %>% \n  ggplot() + \n  aes(x = date, y = value, colour = name) + \n  geom_path()\n\nWarning: Removed 1 row(s) containing missing values (geom_path)."
  },
  {
    "objectID": "ae/ae03-data-wrangling/ae03-01-import-clean-sum-plot.html#exercise-2.-optional-import-from-a-.csv-coma-separated-file",
    "href": "ae/ae03-data-wrangling/ae03-01-import-clean-sum-plot.html#exercise-2.-optional-import-from-a-.csv-coma-separated-file",
    "title": "AE03-01 Import, cleaning, summary plot",
    "section": "Exercise 2. OPTIONAL Import from a .csv: coma separated file",
    "text": "Exercise 2. OPTIONAL Import from a .csv: coma separated file\nHere is the example NHIS 2009 data used in the [@Angrist2014]. To load such data in R, we can use readr package from tidyverse readr.\nOne may use a visual import tool for data available in R studio. But remember to save the R code for data import in the script. Data import code must be a part of your analysis.\nThe challenge is to specify the right path to the file that we want to import. For this exercise, this file is also saved in the folder ./data/NHIS2009.csv\n\n2.1 Simple CSV file: readr::read_csv(), dplyr::glimpse() , base::summary() , utils::View()\nIn the folder data there is a file chicken.csv. Load it into the object chick.\n\nlibrary(readr)\n# chick <- read_csv(____)\n\nNow inspect the data:\n\nuse glimpse(____);\nprint the data set;\nView() the data;\n\n\n#\n\nTry function summary(_____).\n\n# \n\nWhat is the difference between summary and previous two ways of data exploration?\n\n\n2.2 Large and complex CSV file\nLoading larger CSV files is not different from loading small files. Below, load the file NHIS2009.csv from the folder data and then glimpse at it:\n\n# \n\n\n\nSolutions\n\nchick <- read_csv(\"data/chicken.csv\")\n\nNew names:\nRows: 5 Columns: 5\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(3): chicken, sex, motto dbl (2): ...1, eggs_laid\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `` -> `...1`\n\nglimpse(chick)\n\nRows: 5\nColumns: 5\n$ ...1      <dbl> 1, 2, 3, 4, 5\n$ chicken   <chr> \"Foghorn Leghorn\", \"Chicken Little\", \"Ginger\", \"Camilla the …\n$ sex       <chr> \"rooster\", \"hen\", \"hen\", \"hen\", \"rooster\"\n$ eggs_laid <dbl> 0, 3, 12, 7, 0\n$ motto     <chr> \"That's a joke, ah say, that's a joke, son.\", \"The sky is fa…\n\n# View(chick)\nsummary(chick)\n\n      ...1     chicken              sex              eggs_laid   \n Min.   :1   Length:5           Length:5           Min.   : 0.0  \n 1st Qu.:2   Class :character   Class :character   1st Qu.: 0.0  \n Median :3   Mode  :character   Mode  :character   Median : 3.0  \n Mean   :3                                         Mean   : 4.4  \n 3rd Qu.:4                                         3rd Qu.: 7.0  \n Max.   :5                                         Max.   :12.0  \n    motto          \n Length:5          \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n\nnhis <- read_csv(\"data/NHIS2009.csv\")\n\nRows: 80634 Columns: 40\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (38): year, inc1, inc2, inc3, inc4, inc5, inc6, inc7, inc8, serial, hhwe...\nlgl  (2): fml, marradult\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "ae/ae03-data-wrangling/ae03-01-import-clean-sum-plot.html#exercise-3.-optional.-janitor-for-cleaning-data-in-r",
    "href": "ae/ae03-data-wrangling/ae03-01-import-clean-sum-plot.html#exercise-3.-optional.-janitor-for-cleaning-data-in-r",
    "title": "AE03-01 Import, cleaning, summary plot",
    "section": "Exercise 3. OPTIONAL. janitor for cleaning data in R",
    "text": "Exercise 3. OPTIONAL. janitor for cleaning data in R\nwe follow the data cleaning exercise form the janitor webpage. Data set is called dirty_data.xlsx and it is located in: ./data/dirty_data.xlsx or on the github.\n\nddta <- read_excel(\"./data/dirty_data.xlsx\")\n\nNew names:\n• `` -> `...2`\n• `` -> `...3`\n• `` -> `...5`\n• `` -> `...6`\n• `` -> `...7`\n• `` -> `...8`\n• `` -> `...9`\n• `` -> `...10`\n• `` -> `...11`\n\nglimpse(ddta)\n\nRows: 14\nColumns: 11\n$ `Data most recently refreshed on:` <chr> \"First Name\", \"Jason\", \"Jason\", \"Al…\n$ ...2                               <chr> \"Last Name\", \"Bourne\", \"Bourne\", \"K…\n$ ...3                               <chr> \"Employee Status\", \"Teacher\", \"Teac…\n$ `Dec-27 2020`                      <chr> \"Subject\", \"PE\", \"Drafting\", \"Music…\n$ ...5                               <chr> \"Hire Date\", \"39690\", \"43479\", \"371…\n$ ...6                               <chr> \"% Allocated\", \"0.75\", \"0.25\", \"1\",…\n$ ...7                               <chr> \"Full time?\", \"Yes\", \"Yes\", \"Yes\", …\n$ ...8                               <chr> \"do not edit! --->\", NA, NA, NA, NA…\n$ ...9                               <chr> \"Certification\", \"Physical ed\", \"Ph…\n$ ...10                              <chr> \"Certification\", \"Theater\", \"Theate…\n$ ...11                              <chr> \"Active?\", \"YES\", \"YES\", \"YES\", \"YE…\n\n\nAs you can see, this data is dirty. The problems are:\n\nVariables names are wrong, they are in fact in the first row of data.\nAll variables are in character type, when in fact some variables are in different format.\nThere are some columns that are empty.\nThere are some rows that are empty.\n\n\n3.1 Make all variables named as values in the first row.\nUse function row_to_names() and specify the parameter row_number to 1.\n\n# ddta %>% \n#   ____________(__________ = 1) %>% \n#   glimpse()\n\n\n\n3.2 Make all names nice\nCurrently, all names are (insert your code form previous step):\n\n# ddta %>% \n#   ____________(__________ = 1) %>% \n#   names()\n\nUse function clean_names(), to make names nice.\n\n# ddta %>%\n#   ____________(__________ = 1) %>%\n#   ____________() %>% \n#   glimpse()\n\n\n\n3.3 Make variable hire_data as date\nTo convert variable types to meaningful numeric variables, we need to use some more functions. Specifically, functions convert_to_date(). In addition, we need to use function mutate() to tell r to modify existing variable.\nHere is the example, where we use mutate to modify existing variable Sepal.Width with the same variable but as character string instead of a number.\n\niris %>% glimpse()\n\nRows: 150\nColumns: 5\n$ Sepal.Length <dbl> 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.…\n$ Sepal.Width  <dbl> 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.…\n$ Petal.Length <dbl> 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.…\n$ Petal.Width  <dbl> 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.…\n$ Species      <fct> setosa, setosa, setosa, setosa, setosa, setosa, setosa, s…\n\niris %>% \n  mutate(Sepal.Width = as.character(Sepal.Width)) %>% \n  glimpse()\n\nRows: 150\nColumns: 5\n$ Sepal.Length <dbl> 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.…\n$ Sepal.Width  <chr> \"3.5\", \"3\", \"3.2\", \"3.1\", \"3.6\", \"3.9\", \"3.4\", \"3.4\", \"2.…\n$ Petal.Length <dbl> 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.…\n$ Petal.Width  <dbl> 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.…\n$ Species      <fct> setosa, setosa, setosa, setosa, setosa, setosa, setosa, s…\n\n\nUse the example from above to modify the variable hire_date with its values converted to date using function convert_to_date.\n\n#ddta %>%\n#   ____________(__________ = 1) %>%\n#   ____________() %>% \n#   mutate(_________ = ____________(hire_date)) %>% \n#  glimpse()\n\n\n\n3.4 Make variable percent_allocated as numeric\nSame as above, but now using function as.numeric().\n\n# ddta %>%\n#   ______________(__________ = 1) %>%\n#   ______________() %>%\n#   mutate(_________ = ____________(hire_date),\n#          percent_allocated = ________(___________)) %>%\n#   glimpse()\n\n\n\nSolutions\n\nddta <- read_excel(\"./data/dirty_data.xlsx\")\n\nNew names:\n• `` -> `...2`\n• `` -> `...3`\n• `` -> `...5`\n• `` -> `...6`\n• `` -> `...7`\n• `` -> `...8`\n• `` -> `...9`\n• `` -> `...10`\n• `` -> `...11`\n\nddta %>%\n  row_to_names(row_number = 1) %>%\n  clean_names() %>%\n  mutate(hire_date = as.numeric(hire_date),\n         percent_allocated = as.numeric(percent_allocated)) %>%\n  glimpse()\n\nWarning in row_to_names(., row_number = 1): Row 1 does not provide unique names.\nConsider running clean_names() after row_to_names().\n\n\nRows: 13\nColumns: 11\n$ first_name        <chr> \"Jason\", \"Jason\", \"Alicia\", \"Ada\", \"Desus\", \"Chien-S…\n$ last_name         <chr> \"Bourne\", \"Bourne\", \"Keys\", \"Lovelace\", \"Nice\", \"Wu\"…\n$ employee_status   <chr> \"Teacher\", \"Teacher\", \"Teacher\", \"Teacher\", \"Adminis…\n$ subject           <chr> \"PE\", \"Drafting\", \"Music\", NA, \"Dean\", \"Physics\", \"C…\n$ hire_date         <dbl> 39690, 43479, 37118, 38572, 42791, 11037, 11037, NA,…\n$ percent_allocated <dbl> 0.75, 0.25, 1.00, 1.00, 1.00, 0.50, 0.50, NA, 0.50, …\n$ full_time         <chr> \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", NA,…\n$ do_not_edit       <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA\n$ certification     <chr> \"Physical ed\", \"Physical ed\", \"Instr. music\", \"PENDI…\n$ certification_2   <chr> \"Theater\", \"Theater\", \"Vocal music\", \"Computers\", NA…\n$ active            <chr> \"YES\", \"YES\", \"YES\", \"YES\", \"YES\", \"YES\", \"YES\", NA,…"
  },
  {
    "objectID": "ae/ae03-data-wrangling/ae03-01-import-clean-sum-plot.html#functional-reference",
    "href": "ae/ae03-data-wrangling/ae03-01-import-clean-sum-plot.html#functional-reference",
    "title": "AE03-01 Import, cleaning, summary plot",
    "section": "Functional reference",
    "text": "Functional reference\nIn this exercise, we shall practice the following:\nLoading data:\n\nreadr::read_csv() and readxl::excel_sheets() with readxl::read_excel();\n\nInspecting data:\n\ndplyr::glimpse(), utils::View(), utils::head(), base::names();\n\nData summary:\n\nbase::summary(); Renaming variables:\njanitor::clean_names(...), dplyr::rename();\n\nRemoving undesired observations/row by their number in the data with:\n\ndplyr::slice();\n\nMutating/modifying types of existing variables:\n\ndplyr::mutate()\n\nConverting excel dates to R-relevant <date> variable type:\n\njanitor::convert_to_date() and janitor::excel_numeric_to_date().\n\nSummary statistics with:\n\nskimr::skim().\n\nPlotting time series with:\n\nggplot2::ggplot(), ggplot2::aes(), ggplot2::geom_path()."
  },
  {
    "objectID": "ae/ae05-multiple-regression-part-2/ae05-02-HW-slides-ovb.html",
    "href": "ae/ae05-multiple-regression-part-2/ae05-02-HW-slides-ovb.html",
    "title": "AE05-02 OVB examples from the slides",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\n\n✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n✔ tibble  3.1.7     ✔ dplyr   1.0.9\n✔ tidyr   1.2.0     ✔ stringr 1.4.0\n✔ readr   2.1.2     ✔ forcats 0.5.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\nlibrary(wooldridge)\nlibrary(modelsummary)\nlibrary(GGally)\n\nRegistered S3 method overwritten by 'GGally':\n  method from   \n  +.gg   ggplot2\n\nlibrary(parameters)\n\nRegistered S3 method overwritten by 'parameters':\n  method                         from      \n  format.parameters_distribution datawizard\n\n\n\nAttaching package: 'parameters'\n\n\nThe following object is masked from 'package:modelsummary':\n\n    supported_models\n\nlibrary(performance)\nlibrary(see)\n\nggplot2::theme_set(ggplot2::theme_bw())\n\nknitr::opts_chunk$set(\n  fig.width = 12,\n  fig.asp = 0.618,\n  out.width = \"100%\"\n)"
  },
  {
    "objectID": "ae/ae05-multiple-regression-part-2/ae05-02-HW-slides-ovb.html#goals",
    "href": "ae/ae05-multiple-regression-part-2/ae05-02-HW-slides-ovb.html#goals",
    "title": "AE05-02 OVB examples from the slides",
    "section": "Goals",
    "text": "Goals\n\nReproduce analysis from the slides on the OVB in a form of an RMarkdown document;"
  },
  {
    "objectID": "ae/ae05-multiple-regression-part-2/ae05-01-OVB.html",
    "href": "ae/ae05-multiple-regression-part-2/ae05-01-OVB.html",
    "title": "AE05-01 OVB and wage equation",
    "section": "",
    "text": "library(tidyverse)\nlibrary(alr4)\nlibrary(GGally)\nlibrary(parameters)\nlibrary(performance)\nlibrary(see)\nlibrary(car)\nlibrary(broom)\nlibrary(modelsummary)\nlibrary(texreg)\nlibrary(correlation)\nlibrary(patchwork)\nlibrary(lmtest)\nlibrary(sandwich)\nlibrary(clubSandwich)\n\nknitr::opts_chunk$set(\n  fig.align = \"center\",\n  fig.width = 16,\n  fig.asp = 0.618,\n  fig.retina = 1,\n  out.width = \"100%\", \n  message = FALSE,\n  warning = FALSE,\n  echo = TRUE\n)"
  },
  {
    "objectID": "ae/ae05-multiple-regression-part-2/ae05-01-OVB.html#load-data",
    "href": "ae/ae05-multiple-regression-part-2/ae05-01-OVB.html#load-data",
    "title": "AE05-01 OVB and wage equation",
    "section": "1.1 Load data",
    "text": "1.1 Load data\nCheck help fo the data frame ?wooldridge::wage2.\n\ndta <- \n  wooldridge::wage2 %>% \n  as_tibble()"
  },
  {
    "objectID": "ae/ae05-multiple-regression-part-2/ae05-01-OVB.html#compute",
    "href": "ae/ae05-multiple-regression-part-2/ae05-01-OVB.html#compute",
    "title": "AE05-01 OVB and wage equation",
    "section": "1.2 Compute",
    "text": "1.2 Compute\n\ntotal amount of parents education paredu as a sum of years of their education\nwage per hour wagehour as wage divided by average daily hours and 21 working days month. assume that each week has 5 working days.\nselect wage, wagehour, educ, exper, tenure, age, paredu and black, married, urban, and IQ.\n\n\n# dta1 <- \n#   ________ %>% \n#   ________(paredu = ________,\n#            wagehour = ________) %>% \n#   select(________)"
  },
  {
    "objectID": "ae/ae05-multiple-regression-part-2/ae05-01-OVB.html#built-pairs-plot-and-descriptive-statistics",
    "href": "ae/ae05-multiple-regression-part-2/ae05-01-OVB.html#built-pairs-plot-and-descriptive-statistics",
    "title": "AE05-01 OVB and wage equation",
    "section": "1.3 Built pairs plot and descriptive statistics",
    "text": "1.3 Built pairs plot and descriptive statistics\n\n# library(GGally)\n# ________(dta1)\n\n\n# library(modelsummary)\n# dta1 %>% ________()"
  },
  {
    "objectID": "ae/ae05-multiple-regression-part-2/ae05-01-OVB.html#short-regression-wage-on-all-but-iq",
    "href": "ae/ae05-multiple-regression-part-2/ae05-01-OVB.html#short-regression-wage-on-all-but-iq",
    "title": "AE05-01 OVB and wage equation",
    "section": "1.4 Short regression: wage on all but IQ",
    "text": "1.4 Short regression: wage on all but IQ\nWhy is IQ important?\n\n# fit_s <- lm()"
  },
  {
    "objectID": "ae/ae05-multiple-regression-part-2/ae05-01-OVB.html#hypothesis-the-bias",
    "href": "ae/ae05-multiple-regression-part-2/ae05-01-OVB.html#hypothesis-the-bias",
    "title": "AE05-01 OVB and wage equation",
    "section": "1.5 Hypothesis the bias",
    "text": "1.5 Hypothesis the bias"
  },
  {
    "objectID": "ae/ae05-multiple-regression-part-2/ae05-01-OVB.html#auxiliary-regression-iq-on-all-but-wage",
    "href": "ae/ae05-multiple-regression-part-2/ae05-01-OVB.html#auxiliary-regression-iq-on-all-but-wage",
    "title": "AE05-01 OVB and wage equation",
    "section": "1.6 Auxiliary regression: IQ on all but wage",
    "text": "1.6 Auxiliary regression: IQ on all but wage\n\n# fit_aux <- lm()"
  },
  {
    "objectID": "ae/ae05-multiple-regression-part-2/ae05-01-OVB.html#long-regression-wage-on-all-including-iq",
    "href": "ae/ae05-multiple-regression-part-2/ae05-01-OVB.html#long-regression-wage-on-all-including-iq",
    "title": "AE05-01 OVB and wage equation",
    "section": "1.7 Long regression: wage on all including IQ",
    "text": "1.7 Long regression: wage on all including IQ\n\n# fit_l <- lm()"
  },
  {
    "objectID": "ae/ae05-multiple-regression-part-2/ae05-01-OVB.html#compare-all-models-together-with-parameters-and-performance",
    "href": "ae/ae05-multiple-regression-part-2/ae05-01-OVB.html#compare-all-models-together-with-parameters-and-performance",
    "title": "AE05-01 OVB and wage equation",
    "section": "1.8.1 Compare all models together with parameters and performance",
    "text": "1.8.1 Compare all models together with parameters and performance\n\nuse function compare_parameters from parameters\nspecify style of standard errors and p-values in style = \"se_p\"\nprovide models names in argument column_names = c(...)\n\n\n# library(_____)\n# _____________________(\n#   _____, _____, _____, \n#   _____, \n#   _____ = c(\"short\", _____, _____)\n#   )\n\nCompare goodness of fit measures using performance::compare_performance\n\n# library(_____)\n# _____(_____, _____, _____)"
  },
  {
    "objectID": "ae/ae05-multiple-regression-part-2/ae05-01-OVB.html#compare-all-models-together-with-modelsummarymodelsummary",
    "href": "ae/ae05-multiple-regression-part-2/ae05-01-OVB.html#compare-all-models-together-with-modelsummarymodelsummary",
    "title": "AE05-01 OVB and wage equation",
    "section": "1.8.2 Compare all models together with modelsummary::modelsummary",
    "text": "1.8.2 Compare all models together with modelsummary::modelsummary\n\nyou need create an object all_mods with all three models in a list using function list(...);\nin the list, provide names for each model. For example:\n\n\nlist(`Model name` = fit_s)\n\nCreate a list below\n\n# all_mods <- list(\n#   `Short (dep: wage)` = fit_s, \n#   `_____` = _____, \n#   _____ = _____\n#   )\n\nDisplay the list structure:\n\n# str(all_mods, max.level = 1)\n\nSummarize models with modelsummary::modelsummary\n\n# library(_____)\n# _____(all_mods)"
  },
  {
    "objectID": "ae/ae05-multiple-regression-part-2/ae05-01-OVB.html#compute-the-omitted-variables-bias",
    "href": "ae/ae05-multiple-regression-part-2/ae05-01-OVB.html#compute-the-omitted-variables-bias",
    "title": "AE05-01 OVB and wage equation",
    "section": "1.9 Compute the omitted variables bias",
    "text": "1.9 Compute the omitted variables bias\n\n# coef(fit_s)[[\"educ\"]] - coef(fit_l)[[\"educ\"]]\n# coef(fit_aux)[[\"educ\"]] * coef(fit_l)[[\"IQ\"]]"
  },
  {
    "objectID": "ae/ae05-multiple-regression-part-2/ae05-01-OVB.html#interpret-the-effect-of-education",
    "href": "ae/ae05-multiple-regression-part-2/ae05-01-OVB.html#interpret-the-effect-of-education",
    "title": "AE05-01 OVB and wage equation",
    "section": "1.10 Interpret the effect of education",
    "text": "1.10 Interpret the effect of education"
  },
  {
    "objectID": "ae/ae05-multiple-regression-part-2/ae05-01-OVB.html#check-the-linearity-assumption-in-the-long-model",
    "href": "ae/ae05-multiple-regression-part-2/ae05-01-OVB.html#check-the-linearity-assumption-in-the-long-model",
    "title": "AE05-01 OVB and wage equation",
    "section": "2.1 Check the linearity assumption in the long model",
    "text": "2.1 Check the linearity assumption in the long model\n\n2.1.1 Visually\n?check_model\n\n# _____(_____, check = \"linearity\")\n\n\n\n2.1.2 Using Tukey test\n?car::residualPlots\n\n# library(_____)\n# _____(_____)"
  },
  {
    "objectID": "ae/ae05-multiple-regression-part-2/ae05-01-OVB.html#improve-long-model",
    "href": "ae/ae05-multiple-regression-part-2/ae05-01-OVB.html#improve-long-model",
    "title": "AE05-01 OVB and wage equation",
    "section": "2.2 Improve long model:",
    "text": "2.2 Improve long model:\n\ncreate object fil_l2;\nuse wagehour as a dependent variable;\nadd age^2 to the model by including I(age^2) to the regression equation\n\n\n# fit_l2 <-  lm(_____)\n\n\n2.2.1 Check the linearity assumption again\n\n# _____(_____, check = \"linearity\")\n# _____(fit_l2)"
  },
  {
    "objectID": "ae/ae05-multiple-regression-part-2/ae05-01-OVB.html#check-the-multicollinearity-assumption-in-the-long-model",
    "href": "ae/ae05-multiple-regression-part-2/ae05-01-OVB.html#check-the-multicollinearity-assumption-in-the-long-model",
    "title": "AE05-01 OVB and wage equation",
    "section": "2.2 Check the multicollinearity assumption in the long model",
    "text": "2.2 Check the multicollinearity assumption in the long model\n?car::vif\n\n# _____(_____)"
  },
  {
    "objectID": "ae/ae05-multiple-regression-part-2/ae05-01-OVB.html#conclude-on-the-final-functional-form",
    "href": "ae/ae05-multiple-regression-part-2/ae05-01-OVB.html#conclude-on-the-final-functional-form",
    "title": "AE05-01 OVB and wage equation",
    "section": "2.3 Conclude on the final functional form",
    "text": "2.3 Conclude on the final functional form"
  },
  {
    "objectID": "ae/ae05-multiple-regression-part-2/ae05-01-OVB.html#check-the-residual-homogeneity",
    "href": "ae/ae05-multiple-regression-part-2/ae05-01-OVB.html#check-the-residual-homogeneity",
    "title": "AE05-01 OVB and wage equation",
    "section": "2.4 Check the residual homogeneity",
    "text": "2.4 Check the residual homogeneity\n\n2.4.1 Visually\n\n# _____(_____, _____ = \"homogeneity\")\n\n\n\n2.4.1 statistical test\nlmtest::bptest\n\n# library(_____)\n# bptest(_____)"
  },
  {
    "objectID": "ae/ae05-multiple-regression-part-2/ae05-01-OVB.html#check-the-robustness-of-regression-again-sample-selectivity",
    "href": "ae/ae05-multiple-regression-part-2/ae05-01-OVB.html#check-the-robustness-of-regression-again-sample-selectivity",
    "title": "AE05-01 OVB and wage equation",
    "section": "2.5 Check the robustness of regression again sample selectivity",
    "text": "2.5 Check the robustness of regression again sample selectivity\n\nInspect closely the descriptive statistics on the subject of missing observations.\nWhy regression has fewer observations than the data?\nBuilt regression for the complete data set.\nCompare all estimates.\nDiscuss bias caused by OVB if present.\n\n\n# fit_l3 <- lm(_____)\n# _____(fit_l, fit_l2, fit_l3, style = \"se_p\")"
  },
  {
    "objectID": "ae/ae05-multiple-regression-part-2/ae05-01-OVB.html#construct-predicted-values-plot-for-age-variable-in-model-fit_l2",
    "href": "ae/ae05-multiple-regression-part-2/ae05-01-OVB.html#construct-predicted-values-plot-for-age-variable-in-model-fit_l2",
    "title": "AE05-01 OVB and wage equation",
    "section": "2.6 Construct predicted values plot for age variable in model fit_l2",
    "text": "2.6 Construct predicted values plot for age variable in model fit_l2\n?ggeffects::ggpredict\n\n# library(_____)\n# _____(_____, terms = \"age\") %>% plot()"
  },
  {
    "objectID": "ae/ae05-multiple-regression-part-2/ae05-01-OVB.html#interpret-the-results",
    "href": "ae/ae05-multiple-regression-part-2/ae05-01-OVB.html#interpret-the-results",
    "title": "AE05-01 OVB and wage equation",
    "section": "2.7 Interpret the results",
    "text": "2.7 Interpret the results"
  },
  {
    "objectID": "ae/ae05-multiple-regression-part-2/ae05-03-hedonic-complete-reg-analysis.html",
    "href": "ae/ae05-multiple-regression-part-2/ae05-03-hedonic-complete-reg-analysis.html",
    "title": "AE05-03 Hedonic Prices and heteroscedasticity",
    "section": "",
    "text": "library(tidyverse)\nlibrary(alr4)\nlibrary(GGally)\nlibrary(parameters)\nlibrary(performance)\nlibrary(see)\nlibrary(car)\nlibrary(broom)\nlibrary(modelsummary)\nlibrary(texreg)\nlibrary(correlation)\nlibrary(patchwork)\nlibrary(lmtest)\nlibrary(sandwich)\nlibrary(clubSandwich)\n\nknitr::opts_chunk$set(\n  fig.align = \"center\",\n  fig.width = 12,\n  fig.asp = 0.618,\n  fig.retina = 1,\n  out.width = \"100%\", \n  message = FALSE,\n  echo = TRUE\n)\n\nmy_gof <- function(fit_obj, digits = 4) {\n  sum_fit <- summary(fit_obj)\n  \n  stars <- \n    pf(sum_fit$fstatistic[1],\n       sum_fit$fstatistic[2], \n       sum_fit$fstatistic[3],\n       lower.tail=FALSE) %>% \n    symnum(corr = FALSE, na = FALSE, \n           cutpoints = c(0,  .001,.01,.05,  1),\n           symbols   =  c(\"***\",\"**\",\"*\",\" \")) %>% \n    as.character()\n  \n  list(\n    # `R^2` = sum_fit$r.squared %>% round(digits),\n    # `Adj. R^2` = sum_fit$adj.r.squared %>% round(digits),\n    # `Num. obs.` = sum_fit$residuals %>% length(),\n    `Num. df` = sum_fit$df[[2]],\n    `F statistic` = \n      str_c(sum_fit$fstatistic[1] %>% round(digits), \" \", stars)\n  )\n}\n\n# Function for screening many regressors\nscreen_many_regs <-\n  function(fit_obj_list, ..., digits = 4, single.row = TRUE) {\n    \n    if (class(fit_obj_list) == \"lm\") \n      fit_obj_list <- list(fit_obj_list)\n    \n    if (length(rlang::dots_list(...)) > 0)  \n      fit_obj_list <- fit_obj_list %>% append(rlang::dots_list(...))\n    \n    # browser()\n    fit_obj_list %>%\n      screenreg(\n        custom.note =\n          map2_chr(., seq_along(.), ~ {\n            str_c(\"Model \", .y, \" \", as.character(.x$call)[[2]])\n          }) %>%\n          c(\"*** p < 0.001; ** p < 0.01; * p < 0.05\", .) %>%\n          str_c(collapse = \"\\n\") ,\n        digits = digits,\n        single.row = single.row,\n        custom.gof.rows =\n          map(., ~my_gof(.x, digits)) %>%\n          transpose() %>%\n          map(unlist),\n        reorder.gof = c(3, 4, 5, 1, 2)\n      )\n  }"
  },
  {
    "objectID": "ae/ae05-multiple-regression-part-2/ae05-03-hedonic-complete-reg-analysis.html#load-the-data",
    "href": "ae/ae05-multiple-regression-part-2/ae05-03-hedonic-complete-reg-analysis.html#load-the-data",
    "title": "AE05-03 Hedonic Prices and heteroscedasticity",
    "section": "1. Load the data",
    "text": "1. Load the data\n\ndta <- \n  alr4::MinnLand %>% \n  as_tibble()"
  },
  {
    "objectID": "ae/ae05-multiple-regression-part-2/ae05-03-hedonic-complete-reg-analysis.html#draw-box-plots-of-acreprice-versus-year",
    "href": "ae/ae05-multiple-regression-part-2/ae05-03-hedonic-complete-reg-analysis.html#draw-box-plots-of-acreprice-versus-year",
    "title": "AE05-03 Hedonic Prices and heteroscedasticity",
    "section": "2. Draw box-plots of acrePrice versus year",
    "text": "2. Draw box-plots of acrePrice versus year\nModify variable year creating a factor based on year: use function as.factor();\nPlay with the scale transformation of acrePrice to visualize data more meaningful:\n\ncheck help for ggplot2::scale_*_continuous(trans = \"_______\")\ncheck help for ggplot2::scale_*_log10()\n\n\n# dta %>% \n#   _________(________ = __________(________)) %>% \n#   ggplot() + \n#   aes(___ = ____, ___ = ____) + \n#   geom_________()"
  },
  {
    "objectID": "ae/ae05-multiple-regression-part-2/ae05-03-hedonic-complete-reg-analysis.html#convert-monetary-values-from-current-to-constant-prices",
    "href": "ae/ae05-multiple-regression-part-2/ae05-03-hedonic-complete-reg-analysis.html#convert-monetary-values-from-current-to-constant-prices",
    "title": "AE05-03 Hedonic Prices and heteroscedasticity",
    "section": "3. Convert monetary values from current to constant prices",
    "text": "3. Convert monetary values from current to constant prices\nCreate a table with GDP deflator rates\n\ndefl_dta <-\n  tibble(\n    year = 2002:2011,\n    defl = c(77.47, 78.91, 81.03, 83.56, 86.09, \n             88.4, 90.12, 90.8, 91.86, 93.78)\n  )\nglimpse(defl_dta)\n\nRows: 10\nColumns: 2\n$ year <int> 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011\n$ defl <dbl> 77.47, 78.91, 81.03, 83.56, 86.09, 88.40, 90.12, 90.80, 91.86, 93…\n\n\nJoin defl_dta to the dta data and create new object dta_const:\n\nsee help on joining data here;\nconvert acrePrice to the constant prices.\nremove deflator variable;\nconvert variable year to a factor;\n\n\n# dta_const <- \n#   _________ %>% \n#   left_join(_________, by = \"_________\") %>% \n#   _________(_________ = _________ * (_________),\n#             year = _________(_________)) %>% \n#   _________(- _________)\n# glimpse(dta_const)\n\nHW. Built a box plot out of it with log transformation.\n\n#"
  },
  {
    "objectID": "ae/ae05-multiple-regression-part-2/ae05-03-hedonic-complete-reg-analysis.html#produce-summary-statistics",
    "href": "ae/ae05-multiple-regression-part-2/ae05-03-hedonic-complete-reg-analysis.html#produce-summary-statistics",
    "title": "AE05-03 Hedonic Prices and heteroscedasticity",
    "section": "4. Produce summary statistics",
    "text": "4. Produce summary statistics\nUse any function of your liking. Maybe data summary skim from modelsummary package.\n\n#"
  },
  {
    "objectID": "ae/ae05-multiple-regression-part-2/ae05-03-hedonic-complete-reg-analysis.html#produce-a-correlation-matrix",
    "href": "ae/ae05-multiple-regression-part-2/ae05-03-hedonic-complete-reg-analysis.html#produce-a-correlation-matrix",
    "title": "AE05-03 Hedonic Prices and heteroscedasticity",
    "section": "5. Produce a correlation matrix",
    "text": "5. Produce a correlation matrix\nUse: correlation::correlation()\n\n# ___________ %>% \n#   ___________() %>% \n#   summary()"
  },
  {
    "objectID": "ae/ae05-multiple-regression-part-2/ae05-03-hedonic-complete-reg-analysis.html#fit-regression-and-summarize-the-results",
    "href": "ae/ae05-multiple-regression-part-2/ae05-03-hedonic-complete-reg-analysis.html#fit-regression-and-summarize-the-results",
    "title": "AE05-03 Hedonic Prices and heteroscedasticity",
    "section": "6. Fit regression and summarize the results",
    "text": "6. Fit regression and summarize the results\nuse log(acrePrice) as a dependent variable\n\n# fit1 <- lm(\n#   _____ ~ _____,\n#   data = _____\n# )\n# summary(fit1)\n\nUse performance and parameters package to summarize the regression results.\n\nlibrary(parameters)\nlibrary(performance)\n# parameters(_____)\n# performance(_____)\n\n\nInterpret the regression results\n\n# screen_many_regs(fit1)"
  },
  {
    "objectID": "ae/ae05-multiple-regression-part-2/ae05-03-hedonic-complete-reg-analysis.html#check-linearity-visually",
    "href": "ae/ae05-multiple-regression-part-2/ae05-03-hedonic-complete-reg-analysis.html#check-linearity-visually",
    "title": "AE05-03 Hedonic Prices and heteroscedasticity",
    "section": "7. Check linearity visually",
    "text": "7. Check linearity visually\n\n# check_model(______, check = ______)"
  },
  {
    "objectID": "ae/ae05-multiple-regression-part-2/ae05-03-hedonic-complete-reg-analysis.html#check-the-linearity-using-car-package",
    "href": "ae/ae05-multiple-regression-part-2/ae05-03-hedonic-complete-reg-analysis.html#check-the-linearity-using-car-package",
    "title": "AE05-03 Hedonic Prices and heteroscedasticity",
    "section": "9. Check the linearity using car package",
    "text": "9. Check the linearity using car package\n\nlibrary(car)\n# residualPlots(______)"
  },
  {
    "objectID": "ae/ae05-multiple-regression-part-2/ae05-03-hedonic-complete-reg-analysis.html#check-multicollinearity",
    "href": "ae/ae05-multiple-regression-part-2/ae05-03-hedonic-complete-reg-analysis.html#check-multicollinearity",
    "title": "AE05-03 Hedonic Prices and heteroscedasticity",
    "section": "11. Check multicollinearity",
    "text": "11. Check multicollinearity\nuse vif() from car.\n\n# ______(______)"
  },
  {
    "objectID": "ae/ae05-multiple-regression-part-2/ae05-03-hedonic-complete-reg-analysis.html#check-homoscedasticity-visually",
    "href": "ae/ae05-multiple-regression-part-2/ae05-03-hedonic-complete-reg-analysis.html#check-homoscedasticity-visually",
    "title": "AE05-03 Hedonic Prices and heteroscedasticity",
    "section": "12. Check homoscedasticity visually",
    "text": "12. Check homoscedasticity visually\n\n# check_model(______, check = c(\"linearity\", \"homogeneity\"))"
  },
  {
    "objectID": "ae/ae05-multiple-regression-part-2/ae05-03-hedonic-complete-reg-analysis.html#check-homoscedasticity-using-statistical-tests",
    "href": "ae/ae05-multiple-regression-part-2/ae05-03-hedonic-complete-reg-analysis.html#check-homoscedasticity-using-statistical-tests",
    "title": "AE05-03 Hedonic Prices and heteroscedasticity",
    "section": "13. Check homoscedasticity using statistical tests",
    "text": "13. Check homoscedasticity using statistical tests\n\nlibrary(lmtest)\n# ______(______)"
  },
  {
    "objectID": "ae/ae05-multiple-regression-part-2/ae05-03-hedonic-complete-reg-analysis.html#correct-standard-errors-and-interpret-the-results",
    "href": "ae/ae05-multiple-regression-part-2/ae05-03-hedonic-complete-reg-analysis.html#correct-standard-errors-and-interpret-the-results",
    "title": "AE05-03 Hedonic Prices and heteroscedasticity",
    "section": "14. Correct standard errors and interpret the results",
    "text": "14. Correct standard errors and interpret the results\n\nlibrary(sandwich)\n# parameters(_____, vcov = \"HC3\")"
  }
]